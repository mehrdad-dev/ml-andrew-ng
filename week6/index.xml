<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> هفته ششم on Machine Learning Andrew Ng</title>
    <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/</link>
    <description>Recent content in  هفته ششم on Machine Learning Andrew Ng</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 04 Oct 2020 13:22:07 +0330</lastBuildDate>
    
	<atom:link href="https://mehrdad-dev.github.io/ml-andrew-ng/week6/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ارزیابی فرضیه</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/evaluating-hypothesis/</link>
      <pubDate>Sun, 04 Oct 2020 13:22:30 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/evaluating-hypothesis/</guid>
      <description>خطاهای موجود در پیش بینی هایتان را با استفاده از روش های زیر می‌توانید عیب یابی کنید:
 جمع آوری داده های آموزشی بیشتر استفاده از مجموعه های ویژگی کوچکتر امتحان کردن ویژگی های اضافی استفاده از ویژگی های چند جمله ای افزایش یا کاهش مقدار $\lambda$  برای عیب یابی یکی از راه های ذکر شده در بالا را به صورت تصادفی انتخاب نکنید، در بخش های بعدی تکنیک هایی برای انتخاب یکی از راه حل ها را بررسی می‌کنیم.</description>
    </item>
    
    <item>
      <title>انتخاب مدل</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/model-selection/</link>
      <pubDate>Thu, 15 Oct 2020 17:25:10 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/model-selection/</guid>
      <description>فقط به این دلیل که یک الگوریتم یادگیری متناسب با مجموعه آموزشی ما است، به این معنی نیست که آن فرضیه خوبی است!
می‌تواند overfit شده باشد، که در نتیجه پیش بینی های شما برای مجموعه آزمون ضعیف خواهد بود.
اگر خطای فرضیه خود را با داده هایی که با آن پارامتر ها را آموزش داده اید محاسبه کنید، کمتر از مجموعه داده های دیگر خواهد بود!
برای انتخاب مدل خود، می‌توانید هر درجه از چند جمله ای ها را آزمایش کرده و به نتیجه خطای آن توجه کنید.</description>
    </item>
    
    <item>
      <title>تشخیص بایاس در مقابل واریانس</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/diagnosing-bias-variance/</link>
      <pubDate>Fri, 16 Oct 2020 19:43:49 +0000</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/diagnosing-bias-variance/</guid>
      <description>در این بخش به بررسی رابطه بین درجه چند جمله ای (d) و underfit و یا overfit بودن فرضیه می‌پردازیم.
 در ابتدا لازم است که تشخیص دهیم، عاملی که باعث پیش بینی نادرست شده بایاس است یا واریانس؟ بایاس زیاد همان underfitting و واریانس زیاد همان overfitting است که باید یک میانگین مناسب بین این دو مقدار انتخاب شود.  مادامی که ما درجه چندجمله ای را افزایش می‌دهیم، خطای آموزش کاهش می‌یابد.</description>
    </item>
    
    <item>
      <title>منظم سازی و بایاس/واریانس</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/regularization-and-bias-variance/</link>
      <pubDate>Fri, 16 Oct 2020 19:43:49 +0000</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/regularization-and-bias-variance/</guid>
      <description>در ادامه به جای بررسی d و تاثیر آن بر بایاس/واریانس، نگاهی به پارامتر مرتب سازی $\lambda$ خواهیم داشت.
 $\lambda$ بزرگ: بایاس زیاد (underfitting) $\lambda$ متوسط: مقدار مناسب $\lambda$ کوچک: واریانس زیاد (overfitting)  $\lambda$ بزرگ به شدت در تمامی پارامترهای $\theta$ ایجاد نقص می‌کند که این مسئله خط تابع حاصل شده را بسیار ساده کرده و موجب underfitting خواهد شد.
رابطه $\lambda$ با مجموعه آموزشی و مجموعه واریانس به صورت زیر است:</description>
    </item>
    
    <item>
      <title>منحنی های یادگیری</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/learning-curves/</link>
      <pubDate>Fri, 16 Oct 2020 19:43:49 +0000</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/learning-curves/</guid>
      <description>آموزش 3 نمونه به آسانی خطایی برابر با صفر خواهد داشت زیرا امکان پیدا کردن یک منحنی درجه دو که دقیقا با این سه نقطه برخورد کند همیشه وجود دارد!
  هرچه مجموعه آموزشی بزرگتر می‌شود، خطای تابع درجه دو افزایش می‌یابد.
  مقدار خطا پس از تعیین اندازه m یا مجموعه آموزشی، ثابت خواهد بود.
  با بایاس زیاد مجموعه آموزشی کوچک: باعث می‌شود تا $J_{train}\left ( \Theta \right )$ کم و $J_{cv}\left ( \Theta \right )$ زیاد باشد.</description>
    </item>
    
    <item>
      <title>تصمیم گیری درباره اقدامات بعدی</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/deciding-what-to-do-next/</link>
      <pubDate>Sat, 17 Oct 2020 20:45:00 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/deciding-what-to-do-next/</guid>
      <description>روند تصمیم‌گیری ما می‌تواند به به شرح زیر باشد:
 جمع‌آوری نمونه آموزشی بیشتر: اصلاح واریانس زیاد استفاده از مجموعه کوچکتری از ویژگی‌ها: اصلاح واریانس زیاد اضافه کردن ویژگی: اصلاح بایاس زیاد اضافه کردن ویژگی‌های چندجمله‌ای: اصلاح بایاس زیاد کاهش $\lambda$: اصلاح بایاس زیاد افزایش $\lambda$: اصلاح واریانس زیاد  تشخیص شبکه‌های عصبی   یک شبکه عصبی با تعداد پارامترهای کم مستعد underfitting خواهد بود. همچنین این شبکه عصبی از نظر محاسباتی ارزان است.</description>
    </item>
    
    <item>
      <title>اولویت بندی کارها</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/prioritizing-what-to-work-on/</link>
      <pubDate>Mon, 19 Oct 2020 15:41:53 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/prioritizing-what-to-work-on/</guid>
      <description>راه‌های متفاوتی در برخورد با یک مسئله یادگیری ماشین وجود دارد:
  جمع‌آوری داده‌های زیاد (برای مثال مسئله &amp;ldquo;کوزه عسل&amp;rdquo;. اما این روش در تمامی موارد پاسخگو نخواهد بود).
  ایجاد ویژگی‌های پیچیده (برای مثال: استفاده از داده‌های سرتیتر ایمیل در ایمیل‌های spam).
  توسعه الگوریتم‌هایی که ورودی‌ها را به گونه متفاوتی پردازش کنند (تشخیص غلط‌های املایی در spam).
  اما انتخاب این که کدام یک از این گزینه‌ها مفید خواهد بود مشکل است.</description>
    </item>
    
    <item>
      <title>تحلیل خطا</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/error-analysis/</link>
      <pubDate>Mon, 19 Oct 2020 17:16:27 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/error-analysis/</guid>
      <description>رویکرد پیشنهادی برای حل کردن یک مسئله یادگیری ماشین به شرح زیر است:
  با یک الگوریتم ساده شروع کنید، سریعا آن را پیاده کرده و تست کنید.
  منحنی یادگیری را رسم کنید تا متوجه شوید که آیا داده بیشتر، ویژگی‌های بیشتر و &amp;hellip; مفید خواهند بود یا خیر.
  تحلیل خطا: به صورت دستی خطای موجود در نمونه‌های مجموعه cross validation را بررسی کرده و سعی کنید روند الگوریتم را تشخیص دهید.</description>
    </item>
    
    <item>
      <title>معیار‌های خطا برای کلاس‌های نامتوازن</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/error-metrics-for-skewed-classes/</link>
      <pubDate>Mon, 19 Oct 2020 18:13:55 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/error-metrics-for-skewed-classes/</guid>
      <description>گاهی اوقات دشوار است که بگوییم کاهش خطاها باعث بهبود الگوریتم می‌شوند.
 برای مثال: در پیش‌ بینی تشخیص سرطان که 0.5% از نمونه‌ها سرطان دارند، متوجه می‌شویم که الگوریتم یادگیری 1% خطا دارد.  هرچند اگر به سادگی هریک از نمونه‌ها را با عنوان 0 طبقه‌بندی می‌کردیم، خطا به 0.5% کاهش پیدا میکرد، با این وجود که ما الگوریتم را بهبود نداده بودیم.
این مسئله در کلاس‌های نامتوازن رخ می‌دهد، هنگامی که کلاس در کل مجموعه داده بسیار نادر است.</description>
    </item>
    
    <item>
      <title>متوازن کردن Precision  و Recall</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/trading-off-precision-and-recall/</link>
      <pubDate>Mon, 19 Oct 2020 21:27:10 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/trading-off-precision-and-recall/</guid>
      <description>ممکن است ما نیاز به یک پیش بینی مطمئن از دو کلاس به وسیله رگرسیون لجستیک داشته باشیم. یک راه این است که آستانه را افزایش دهیم:
 پیش بینی 1 اگر: $h_{\theta }\left ( x \right ) \geq 0.7$ پیش بینی 0 اگر: $h_{\theta }\left ( x \right ) &amp;lt; 0.7$  بدین ترتیب تنها درصورتی که بیمار 70% شانس بیماری داشته باشد، سرطان را پیش بینی می‌کنیم.
اکنون ما precision زیادتر و recall کمتر خواهیم داشت(با توجه به تعاریف در بخش قبل).</description>
    </item>
    
    <item>
      <title>داده برای یادگیری ماشین</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/data-for-machine-learning/</link>
      <pubDate>Mon, 19 Oct 2020 22:37:58 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/data-for-machine-learning/</guid>
      <description>چه مقدار داده را باید آموزش دهیم؟ در موارد مشخص، یک الگوریتم کم کیفیت با داده بیشتر، میتواند عملکرد بهتری نسبت به یک الگوریتم با کیفیت و داده کمتر داشته باشد.
ما باید ویژگی‌هایی را انتخاب کنیم تا اطلاعات کافی داشته باشیم. یک آزمون مفید به این صورت است که: با توجه به ورودی x، آیا یک متخصص انسانی می‌تواند با اطمینان y را پیش بینی کند؟
منطق داده‌های بزرگ: اگر یک الگوریتم با بایاس کم داشته باشیم (ویژگی‌های زیاد یا واحدهای پنهان یک تابع بسیار پیچیده می‌سازد)، پس هرچه مجموعه آموزشی بزرگتر باشد، overfitting کمتری خواهیم داشت (و الگوریتم روی مجموعه آزمون دقیق‌تر خواهد بود).</description>
    </item>
    
    <item>
      <title>فایل های هفته ششم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/files/</link>
      <pubDate>Sat, 24 Oct 2020 13:15:49 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/files/</guid>
      <description>اسلاید ها  Advice for applying machine learning - pdf Machine learning system design - pdf  غلط نامه  Errata - pdf  تمرین برنامه نویسی  Programming Exercise 5: Regularized Linear Regression and Bias v.s. Variance - pdf | problem  زیر نویس ها  انگلیسی هننوز ساخته نشده - فارسی  </description>
    </item>
    
  </channel>
</rss>