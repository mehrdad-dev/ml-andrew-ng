[
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/",
	"title": "دوره یادگیری ماشین دانشگاه استنفورد به فارسی",
	"tags": [],
	"description": "Andrew Ng دوره ماشین لرنینگ پروفسور",
	"content": "دوره یادگیری ماشین دانشگاه استنفورد در حال تکمیل است \u0026hellip;\nاین دوره به طور رایگان توسط پروفسور Andrew Ng استاد دانشگاه استنفورد تهیه شده است، و ما اینجا به طور خلاصه و مفید این دوره ارزشمند را به فارسی روان قرار داده ایم.\nبرای مشاهده بهتر فرمول های ریاضی از کامپیوتر استفاده کنید! ممکن است با گوشی درست نمایش داده نشود.\n برای دسترسی به محتوای اصلی دوره می‌توانید از روش های زیر اقدام کنید:\n  تماشای ویدئو ها از طریق یوتیوب\n  دسترسی به دوره از طریق کورسرا\n  میزان رضایت شرکت کنندگان دوره در سایت کورسرا: مشارکت مخزن گیت هاب سورس کد وب سایت برای مشارکت:\nhttps://github.com/mehrdad-dev/ml-andrew-ng-code\nاگر علاقه به مشارکت در این کار دارید از قبیل:\n کامل تر کردن محتوای مطالب بهتر کردن ترجمه مطالب کامل کردن بخش منابع مفید و غیره  لطفا درخواست خود را با عنوان مشارکت در دوره یادگیری ماشین به ایمیل mehrdad.mohammadian.contact@gmail.com ارسال کنید. به پاس قدردانی از مشارکت شما برای تولید محتوای آزاد و کمک به جامعه فارسی زبان در صفحه درباره از شما تشکر خواهد شد.\nفهرست مطالب  هفته اول     یادگیری ماشین چیست؟     یادگیری نظارتی چیست؟     یادگیری غیر نظارتی چیست؟     رگرسیون خطی با یک متغیر     تابع هزینه قسمت اول     تابع هزینه قسمت دوم     تابع هزینه قسمت سوم     گرادیان کاهشی قسمت اول     گرادیان کاهشی قسمت دوم     گرادیان کاهشی قسمت سوم      هفته دوم    رگرسیون خطی چند متغیره     گرادیان کاهشی چند متغیره     Feature Scaling     Debugging Gradient     رگرسیون چند جمله ای     معادله نرمال      هفته سوم    طبقه بندی     تابع هزینه     ساده شده تابع هزینه و گرادیان کاهشی     بهینه سازی پیشرفته     طبقه بندی چند کلاسه     مشکل Overfitting     تابع هزینه در Overfitting     رگرسیون خطی منظم     رگرسیون لجستیک منظم      هفته چهارم    فرضیه غیر خطی     نورون ها و مغز     ارائه مدل قسمت اول     ارائه مدل قسمت دوم     مثال ها قسمت اول      منابع مفید      حمایت     درباره      "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/",
	"title": "   هفته اول ",
	"tags": [],
	"description": "",
	"content": "در این هفته به صورت کلی با مفهوم خود یادگیری ماشین و دو دسته اصلی از انواع مسائل آن آشنا می‌شویم. به سراغ رگرسیون خطی تک متغیره می‌رویم و با استفاده از تابع هزینه و گرادیان کاهشی سعی در بهتر کردن نتایج داریم.\n یادگیری ماشین چیست؟   یادگیری نظارتی چیست؟   یادگیری غیر نظارتی چیست؟   رگرسیون خطی با یک متغیر   تابع هزینه قسمت اول   تابع هزینه قسمت دوم   تابع هزینه قسمت سوم   گرادیان کاهشی قسمت اول   گرادیان کاهشی قسمت دوم   گرادیان کاهشی قسمت سوم   "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/non-linear-hypotheses/",
	"title": "فرضیه غیر خطی",
	"tags": [],
	"description": "",
	"content": "انجام رگرسیون لجستیک با مجموعه ای پیچیده از داده ها و ویژگی های زیاد، کار بسیار دشواری است. تصور کنید فرضیه ای با ۳ ویژگی دارید به همراه تمام جملات درجه ۲ آن:\n$$ g(\\theta_0 + \\theta_1 x_1^2 + \\theta_2 x_1 x_2 + \\theta_3 x_1 x_3 + \\theta_4 x_2 ^2 + \\theta_5 x_2 x_3 + \\theta_6 x_3 ^2 ) $$ می‌بینیم که ۶ ویژگی به ما می‌دهد.\nروشی دقیق برای محاسبه تعداد ویژگی ها: $ \\frac{(n + r - 1)!}{r!(n-1)!} $\nکه برای مثال بالا به این صورت خواهد بود: $ \\frac{(3 + 2 - 1)!}{2!(3-1)!} = \\frac{4!}{4} = 6 $\nبرای ۱۰۰ ویژگی اگر بخواهیم آن ها را درجه ۲ کنیم، خواهیم داشت: $ \\frac{(100 + 2 - 1)!}{2!(100-1)!} = 5050 $ ویژگی جدید.\nما می‌توانیم رشد تعداد ویژگی هایی را که با تمام جملات درجه ۲ به دست می‌آوریم را به صورت $ O(\\frac{n^2}{2}) $ تقریب کنیم. و اگر بخواهیم تمام جملات درجه ۳ را در فرضیه خود داشته باشیم، ویژگی ها به صورت مرتبه زمانی $ O(n^3) $ رشد می‌کنند.\nمی‌بینیم که با افزایش تعداد ویژگی های ما، تعداد ویژگی های درجه ۲ و یا درجه ۳ به سرعت افزایش می‌یابند\nمثال:\nتصور کنید که داده های شما مجموعه ای از عکس های $50 \\times 50$ پیکسل سیاه سفید هستند، و هدف شما طبقه بندی است برای اینکه متوجه بشویم کدام یک از آن ها ماشین است. تعداد ویژگی های ما اگر هر جفت پیکسل را با هم مقایسه کنیم برابر است با: $2500$ و اگر عکس های ما به جای سیاه سفید بودن RGB باشند تعداد ویژگی ها برابر خواهد بود با: $ 7500 $\nحالا تصور کنید که باید یک تابع فرضیه درجه ۲ بسازیم، که تعداد کد ویژگی های ما در حدود $ \\frac{2500^2}{2} = 3125000 $ خواهد بود!\nکه بسیار غیر عملی است.\nشبکه های عصبی (Neural networks) راه دیگری را برای انجام مسائل یادگیری ماشین ارائه می‌دهد، زمانی که ما فرضیه ای پیچیده با تعداد زیادی ویژگی داریم!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/linear-regression-many-variable/",
	"title": "رگرسیون خطی چند متغیره",
	"tags": [],
	"description": "",
	"content": "توی این هفته قراره در مورد رگرسیون خطی با چندین متغیر صحبت کنیم!\nمثلا دیتا ای شبیه به این برای خانه ها را فرض کنید:\n   نماد      $m$ تعداد کل سطر های جدول داده ها   $n$ تعداد ویژگی ها یا همان متغیر ها   $x^{(i)}$ i امین ردیف از جدول شامل متغیر ها   $x_j^{(i)}$ مقدار موجود در ردیف i ام و ستون متغیر j    بنابراین برای تابع فرضه داریم: $h_\\theta = \\theta_0 + \\theta_1 + \\theta_2x + \u0026hellip; + \\theta_nx$\nبا مقدار پیشفرض برای $x_0$ که برابر با مقدار $1$ است.\nکه می‌توانیم برای محاسبه این مقدار از ضرب ترانهاده وکتور مقادیر تتا و وکتور x ها استفاده کنیم:\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/what-is-ml/",
	"title": "یادگیری ماشین چیست؟",
	"tags": [],
	"description": "",
	"content": "دو تعریف از یادگیری ماشین ارائه شده است:\n Arthur Samuel: رشته مطالعاتی که به کامپیوتر ها این توانایی را می‌دهد که بدون برنامه نویسی صریح یاد بگیرند.\n توجه: این یک تعریف قدیمی و غیر رسمی است!\n اما تعریفی مدرن تر \u0026hellip;\n Tom Mitchell: به یک برنامه کامپیوتری گفته می‌شود که: برای یادگیری از تجربه E با توجه به برخی از وظایف به عنوان T و اندازه گیری عملکرد با P اگر عملکرد وظیفه T با استفاده از P اندازه گیری شود با استفاده از تجربه E بهبود یابد.\n مثلا بازی چکرز!    نماد      E تجربه بار ها بازی کردن   T انجام بازی چکرز   P احتمال اینکه برنامه در بازی بعد برنده شود    به طور کلی هر مسئله یادگیری ماشین را میتوان به دو دسته نظارتی و غیر نظارتی تقسیم کرد.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/",
	"title": " هفته دوم",
	"tags": [],
	"description": "",
	"content": "در این هفته سراغ رگرسیون خطی چند متغیره می‌رویم و با فوت و فن هایی آشنا می‌شویم که برای بهتر کردن نتایج ما قابل استفاده است.\n رگرسیون خطی چند متغیره   گرادیان کاهشی چند متغیره   Feature Scaling   Debugging Gradient   رگرسیون چند جمله ای   معادله نرمال   "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/",
	"title": " هفته سوم",
	"tags": [],
	"description": "",
	"content": "این هفته با رگرسیون لجستیک یا همان Logistic regression آشنا می‌شویم که برای طبقه بندی یا classifying از آن استفاده می‌کنیم.\nهم چنین با regularization یا منظم سازی برای مدل مان آشنا می‌شویم، تا با استفاده از آن از مشکل overfitting پرهیز کنیم.\n طبقه بندی   تابع هزینه   ساده شده تابع هزینه و گرادیان کاهشی   بهینه سازی پیشرفته   طبقه بندی چند کلاسه   مشکل Overfitting   تابع هزینه در Overfitting   رگرسیون خطی منظم   رگرسیون لجستیک منظم   "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/neurons-and-brain/",
	"title": "نورون ها و مغز",
	"tags": [],
	"description": "",
	"content": "مبدا و سرچشمه شبکه های عصبی (Neural networks) ساخت الگوریتم هایی است که سعی کنند از مغز تقلید کنند. شبکه های عصبی در دهه ۸۰ و ۹۰ میلادی بسیار مورد استفاده قرار می‌گرفته اند، اما در اواخر دهه ۹۰ از محبوبیت آن ها کاسته شد، و اخیرا به دلیل پشرفت در سخت افزار کامپیوتر ها دوباره احیا شده است.\nشواهدی وجود دارد که مغز تنها از یک الگوریتم یادگیری برای انجام تمام عملکرد های محتلف خود استفاده می‌کند.\nدانشمندان سعی کرده اند در مغز حیوانات اتصال بین گوش و قشر شنوایی آن در مغز را قطع کنند و به جای آن عصب بینایی را به قشر شنوایی متصل کنند و دریافت اند که قشر شنوایی دیدن را یاد می‌گیرد!\nبه طور مشابه برای قشر حس لامسه:\nبرای مثال های بیشتر اجرایی شده می‌توانیم به موارد زیر اشاره کنیم:\nپروژه Brainport با زبان خود ببینید! ویدئو مربوط به این پروژه را در Youtube ببینید (روی تصویر کلیک کنید!):\n\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/",
	"title": " هفته چهارم",
	"tags": [],
	"description": "",
	"content": "  فرضیه غیر خطی   نورون ها و مغز   ارائه مدل قسمت اول   ارائه مدل قسمت دوم   مثال ها قسمت اول   "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/useful-articles/",
	"title": "منابع مفید ",
	"tags": [],
	"description": "",
	"content": "این صفحه در حال ویرایش و کامل شدن است \u0026hellip;\nصفحات اجتماعی افراد تاثیر گذار لیستی از صفحات اجتماعی افراد تاثیر گذار فارسی زبان در حوزه هوش مصنوعی و دیتاساینس به ترتیب الفبا:\n پوریا حداد سروناز چوبدار سعید چوپانی سید ناصر رضوی کوشیار عظیمیان شیدا وانوئی علیرضا اخوان پور علی صادقی عقیلی مریم رهبر عالم مهدی حبیب زاده  افراد تاثیر گذار انگلیسی زبان:\n Andrew Ng Yann LeCun Alfredo Canziani  کانال های مفید تلگرامی دوره های مفید دیگر  دوره یادگیری عمیق با پایتورچ دانشگاه نیویورک توسط Yann LeCun و Alfredo Canziani (در حال ترجمه به فارسی)  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/classification/",
	"title": "طبقه بندی",
	"tags": [],
	"description": "",
	"content": "Logistic Regresstion اینجا از مسائل Regression به مسائل Classification می‌رویم، اما با اسم Logistic Regression گیج نشوید! این اسم به دلایل تاریخی نامگذاری شده که در واقع رویکردی برای حل مسائل طبقه بندی است نه رگرسیون!\nBinary Classification به جای اینکه خروجی یعنی $y$ مقداری پیوسته در یک محدوده باشد، فقط $0$ یا $1$ است، یعنی : $ y \\in \\text{{0,1}} $\nبه طوری که معمولا به $0$، negative class و به $1$ هم positive class می‌گوییم، اما شما آزاد هستید که هر اسم دلخواهی را برای نام‌گذاری آن ها انتخاب کنید!\nفعلا فقط دو تا کلاس داریم که به این نوع از مسئله Binary Classification می‌گوییم.\nفرض کنید از رگرسیون خطی استفاده کنیم و نتیجه تمام پیش بینی های بیشتر از $0.5$ را به عنوان 1 در نظر بگیریم (نگاشت کنیم) ، و هم چنین تمام موارد کوچکتر از $0.5$ را $0$ در نظر بگیریم.\nآیا این متد برای مسائل طبقه بندی باینری خوب است؟\n  برای پاسخ کلیک کن   naghes\n  Hypothesis Representation تابع فرضیه ما باید به این شکل باشد:\n$$ h_\\theta(x) = g(\\theta^T x) \\hspace{2cm} 0 \\leqslant h_\\theta(x) \\leqslant 1 $$\n$$ g(z) = \\frac{1}{1 + e^{-z}} \\hspace{2cm} z = \\theta^Tx $$\nکه به این فرم جدید تابع سیگموئید یا تابع لجستیک می‌گوییم.\nکار با نمودار تعاملی تابع سیگموئید: http://desmos.com/calculator/bgontvxotm\n تابع $g(z)$ در اینجا اعداد حقیقی را به عددی بین $0$ و $1$ نگاشت می‌کند.\n$h_\\theta(x)$ به ما احتمال اینکه خروجی ما $1$ است را می‌دهد برای مثال $h_\\theta(x) = 0.7$ احتمال 70 درصدی را به ما می‌دهد که خروجی $1$ باشد.\nو احتمال اینکه پیش بینی ما در کلاس $0$ باشد متمم احتمال کلاس 0 است، که اینجا $\\text{30%} $ می‌شود.\n$$ h_\\theta(x) = P (y=1 | x;\\theta) = 1 - P (y = 0 | x;\\theta) $$ $$ P (y=0 | x;\\theta) + P (y=1 | x;\\theta) = 1 $$\nDecision Boundry برای مجزا کردن کلاس های $0$ و $1$ طبقه بندی باید خروجی تابع فرضیه را به این صورت تبدیل کنیم:\n$$ h_\\theta(x) \\geqslant 0.5 \\rightarrow y = 1 \\hspace{2cm} h_\\theta(x) \u0026lt; 0.5 \\rightarrow y = 0 $$\nنحوه عملکرد تابع لجستیکی $g$ ما به این صورت است که وقتی ورودی آن بزرگتر یا برابر صفر باشد، خروجی آن بزرگ تر یا مساوی $0.5$ می‌شود:\n$$ g(z) \\geqslant 0.5 $$ $$ \\text{ when } z \\geqslant 0 $$\nبه یاد داشته باشید که: $$z = 0, e^0 = 1 \\Rightarrow g(z) = \\frac{1}{2} $$ $$ z \\rightarrow \\infty, e^{-\\infty} \\rightarrow 0 \\Rightarrow g(z) = 1 $$ $$ z \\rightarrow -\\infty, e^{\\infty} \\rightarrow \\infty \\Rightarrow g(z) = 0 $$\nو اگر ورودی تابع g ،$ \\theta^T x $ باشد به این معنی است که:\n$$ h_\\theta(x) = g(\\theta^T x) \\geqslant 0.5 \\hspace{1.5cm} \\text{when } \\theta^T x \\geqslant 0 $$\nحالا می‌توانیم بگوییم که:\n$$ \\theta^T x \\geqslant 0 \\Rightarrow y = 1 \\hspace{1cm} \\theta^T x \u0026lt; 0 \\Rightarrow y = 0 $$\nخط تصمیم گیری، خطی است که قسمتی که 1=y است را از قسمت های 0=y جدا می‌کند، که این خط توسط تابع فرضیه ساخته می‌شود.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/gradient-many-variable/",
	"title": "گرادیان کاهشی چند متغیره",
	"tags": [],
	"description": "",
	"content": "الگوریتم جدید ما برای گرادیان کاهشی با چندین متغیر به این صورت است:\nو قسمت $ \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)} $ همان مشتق جرئی $\\frac {\\partial} {\\partial\\theta_0} J(\\theta)$ است.\nبه طور مثال برای دو متغیره و یا بیشتر خواهیم داشت:\nیادآوری: مقدار $x_0$ برابر $1$ است.\n "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/supervised/",
	"title": "یادگیری نظارتی چیست؟",
	"tags": [],
	"description": "",
	"content": "تعریف یادگیری نظارتی در یـادگـیری نــظارتـی یک مجموعه داده داریم و از قبل می‌دانیم که خروجی صحیح باید چطور باشد، اصطلاحا داده های لیبل خورده اند! با این ایده که به بین خروجی و ورودی رابطه وجود دارد.\nمسائل یادگیری نظارتی یا همان Supervised Learning به دو دسته رگرسیون و طبقه بندی تقسیم می‌شوند.\nرگرسیون | Regression در این مسائل سعی می‌کنیم خروجی ای با مقدار پیوسته را پیش بینی کنیم.\nدر مسئله پیش بینی قیمت خانه می‌خواهیم با مجموعه داده ای از قیمت های واقعی خانه ها بر اساس اندازه، قیمت خانه ای جدیدی را پیش بینی کنیم.\nطبقه بندی | Classification در عوض اینجا سعی می‌کنیم خروجی ای با مقدار گسسته پیش بینی کنیم. مثلا در مسئله تشخیص وخیم بودن یا نبودن سرطان می‌خواهیم بر اساس دو ویژگی سن و سایز تومور نتیجه را در یکی از دو دسته وخیم یا غیر وخیم طبقه بندی کنیم.\nمثال های بیشتری که شما پاسخ دهید!  با توجه به عکسی که از یک شخص دریافت کردید تشخیص دهید که سنش چه قدر است. می‌خواهید حساب های مشتری هارا بررسی کنید و تصمیم بگیرید که هک شده است یا نه. شما انبار بزرگی از اقلام یکسان دارید و می‌ خواهید پیش بینی کنید که طی 3 ماه آینده چه تعداد از این اقلام به فروش می رسند.    برای پاسخ مثال ها کلیک کن    Regression Classification Regression    "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/sponsor/",
	"title": "حمایت",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/model-representation-1/",
	"title": "ارائه مدل قسمت اول",
	"tags": [],
	"description": "",
	"content": "چگونه یک تابع فرضیه را با استفاده از شبکه های عصبی نشان خواهیم داد؟\nشبکه های عصبی به عنوان روشی برای شبیه سازی نورون ها یا شبکه ای از نورون های در مغز ساخته شده اند.\nیک نورون در مغز به این شکل است:\nکه به طور کلی از سه بخش قابل توجه زیر ساخته شده است:\n بدنه سلول (Cell body) بخش ورودی دنریت (dendrites) بخش خروجی اکسون(axon)  به طور ساده می‌توانیم بگوییم که:\nنورون ها اساسا واحد های محاسباتی هستند که از طریق رشته سیم های دنریت پالس های الکتریکی به اسم اسپایک (spikes) را ورودی می‌گیرند، و آن ها را به خروجی یا همان اکسون هدایت می‌کنند. بنابراین متوجه می‌شویم که نورون ها توسط پالس های الکتریکی با هم ارتباط برقرار می‌کنند.\nدر شبکه های عصبی مصنوعی، نورون ها واحد هایی لجستیکی (logistic unit) هستند:\nدر مدل ما دنریت ها شبیه به ویژگی ها ورودی $x_1 \u0026hellip; x_n$ هستند، و خروجی ما تابع فرضیه است.\nدر این مدل گره ورودی (node) $x_0$ واحد بایاس یا bias unit نام دارد که همیشه برابر با مقدار ۱ است. در شبکه های عصبی ما از تابع لجستیکی که در طبقه بندی داشتیم استفاده می‌کنیم: $$ \\frac{1}{1+e^{- \\theta^T x}} $$ اگر چه که در شبکه های عصبی گاهی اوقات آن را تابع فعال سازی سیگموئید صدا می‌زنیم، وکتور $\\theta$ نیز weights یا وزن های مدل نامیده می‌شوند.\nبه طور ساده می‌توانیم به این شکل نمایش دهیم:\nنود های ورودی یا لایه اول داخل لایه دوم می‌شوند، و خروجی هم تابع فرضیه است. لایه اول را لایه ورودی یا input layer می‌نامیم، و لایه دوم را هم output layer یا لایه خروجی می‌نامیم، که تابع فرضیه را به عنوان خروجی نتیجه می‌دهد.\nما می‌توانیم لایه های میانی از نود ها داشته باشیم که بین لایه ورودی و خروجی قرار می‌گیرند، که به آن ها لایه های پنهان یا hidden layers می‌گوییم.\nما نود های لایه های میانی یا پنهان را به صورت $a_0 ^2 \u0026hellip; a_n ^2$ نام گذاری می‌کنیم، و به آن ها واحد های فعال سازی یا activation units می‌گوییم.\n$$ \\begin{align*}\u0026amp; a_i^{(j)} = \\text{\u0026ldquo;activation\u0026rdquo; of unit $i$ in layer $j$} \\newline\u0026amp; \\Theta^{(j)} = \\text{matrix of weights controlling function mapping from layer $j$ to layer $j+1$}\\end{align*} $$\nبه طور مثال اگر فقط یک لایه پنهان داشته باشیم به این شکل می‌شود:\nمقدار هر نود فعال ساز به صورت زیر به دست می‌آید:\n$$ \\begin{align*} a_1^{(2)} = g(\\Theta_{10}^{(1)}x_0 + \\Theta_{11}^{(1)}x_1 + \\Theta_{12}^{(1)}x_2 + \\Theta_{13}^{(1)}x_3) \\newline a_2^{(2)} = g(\\Theta_{20}^{(1)}x_0 + \\Theta_{21}^{(1)}x_1 + \\Theta_{22}^{(1)}x_2 + \\Theta_{23}^{(1)}x_3) \\newline a_3^{(2)} = g(\\Theta_{30}^{(1)}x_0 + \\Theta_{31}^{(1)}x_1 + \\Theta_{32}^{(1)}x_2 + \\Theta_{33}^{(1)}x_3) \\newline h_\\Theta(x) = a_1^{(3)} = g(\\Theta_{10}^{(2)}a_0^{(2)} + \\Theta_{11}^{(2)}a_1^{(2)} + \\Theta_{12}^{(2)}a_2^{(2)} + \\Theta_{13}^{(2)}a_3^{(2)}) \\newline \\end{align*} $$\nاین به ما می‌گوید که نود های فعال ساز مان را با استفاده از یک ماتریس $3 \\times 4$ از پارامتر ها محاسبه می‌کنیم. به این ترتیب که ما هر ردیف (row) از پارامتر ها را به ورودی های خود اعمال می‌کنیم، تا مقدار یک نود فعال ساز را بدست آوریم.\nو خروجی فرضیه ما تابعی لجستیکی است که روی مجموع مقادیر نود های فعال ساز ما اعمال می‌شود، که در ماتریسی از پارامتر های دیگری ($\\Theta^{(2)}$) ضرب می‌شود.\nمحاسبه $a_1 ^{(2)}$ : محاسبه $a_2 ^{(2)}$ : محاسبه $a_3 ^{(2)}$ :\n[تصحیح: ردیف سوم از ماتریس $\\Theta^T X$ باید انتخاب شود] محاسبه $a_1 ^{(3)}$ یا همان $h_\\Theta(x)$: $\\Theta^{(2)}$ شامل وزن های نود های لایه دوم است.\n به طور کلی هر لابه ماتریس وزن خود را دارد که به شکل $ \\Theta^{(j)} $ نام گذاری می‌شود.\nابعاد این ماتریس های وزنی به شکل زیر محاسبه می‌شوند:\nاگر شبکه ما شامل $s_j$ واحد (unit) در هر لایه $j$ است، و $s_{j+1}$ واحد داخل لایه $j+1$ ام است، سپس ابعاد ماتریس $\\Theta^{(j)}$ برابر با $ s_{j+1} \\times (s_j + 1) $ خواهد بود.\n1+ آورده شده به خاطر نود بایاس است. نود بایاس در نود های خروجی شامل نمی‌شود، اما در نود های ورودی وجود دارد.\n مثال:\nاگر لایه اول ۲ نود ورودی، و لایه دوم ۴ نود فعال ساز داشته باشد، ابعاد $\\Theta^{(1)}$ به صورت $4 \\times 3$ خواهد بود، به طوری که:\n$$ s_j = 2, s_{j+1} = 4 $$\n$$ s_{j+1} \\times (s_j + 1) = 4 \\times 3 $$\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/cost-function/",
	"title": "تابع هزینه",
	"tags": [],
	"description": "",
	"content": "ما نمی‌توانیم از همان تابعی هزینه ای که برای رگرسیون خطی استفاده کردیم، برای تابع لجستیک نیز استفاده کنیم، زیرا خروجی تابع لجستیک موج گونه است و باعث ایجاد تعداد زیادی مینیمم محلی می‌شود. به عبارت دیگر یک تابع محدب (convex) نیست.\nتابع هزینه ما برای Logistic Regression به این صورت است:\n$$ J(\\theta) = \\frac{1}{m} \\sum_{i = 1}^m Cost(h_\\theta(x^{(i)}, y^{(i)})) $$\n$$ Cost(h_\\theta(x), y) = -log(h_\\theta(x)) \\hspace{1cm} if \\hspace{0.3cm} y = 1 $$\n$$ Cost(h_\\theta(x), y) = -log(1 - h_\\theta(x)) \\hspace{1cm} if \\hspace{0.3cm} y = 0 $$\nهرچه تابع فرضیه از $y$ دور تر باشد، خروجی تابع هزینه بزرگ تر است.\nو اگر تابع فرضیه برابر با $y$ باشد، هزینه ما $0$ است.\n$$ Cost(h_\\theta(x), y) = 0 \\hspace{0.3cm} if \\hspace{0.3cm} h_\\theta(x)) = y $$\n$$ Cost(h_\\theta(x), y) \\rightarrow \\infty \\hspace{0.5cm} if \\hspace{0.3cm} y = 0 \\hspace{0.3cm} and \\hspace{0.3cm} h_\\theta(x) \\rightarrow 1$$\n$$ Cost(h_\\theta(x), y) \\rightarrow \\infty \\hspace{0.5cm} if \\hspace{0.3cm} y = 1 \\hspace{0.3cm} and \\hspace{0.3cm} h_\\theta(x) \\rightarrow 0 $$\nاگر پاسخ صحیح ما $y = 0$ باشد، سپس تابع هزینه $0$ خواهد شد، اگر خروجی تابع فرضیه ما نیز $0$ شود.\nاگر فرضیه ما به $1$ میل کند، سپس تابع هزینه به بی نهایت میل می‌کند.\nاگر پاسخ صحیح ما $y = 1$ باشد، سپس تابع هزینه $0$ خواهد شد، اگر خروجی تابع فرضیه ما $1$ شود.\nاگر فرضیه ما به $0$ میل کند، سپس تابع هزینه به بی نهایت میل می‌کند.\nبه خاطر داشته باشید که نوشتن تابع هزینه به این روش که $J(\\theta)$ برای رگرسیون لجستیک محدب است.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/about/",
	"title": "درباره ",
	"tags": [],
	"description": "",
	"content": "مشارکت کنندگان منابع استفاده شده "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/feature-scaling/",
	"title": "Feature Scaling",
	"tags": [],
	"description": "",
	"content": "در این قسمت و قسمت بعدی در مورد فوت و فن هایی برای اعمال الگوریتم گرادیـــان کـــاهشی صحبت می‌کنیم.\nاگر شما مسئله ای دارید که چندین ویژگی یا متغیر دارد و اگر مطمئن هستید که متغیر ها در مقیاس مشابه ای نسبت به هم هستند، در این حــالت گرادیــــان کـــاهشی با سرعت بیشتری به همگرایی می‌رسد.\nفرض کنید مسئله ما دو متغیر به صورت زیر دارد: $$ x_1 = \\text {size(0-2000 feet^2) }$$ $$ x_2 = \\text {number of bedrooms(1-5) }$$\nکه اگر بـخواهیم نــــمودار کــــانتور را رسم کـنیم به این شکل خواهد شد. شکلی بلند و بیضی مــانند که گرادیـــان کـــاهشی بـرای پیدا کردن مینیمم کلی در این تابع هزینه زمان زیادی را باید صرف کند!\nکه اینجا از تکنیک Feature Scaling استفاده می‌کنیم!\nبرای انجام این کار باید مقدار متغیر $x$ را بر تفـــاضـل کران بالا و پایین خودش تقسیم کنیم. که با این کار مقادیر متغیر ها عددی بین $0$ و $1 $ قرار می‌گــیرد، و شکل معقول تری خـــواهیم داشــت. مثلا در این مسئله داریم:\n$$ x_1 = \\frac {\\text {size(feet^2)} } {2000}$$ $$ x_2 = \\frac {\\text {number of bedrooms} } {(5-1)}$$\nهمچنین روش مشابه دیگری برای انجام این کار به اسم mean normalization داریم. که در صورت کسر، تفاضل مقدار متغیر با میانگین همه مقادیر متغیر $x$ را قرار می‌دهیم.\n$$ x_i := \\frac{x_i - \\mu_i} {s_i} $$\nنکته: همچنین در مخرج کسر مـی‌توانیم از مــقدار انحراف معیار استفاده کنیم، که البته نتایج متفاوتی با هم دارند.\n "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/unsupervised/",
	"title": "یادگیری غیر نظارتی چیست؟",
	"tags": [],
	"description": "",
	"content": "تعریف یادگیری غیر نظارتی یادگیری بدون نظارت این امکان را به ما مـی‌دهد کــه بدون داشتن هیچ ایده ای نسبت به خروجی داده ها به حل مشکلات نزدیک شویم. در واقع در اینجا داده های ما هیچ برچسبی نـدارنـد و الگوریتم‌ها به حال خود رها می‌شوند تا سـاختـارهــای موجود در میان داده‌ها را کشف کنند. Unsupervised Learning ها به دو دسته خوشه بندی و غیر خوشه بندی تقسیم می‌شوند.\nخوشه بندی | Clustering در این مسـائـــل سـعــی مـی‌کــنیم داده هایی با ویژگی های مشترک را به چـندین گــروه تقـسیم کــنیم، یعنی آن ها را به خوشه ها تخصیص بدهیم. فرض کنید مجموعه داده از 1000000 ژن مختلف دارید و می‌خواهید راهی پیدا کنید که به صورت خودکار آن ها را گروه بندی کند که به نوعی به هم شباهت دارند.\nمثال های بیشتر \u0026hellip;\n دسته بندی مشتری های فروشگاه اینترنتی تا بتوانیم مشتری های مشابه را در یک خوشه نگه داری کنیم. الگوریتم Cocktail Party به شما امکان می‌دهد کـــه در مــحیط بــی نظم سـاختـار پیدا کنید:  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/model-representation-2/",
	"title": "ارائه مدل قسمت دوم",
	"tags": [],
	"description": "",
	"content": "در این قسمت چگونگی انجام محاسبات را به صورت بهینه تر از طریق پیاده سازی به روش vectorized بررسی می‌کنیم. و می‌آموزیم که چرا شبکه های عصبی خوب هستند و چطور می‌توانیم از آن ها برای یادگیری چیز های پیچیده و غیر خطی استفاده کنیم.\nبرای یادآوری عبارات زیر مثالی های شبکه های عصبی بودند:\n$$ \\begin{align*} a_1^{(2)} = g(\\Theta_{10}^{(1)}x_0 + \\Theta_{11}^{(1)}x_1 + \\Theta_{12}^{(1)}x_2 + \\Theta_{13}^{(1)}x_3) \\newline a_2^{(2)} = g(\\Theta_{20}^{(1)}x_0 + \\Theta_{21}^{(1)}x_1 + \\Theta_{22}^{(1)}x_2 + \\Theta_{23}^{(1)}x_3) \\newline a_3^{(2)} = g(\\Theta_{30}^{(1)}x_0 + \\Theta_{31}^{(1)}x_1 + \\Theta_{32}^{(1)}x_2 + \\Theta_{33}^{(1)}x_3) \\newline h_\\Theta(x) = a_1^{(3)} = g(\\Theta_{10}^{(2)}a_0^{(2)} + \\Theta_{11}^{(2)}a_1^{(2)} + \\Theta_{12}^{(2)}a_2^{(2)} + \\Theta_{13}^{(2)}a_3^{(2)}) \\newline \\end{align*} $$\nما قصد داریم متغیر جدیدی را به صورت $z_k ^{(j)}$ معرفی کنیم، که تابع $g$ آن را به عنوان ورودی می‌گیرد.\nدر مثال قبلی اگر متغیر $z$ را جایگزین کنیم: $$ \\begin{align*}a_1^{(2)} = g(z_1^{(2)}) \\newline a_2^{(2)} = g(z_2^{(2)}) \\newline a_3^{(2)} = g(z_3^{(2)}) \\newline \\end{align*} $$\nبه عبارت دیگر، برای لایه $j=2$ و نود $k$ متغیر $z$ به این صورت خواهد بود: $$ z_k ^{(2)} = \\Theta_{k,0} ^{(1)}x_0 + \\Theta_{k,1} ^{(1)}x_1 + \u0026hellip; + \\Theta_{k,n} ^{(1)} x_n $$\nبه طور مثال: $$ z_1 ^{(2)} = \\Theta_{1,0} ^{(1)}x_0 + \\Theta_{1,1} ^{(1)}x_1 + \\Theta_{1,2} ^{(1)} x_2 + \\Theta_{1,3} ^{(1)}x_3 $$ $$ a_1 ^2 = g(z_1 ^{(2)} ) $$\nما می‌توانیم محاسبات شبکه عصبی را به صورت برداری (vectorize) درآوریم، برای نمایش $x$ و $z^j$ به صورت برداری می‌توانیم بنویسیم:\n$$ \\begin{align*}x = \\begin{bmatrix}x_0 \\newline x_1 \\newline\\cdots \\newline x_n\\end{bmatrix} \u0026amp; z^{(j)} = \\begin{bmatrix}z_1^{(j)} \\newline z_2^{(j)} \\newline\\cdots \\newline z_n^{(j)}\\end{bmatrix}\\end{align*} $$\nبا تنظیم $x = a^{(1)}$ می‌توانیم معادله را به صورت زیر بازنویسی کنیم: $$ z^{(j)} = \\Theta^{(j - 1)} a^{(j - 1)} $$\nما ماتریس $\\Theta^{(j - 1)}$ با ابعاد $ s_j \\times (n+1) $ ($s_j$ تعداد گره های فعال ساز ما است) را با وکتور $a^{(j - 1)}$ با ارتفاع $n+1$ ضرب می‌کنیم، که به عنوان خروجی به ما وکتور $z^{(j)}$ را با ارتفاغ $s_j$ می‌دهد.\nاکنون ما یک وکتور از نود های فعال سازمان از لایه j ام داریم: $$ a^{(j)} = g(z^{(j)}) $$\nهمانطور که می‌بینیم g، تابع سیگموئید را به صورت عنصر به عنصر (element-wise) به هر یک از اعضای وکتور $z^{(j)}$ اعمال می‌کند.\nو سپس می‌توانیم واحد بایاس (bias unit) که برابر ۱ است را بعد از محاسبه $a^{(j)}$ اضافه کنیم. واحد بایاس همان $a_0 ^{(1)}$ است که برابر با ۱ می‌باشد.\nقبل از محاسبه فرضیه نهایی اجازه دهید یک وکتور $z$ دیگر را هم محاسبه کنیم: $$ z^{(j+1)} = \\Theta^{(j)} a^{(j)} $$\nاین وکتور را از طریق ضرب ماتریس تتا بعد از $\\Theta^{(j - 1)}$ با مقادیر تمام نود های فعال سازی که به دست آورده ایم، محاسبه می‌کنیم.\nآخرین ماتریس تتا یعنی $\\Theta^{(j)}$ فقط یک ردیف خواهد داشت که در یک ستون $a^{(j)}$ ضرب می‌شود، به طوری که نتیجه آن یک عدد است.\nسپس فرضیه نهایی خودمان را به این صورت نتیجه می‌گیریم:\n$$ h_\\theta(x) = a^{(j+1)} = g(z^{(j+1)}) $$\nتوجه داشته باشید که در این مرحله آخر، بین لایه $j$ و لایه $j+1$ دقیقا همان کاری انجام می‌هیم که در رگرسیون لجستیک انجام دادیم.\nافزودن تمام این لایه های میانی در شبکه های عصبی به ما این امکان را می دهد که با ظرافت بیشتری فرضیه های غیر خطی جالب و پیچیده تری تولید کنیم!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/simplified-cost-gradient/",
	"title": "ساده شده تابع هزینه و گرادیان کاهشی",
	"tags": [],
	"description": "",
	"content": "Cost Function ما می‌توانیم دو حالت شرطی تابع هزینه خودمان در قسمت قبلی را در یک حالت فشرده شده بنویسیم:\n$$ Cost(h_\\theta(x), y) = - y \\hspace{0.2cm} log(h_\\theta(x)) - (1 - y) log(1 - h_\\theta(x)) $$\nدر خاطر داشته باشید وقتی که $y$ برابر $1$ است، قسمت $(1 - y) log(1 - h_\\theta(x))$ برار $0$ خواهد شد.\nاگر $y$ برابر با $1$ باشد، سپس قسمت $- y \\hspace{0.2cm} log(h_\\theta(x))$ برابر $0$ خواهد شد و در نتیجه تاثیری ندارد.\nدر نهایت می‌توانیم کل تابه هزینه را به این صورت بنویسیم:\n$$ J(\\theta) = - \\frac{1}{m} \\sum_{i = 1}^m [y^{(i)} log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\\theta(x^{(i)})) ] $$\nو پیاده سازی برداری شده (vectorized) به این صورت خواهد بود:\n$$ \\begin{align*} \u0026amp; h = g(X\\theta)\\newline \u0026amp; J(\\theta) = \\frac{1}{m} \\cdot \\left(-y^{T}\\log(h)-(1-y)^{T}\\log(1-h)\\right) \\end{align*} $$\nGradient Descent به یاد داشته باشید که شکل کلی گرادیان کاهشی به این صورت است:\n$$ \\begin{align*}\u0026amp; Repeat \\lbrace \\newline \u0026amp; \\theta_j := \\theta_j - \\alpha \\dfrac{\\partial}{\\partial \\theta_j}J(\\theta) \\newline \u0026amp; \\rbrace\\end{align*} $$\nمی‌توانیم قسمت مشتق را با استفاده از حساب دیفرانسیل محاسبه کنیم:\n$$ \\begin{align*} \u0026amp; Repeat \\lbrace \\newline \u0026amp; \\theta_j := \\theta_j - \\frac{\\alpha}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} \\newline \u0026amp; \\rbrace \\end{align*} $$\nتوجه داشته باشید که این الگوریتم مشابه الگوریتمی است که ما در رگرسیون خطی استفاده کردیم، هنوز باید به صورت همزمان همه مقادیر $\\theta$ را به روز کنیم.\nو پیاده سازی برداری شده (vectorized) به این صورت خواهد بود:\n$$ \\theta := \\theta - \\frac{\\alpha}{m} X^T g((X \\theta) -\\vec{y} ) $$\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/debugging-gradient/",
	"title": "Debugging Gradient",
	"tags": [],
	"description": "",
	"content": "در این قسمت در مورد تکنیک هایی برای اطمینان از درستی کار گرادیان کاهشی صحبت مـی‌کنیم. و در ادامه در مورد نحوه انتخاب مقدار پارامتر آلفا.\nهمانطور که می‌دانیم کار گرادیان کاهشی پیدا کردن مقدار تتا برای ما است تا تابع هزینه مینیمم شود. می‌خواهیم نمودار تابع $J$ بر حسب دفعات انــــجام گرادیان کاهشی را رسم کنیم و تا متوجه بشویم که گرادیان کاهشی عملکرد درستی دارد یا نه!\nبه این ترتیب نموداری به این شکل خواهیم داشت: می‌بینیم که احتملا گرادیان کاهشی درست کار مـی‌کند چون بعد از هر بار انجام مقدار $J$ کاهش می‌یابد!\nهمـچنین مـی‌توانیم از Automatic convergence test استفاده کنیم، به این صورت که اگر $J$ بعد از هر تکرار کاهشی کمتر از $E= 10^{-3}$ داشته باشد، اعلام همگرایی می‌کنیم، که تعیین مقدار این آستانه سخت است!\nاگر چنین نموداری داشتیم یعنی گرادیان کـاهـشـی به درستی کار نمی‌کند:\nو معمولا به این معنی است که باید از مقدار آلفا کوچک تری استفاده کنیم.\nو در شکل زیر می‌بینیم که بزرگی بیش از حد آلفا باعث واگرایی شده است. که هیـچوقت به مینیمم نمی‌رسد!\nو گاهی اوقات نیز ممکن اسـت به شکل زیر باشد که باید مقدار آلفا را کاهش دهیم و اگر مقدار آلفا بیش از حد کوچک باشد، گرادیان کاهشی دیر تر به همگرایی می‌رسد.\nمتوجه می‌شویم که مقدار خوب برای آلفا مقداری است که در هر بار تکرار الگوریتم گرادیان کاهشی، تابع هزینه $J$ کاهش یابد.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/linear-regression-one-variable/",
	"title": "رگرسیون خطی با یک متغیر",
	"tags": [],
	"description": "",
	"content": "بررسی نماد ها و مفاهیم مثلا در دیتای خانه ها نماد ها به این صورت هستند:    نماد      $m$ تعداد کل ردیف های جدول دیتای یادگیری   $x$ متغیر های ورودی   $y$ متغیر های خروجی یا هدف    برای آدرس دهی در جدول به این شکل عمل می‌کنیم:\n$$(x_i, y_i) \\Rightarrow x_1= 2104, y_1 = 460$$\nاینجا منظور از $i$ اندیس دیتا در جدول است.\n همانطور که می‌بینید هدف ما اینکه با دادن مجموعه داده $train$ به الگوریتم، تابعی رو به وجود بیاوریم که با گرفتن متغیر ورودی $x$ متغیر خروجی یعنی $y$ رو پیش بینی کند! که به تابع $h$ ، $hypothesis$ یا فرضه می‌گوییم.\nتابع $h$ را به این شکل نمایش می‌‌دهیم: $$ h_\\theta(x) = \\theta_0 + \\theta_1x $$\nکه این در واقع رگرسیون خطی تک متغیره است، $x$ همان تک متغیر مدل است، $ \\theta_0, \\theta_1 $ نیز پارامتر های مدل هستند.\nخط قرمز همان تابع $h$ است که برای پیش بینی قیمت خانه با متغیر $x$ به دست آمده\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/examples-1/",
	"title": "مثال ها قسمت اول",
	"tags": [],
	"description": "",
	"content": "عملگر منطقی AND یک مثال ساده از کاربرد شبکه های عصبی پیش بینی نتیجه عملگر منطقی AND بین دو متغیر $x_1$ و $x_2$ است.\nمی‌دانیم که جدول درستی عملگر AND به این صورت است:\nشکل کلی توابع به صورت زیر است:\n$$ \\begin{align*}\\begin{bmatrix}x_0 \\newline x_1 \\newline x_2\\end{bmatrix} \\rightarrow\\begin{bmatrix}g(z^{(2)})\\end{bmatrix} \\rightarrow h_\\Theta(x)\\end{align*} $$\nبه خاطر داشته باشید که $x_0$ متغیر بایاس ما است، و همواره برابر با مقدار 1 است.\n و ماتریس وزن های خود را به این صورت تنظیم می‌کنیم:\n$$ \\Theta^{(1)} = [-30 \\hspace{0.5cm} 20 \\hspace{0.5cm} 20] $$\nاین کار باعث می‌شود که نتیجه تابع فرضیه ۱ شود، اگر هر دو متغیر $x_1$ و $x_2$ ۱ باشند.\nبه صورت خلاصه می‌توانیم این مثال را به شکل زیر شرح دهیم: عملگر منطقی OR "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/advanced-optimization/",
	"title": "بهینه سازی پیشرفته",
	"tags": [],
	"description": "",
	"content": "Conjugate gradient, BFGS و L-BFGS راه های پیچیده تر و سریع تری برای بهینه سازی $\\theta$ به جای Gradient descent هستند.\nپیشنهاد می‌شود که این الگوریتم های پیچیده را خودتان ننویسید (مگر اینکه در محاسبات عددی متخصص باشید)، و به جای آن از کتابخانه ها استفاده کنید، زیرا قبلا آزمایش شده اند و بسیار بهینه شده اند.\nابتدا لازم است تابعی بسازیم که دو مقدار زیر را با ورودی مقدار $\\theta$ برگرداند:\n$$ \\begin{align*} \u0026amp; J(\\theta) \\newline \u0026amp; \\dfrac{\\partial}{\\partial \\theta_j}J(\\theta)\\end{align*} $$\nتابعی می‌نویسیم که هر دو این مقادیر را بر گرداند:\nfunction [jVal, gradient] = costFunction(theta) jVal = [...code to compute J(theta)...]; gradient = [...code to compute derivative of J(theta)...]; end سپس می‌توانیم از الگوریتم بهینه سازی ()fminunc در اکتاو به همراه تابع ()optimset برای ساخت یک object شامل تنظیمات و گزینه هایی که می‌خواهیم به عنوان ورودی به تابع ()fminunc بدهیم.\noptions = optimset(\u0026#39;GradObj\u0026#39;, \u0026#39;on\u0026#39;, \u0026#39;MaxIter\u0026#39;, 100); initialTheta = zeros(2,1); [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options); به عنوان ورودی به تابع ()fminunc:\nتابع هزینه، وکتور مقادیر تتا، و options را که از قبل درست کرده ایم می‌دهیم.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/polynomial-regression/",
	"title": "رگرسیون چند جمله ای",
	"tags": [],
	"description": "",
	"content": "Polynomial Regression تابع فرضیه $h$ می‌تواند خطی نباشد، اگر تناسب خوبی با داده های ما ندارد، می‌توانیم برای تغییر منحنی تابع از توابع چند جمله ای استفاده کنیم تا به تناسب بهتری برای داده ها برسیم.\nفرض کنید که تابع فرضیه ما $ h_\\theta(x) = \\theta_0 + \\theta_1 x_1$ باشد بنابراین می‌توانیم ویژگی جدیدی بر پایه ویژگی $x_1$ اضافه کنیم تا به تابعی quadratic یا درجه دوم برسیم:\n$$ {\\color{Blue} h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2}$$\nیا به تابعی درجه سه یا cubic: $$ {\\color{Green} h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2 + \\theta_3 x_1^3}$$\nبه طور مثال برای تابع درجه سه می‌نویسیم:\nهمچنین می‌توانیم از نمودار ریشه دوم یا squaer root استفاده کنیم:\n$$ h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 \\sqrt{x}$$\nتوجه کنید بعد از اینکه ویژگی های جدید خود را به این روش اضافه کردید، انجام feature scaling برای برای ویژگی ها یا همان متغیر ها خیلی مهم است!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost1/",
	"title": "تابع هزینه قسمت اول",
	"tags": [],
	"description": "",
	"content": "تعریف تابع هزینه | Cost Function با این تابع می‌توانیم بهترین خط مستقیم را برای داده هایمان به دست آوریم. با انتخاب های متفاوت برای پارامتر های $\\theta_1$ و $\\theta_0$ تابع های فرضیه متفاوتی به دست می‌آوریم: در رگرسیون خطی مجموعه آموزشی مثل این نمودار داریم و می‌خواهیم مقادیری برای $\\theta_0$ و $\\theta_1$ به دست آوریم به طوری که خط راستی که رسم می‌کنیم، بهترین تطابق را با داده هایمان داشته باشد.\nبنابراین مقادیر را باید طوری تعیین کنیم که خروجی تابع $h$ بر حسب $x$ تا جای ممکن به مقادیر واقعی $y$ در مجموعه دیتای آموزشی نزدیک باشد.\n$$ h_\\theta(x) = \\theta_0 + \\theta_1x $$ $$ J(\\theta_0,\\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y_i} - y_i)^2 = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x) - y_i)^2 $$\nبنابراین تابع هزینه $J$ را به این صورت تعریف می‌کنیم. که تابع خطای مجذور نیز نامیده می‌شود، و هدف آن مینیمم کردن $\\theta_0$ و $\\theta_1$ است. دلیل حضور $\\frac{1}{2m}$ نیز برای این است که فرمول ریاضی آسان تر شود، با قرار دادن 2 در کسر یعنی عبارت را نصف می‌کنیم چون می‌دانیم که مینیمم کردن نصف چیزی مثل مینیمم کردن همان چیز است!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/multiclass-classification/",
	"title": "طبقه بندی چند کلاسه",
	"tags": [],
	"description": "",
	"content": "هنگامی که در classifiction، بیش از دو دسته داشته باشیم به جای $y = \\text{ {0,1} }$ تعاریف خود را به $ y = \\text { {0,1, \u0026hellip;, n} } $ گسترش می‌دهیم.\nاز آنجا که ما مسئله خودمان را به n+1 (n+1 به این خاطر که ایندکس از صفر شروع می‌شود) مسئله طبقه بندی باینری تقسیم می‌کنیم، در هر کدام از آن ها ما احتمال عضویت $y$ را در یکی از کلاس هایمان پیش بینی می‌کنیم:\n$$ \\begin{align*}\u0026amp; y \\in \\lbrace0, 1 \u0026hellip; n\\rbrace \\newline\u0026amp; h_\\theta^{(0)}(x) = P(y = 0 | x ; \\theta) \\newline\u0026amp; h_\\theta^{(1)}(x) = P(y = 1 | x ; \\theta) \\newline\u0026amp; \\cdots \\newline\u0026amp; h_\\theta^{(n)}(x) = P(y = n | x ; \\theta) \\newline\u0026amp; \\mathrm{prediction} = \\max_i( h_\\theta ^{(i)}(x) )\\newline\\end{align*} $$\nما در واقع یک کلاس را انتخاب می‌کنیم و سپس بقیه را به یک کلاس دوم واحد تبدیل می‌کنیم، این کار را به طور مکرر انجام می‌دهیم ، و binary logistic regression برای هر کدام از آن ها به کار می‌بریم، و سپس از تابع فرضیه ای برای پیش بینی استفاده می‌کنیم که بالاترین مقدار را برگرداننده باشد.\nتصویر زیر نحوه طبقه بندی 3 کلاس را نشان می‌دهد:\nبه طور خلاصه:\nبرای هر $class \\text{ } i$ تابع فرضیه logistic regression classifier را برای پیش‌بینی احتمال $y=i$ تشکیل بدهید.\nو برای یک ورودی جدید به اسم $x$ ، $i$ امین کلاسی که ماکسیمم است را انتخاب کنید:\n$$ \\max_i ( h_\\theta^{(i)} (x) ) $$\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/normal-equation/",
	"title": "معادله نرمال",
	"tags": [],
	"description": "",
	"content": "Normal Equation الگوریتم گرادیان کاهشی روشی بود برای مینیمم کردن تابع $J$ ، اما روش دومی نیز وجود دارد که بدون داشتن حلقه تکرار این کار را انجام بدهد که معادله نرمال نام دارد.\nفرض کنید که تابع هزینه درجه دو ای مثل این داریم: $$ J(\\theta) = a\\theta^2 + b\\theta + c $$ $$ \\frac{\\partial} {\\partial x} J(\\theta) \\overset{\\underset{\\mathrm{set}}{}}{=} 0 $$\nکه برای مینیمم کردن این تابع درجه دو مشتق آن را می‌گیریم و برابر با صفر قرار می‌دهیم، که این به ما اجازه می‌دهد که مقدار $\\theta$ را برای مینیمم کردن تابع پیدا کنیم.\nاما مسئله ای که برای ما جالب است $\\theta$ یک عدد حقیقی نیست، بلکه یک وکتور در ابعدا 1+n است:\nبرای محاسبه اینکه چطور تابع هزینه را مینیمم کنیم باید مشتق جزئی تابع $J$ را برای هر کدام از تتا ها بگیریم و برابر با صفر قرار دهیم، بعد از محاسبه همه معادله ها مقدار تتا ای که تابع $J$ مینیمم می‌شود را به دست می‌آوریم.\nاگر مجموعه آموزشی به این شکل داشته باشیم:\nمعادله نرمال ما برای محاسبه تتا به این صورت خواهد بود:\n$$ \\theta = (X^T X)^{-1} X^T y $$\nبا استفاده از معادله نرمال نیازی به Feature Scaling نداریم، و برای مقایسه گرادیان کاهشی و معادله نرمال:\n   گرادیان کاهشی معادله نرمال     به تنظیم پارامتر آلفا نیاز دارد به تنظیم پارامتر آلفا نیاز ندارد   به تکرار نیاز دارد به تکرار نیاز ندارد   مرتبه زمانی اش $O(kn)^3 $ است مرتبه زمانی اش $O(n)^3$ است   برای تعداد ویژگی های زیاد خوب کار می‌کند برای تعداد ویژگی های زیاد کند است    "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost2/",
	"title": "تابع هزینه قسمت دوم",
	"tags": [],
	"description": "",
	"content": "تا اینجا به طور خلاصه تمام چیزی که از تابع هزینه می‌دانیم در زیر آمده است:\nاما اجازه بدید برای ساده سازی تابع فرضیه را تنها با یک پارامتر به این شکل در نظر بگیریم: $ h_\\theta(x) = \\theta_1x $ و سه مقدار مختلف $0$، $5.0 $ و $1$ رو حساب کنیم \u0026hellip;\nمثلا برای مقدار تتا برابر با $1$ محاسبات زیر را خواهیم داشت:\n$$ {\\color{Red} J(\\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\theta_1x - y_i)^2 \\Rightarrow \\frac{1}{2m} (0^2 + 0^2 + 0^2) = 0 } $$ به همین صورت برای دو مقدار دیگر داریم:\n$$ {\\color{Blue} J(0.5) = \\frac{1}{2m} [ (0.5 - 1)^2 + (1-2)^2 + (1.5 -3)^2] \\Rightarrow 0.58 } $$ $$ {\\color{Green} J(0) = \\frac{1}{2m} ( 1^2 + 2^2 + 3^2 +) \\Rightarrow 2.3 }$$\nو اگر به همین ترتیب برای مقادیر دیگر رسم کنیم:\nمتوجه می‌شویم که به ازای هر مقدار تتا به یک تابع فرضیه متفاوت و یک مقدار متفاوت برای تابع $J$ می‌رسیم و همینطور که می‌بینیم در نقطه $1$ در مینیمم ترین حالت ممکن هستیم و این همان هدف ما است!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/overfitting/",
	"title": "مشکل Overfitting",
	"tags": [],
	"description": "",
	"content": "تصور کنید مسئله پیش بینی $y$ را، به صورتی که $x \\in R$ است را داریم.\nسمت چپ ترین شکل زیر نتیجه fitting، $y = \\theta_0 + \\theta_1x$ را بر روی مجموعه داده نشان می‌دهد. می بینیم که داده ها واقعاً روی خط مستقیم قرار ندارند، بنابراین اصطلاحا خوب fit نشده است (تناسب خوبی با داده ها ندارد).\nدر عوض اگر ویژگی $x^2$ را اضافه کنیم، و $y = \\theta_0 + \\theta_1x+ \\theta_2 x^2$ را fit کنیم، سپس کمی بهتر با داده ها مطابقت پیدا می‌کنیم که در شکل وسطی می‌بینیم. به طور ساده لوحانه ممکن است به نظر برسد که هرچه تعداد ویژگی بیشتری اضافه کنیم بهتر است!\nبا این حال اضافه کردن ویژگی های بیش از حد نیز خطراتی دارد!\nسمت راست ترین شکل نتیجه چند جمله ای مرتبه ۵ $y = \\sum_{j = 0}^5 \\theta _j x^j$ است.\nما می‌بینیم که منحنی اعمال شده به خوبی از داده ها عبور می‌کند، اما انتظار نداریم که این پیش بینی کننده (predictor) خوبی برای پیش بینی قیمت مسکن (y) در مناطق مختلف قابل سکونت (x) باشد.\nبدون اینکه به طور رسمی معنی این اصطلاحات را مشخص کنیم، می‌گوییم که:\nشکل سمت چپ نمونه ای از underfitting است. و شکل سمت راست نیز نمونه ای overfitting است.\nUnderfitting Underfitting یا بایاس زیاد (high bias) زمانی رخ می‌دهد که شکل حاصل از تابع فرضیه ما (h) به طور ضعیفی با روند داده های ما در مجموعه داده (dataset) تطابق داشته باشد.\nاین وضعیت معمولا به دلیل بسیار ساده بودن تابع یا استفاده از ویژگی های کم رخ می‌دهد.\nOverfitting در طرف دیگر overfitting یا واریانس زیاد (high variance) وضعیتی است که توسط یک تابع فرضیه ایجاد می‌شود که تناسب خوبی با داده های ما دارد، اما پیش بینی داده های جدید که تا کنون ندیده است را به خوبی انجام نمی‌دهد، اصطلاحا generalize نیست.\nاین وضعیت معمولا به دلیل پیچیده بودن تابع فرضیه ایجاد می‌شود که انحنا ها و زوایای غیر ضروری زیادی را ایجاد می‌کند که با داده های ما ارتباطی ندارند.\nدو گزینه برای حل مشکل overfitting وجود دارد:\n تعداد ویژگی ها را کاهش دهید   به طور دستی ویژگی هایی را برای نگهداری انتخاب کنید از یک الگوریتم model selection استفاده کنید  منظم سازی | Regularization   همه ویژگی ها را نگه دارید، اما اندازه پارامتر های $\\theta_j$ را کاهش دهید Regularization زمانی خوب عمل می‌کند که ویژگی های مفیدی داشته باشیم  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost3/",
	"title": "تابع هزینه قسمت سوم",
	"tags": [],
	"description": "",
	"content": "قسمت قبل دیدیم که با داشتن فقط یک پارامتر برای تابع فرضیه، نمودار تابع هزینه یا همان $J$ به صورت سهمی بود. اگر دو پارامتر داشته باشیم باز هم به صورت سهمی است، اما سه بعدی و بسته به دیتای ما ممکن است به شکل زیر باشد:\nاما ما برای نمایش این تابع از شکل سه بعدی استفاده نمی‌کنیم‌، بلکه از نمودار های کانتور استفاده می‌کنیم!\nدر این نمودار ها هر یک از بیضی ها نشان دهنده مجموعه ای از نقاط است که مقادیر یکسانی در $J$ بر حسب $\\theta_0$ و $\\theta_1$ های مختلف دارند.\nمثالی از یک نمودار کانتور:\nمثلا نقطه قرمز روی نمودار کانتور سمت راست برابر است با: $ \\theta_1 = -0.15, \\theta_0 = 800 $\nاما همینطور که می‌بینیم خط حاصل از تابع فرضیه تناسب خوبی با دیتا های ما ندارد! به این خاطر که نقطه ما از مینیمم که کوچکترین بیضی است خیلی دور است!\nدر این نقطه جدید هم کاملا مینیمم نیست اما خیلی بهتر از قبلی است. باز هم خط حاصل از تابع فرضیه بر حسب مقادیر انتخابی برای دو پارامتر مسئله با داده های ما متناسب نیست \u0026hellip;\nدر واقع ما به الگوریتمی نیاز داریم که برای ما مقادیر $\\theta_0$ و $\\theta_1$ را در حالتی که تابع $J$ مینیمم است بیابد.\nکه پاسخ ما گرادیان کاهشی یا همان Gradient Descent است !\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/cost-function-overfitting/",
	"title": " تابع هزینه در Overfitting",
	"tags": [],
	"description": "",
	"content": "اگر تابع فرضیه ما مشکل overfitting دارد، ما می‌توانیم وزن بعضی از بخش های تابع فرضیه را با افزایش هزینه آن ها کاهش دهیم:\nتصور کنید که تابع زیر را درجه ۲ (quadratic) تر کنیم: $$ \\theta_0 + \\theta_1x + \\theta_2 x^2 + \\theta_3 x^3 +\\theta_4 x^4 $$\nما می‌خواهیم تاثیر $\\theta_3 x^3$ و $\\theta_4 x^4$ را از بین ببریم ، بدون اینکه از شر این ویژگی ها خلاص شویم یا فرم تابع فرضیه خود را تغییر دهیم، ما می‌توانیم تابع هزینه خود را اصلاح کنیم:\n$$ min_\\theta \\frac{1}{2m} \\sum_{i = 1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 + 1000 \\cdot \\theta_3 ^2 + 1000 \\cdot \\theta_4 ^ 2 $$\nما اینجا در انتها دو بخش اضافه کرده ایم تا هزینه $\\theta_3$ و $\\theta_4$ را افزایش دهیم. حالا برای اینکه تابع هزینه به صفر نزدیک شود، ما باید مقادیر $\\theta_3$ و $\\theta_4$ را به صفر نزدیک کنیم.\nاین کار به خوبی مقادیر $\\theta_3 x^3$ و $\\theta_4 x^4$ را در تابع هزینه ما کاهش می‌هد.\nدر نتیجه می‌بینیم که فرضیه جدید (که توسط منحنی صورتی نشان داده شده است) مانند یک تابع درجه دوم به نظر می‌رسد، و به خاطر اصلاحات در $\\theta_3 x^3$ و $\\theta_4 x^4$ باداده ها تناسب بهتری دارد.\nو برای جمع بندی می‌توانیم بنویسیم: $$ min_\\theta \\frac{1}{2m} \\sum_{i = 1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j = 1}^n \\theta_j ^ 2 $$\nلامبدا ($\\lambda$) پارامتر منظم سازی (regularization parameter) است، تعیین می‌کند که هزینه پارامتر های تتا ما چه قدر باید زیاد شود.\nبا استفاده از تابع هزینه بالا ما می‌توانیم خروجی تابع فرضیه خود را صافکاری کنیم تا وضعیت overfitting را کاهش دهیم.\nاگر پارامتر لامبدا بسیار بزرگ انتخاب شود، ممکن است تابع ما را بیش از حد صافکاری کند و باعث underfitting شود!\nحالا به نظر شما چه اتفاقی می‌افتد اگر لامبدا $0$ یا خیلی کوچک انتخاب شود ؟\n  برای پاسخ کلیک کن   باید پر بشه\n  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient1/",
	"title": "گرادیان کاهشی قسمت اول",
	"tags": [],
	"description": "",
	"content": "تعریف گرادیان کاهشی | Gradient Descent گرادیان کاهشی را برای مینیمم کردن تابع هزینه $J$ استفاده می‌کنیم. اما این الگوریتم تنها فقط در رگرسیون خطی کاربرد ندارد، بلکه در سایر قسمت های حوزه یادگیری ماشین نیز استفاده می‌شود.\nمراحل کار به این شکل است:\nبا حدس های اولیه برای دو پارامتر $\\theta_0$ و $\\theta_1$ شروع می‌کنیم، مثلا مقدار هر دو را در ابتدا $0$ تعیین می‌کنیم.\nو سپس مقادیر $\\theta_0$ و $\\theta_1$ را به صورت جزئی تغییر می‌دهیم تا تابع $J$ کاهش یابد، تا زمانی که به مینیمم کلی یا محلی برسیم.\nبرای درک بهتر فرض کنید موتور سواری هستید بر روی سطح شکل زیر و می‌خواهید به پایین ترین نقطه این سطح برسید!\nکه بسته به مقادیر پارامتر ها سفر خود را از یک نقطه بر روی این سطح شروع می‌کنید.\nشما در همه جهات میچرخید و اطرافتان را نگاه می‌کنید و سپس سعی می‌کنید مقدار کمی به پایین در یک جهت بروید و در سریع ترین زمان به پایین برسید. بنابراین به کدام جهت باید بروید ؟!\nاگر از بالاترین نقطه شکل زیر حرکت کنید به این نقطه نهایی در کف سطح می‌رسید.\nاما اگر نقطه شروع را کمی از سمت راست شروع کرده بودید مسیرتان به این شکل میشد.\nکه این ویژگی گرادیان کاهشی است!\nو اما این تعریف ریاضی الگوریتم گرادیان کاهشی است:\nقرار است به صورت مکرر این کار را ادامه بدهیم تا به نقطه مینیمم برسیم!، اما اجازه دهید با مثال موتور قضیه را باز کنیم!\nاینجا $\\alpha$ / آلفا یا همان نرخ یادگیری شبیه به گاز موتور ما است که تعیین می‌کند میزان بزرگی حرکت ما به پایین چه قدر باشد.\nعبارت مشتق $\\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) $ نیز برای ما شبیه به فرمان موتور است که تعیین کننده جهت حرکت خواهد بود.\nاما نکته ی دیگری نیز در گرادیان کاهشی وجود دارد تغییر مقدار $\\theta_0$ و $\\theta_1$ در هر بار در فرمول باید به صورت پیوسته انجام بشود!، یعنی ابتدا مقادیر حساب شود و سپس به مقادیر بعد از انجام محاسبه تغییر کند:\nاما به نظر شما کدام درست است ؟!\n  برای پاسخ کلیک کن   جواب درست شکل سمت جپ است، زیرا دو پارامتر هم زمان و پشت سر هم مقادیرشان تغییر می‌کند، درحالی که در شکل سمت راست ابتدا $\\theta_0$ تغییر می‌کند و بعد از آن در مرحله بعد برای محاسبه $\\theta_1$ از مقدار جدید و تغییر داده شده $\\theta_0$ استفاده می‌شود.\n  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/regularized-linear-regression/",
	"title": "رگرسیون خطی منظم",
	"tags": [],
	"description": "",
	"content": "ما می‌توانیم regularization را هم برای رگرسیون خطی و هم برای رگرسیون لجستیک استفاده کنیم. که اینجا ابتدا رگرسیون خطی را بررسی می‌کنیم.\nGradient Descent گرادیان کاهشی را اصلاح می‌کنیم تا $\\theta_0$ را از بقیه پارامتر ها جدا کنیم، زیرا نمی‌خواهیم تاثیر $\\theta_0$ را کاهش دهیم و از بین ببریم:\n$$ \\begin{align*} \u0026amp; \\text{Repeat}\\ \\lbrace \\newline \u0026amp; \\ \\ \\ \\ \\theta_0 := \\theta_0 - \\alpha\\ \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \\newline \u0026amp; \\ \\ \\ \\ \\theta_j := \\theta_j - \\alpha\\ \\left[ \\left( \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\right) + \\frac{\\lambda}{m}\\theta_j \\right] \u0026amp;\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ j \\in \\lbrace 1,2\u0026hellip;n\\rbrace\\newline \u0026amp; \\rbrace \\end{align*} $$\nقسمت $\\frac{\\lambda}{m}\\theta_j$ منظم سازی ما را انجام می‌دهد. و با یک مقدار دستکاری می‌توانیم $\\theta_j$ را به این صورت نشان دهیم:\n$$ \\theta_j := \\theta_j(1 - \\alpha \\frac{\\lambda}{m} ) - \\alpha \\frac{1}{m} \\sum_{i = 1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j ^ {(i)} $$\nقسمت اول معدله یعنی $1 - \\alpha \\frac{\\lambda}{m}$ همیشه کم از $1$ خواهد بود، و به طور چشمی می‌بینیم که مقدار $\\theta_j$ را در هر بروزرسانی کمتر می‌کند.\nتوجه داشته باشید که قسمت دوم دقیقا مثل قبل است.\nNormal Equation حالا منظم سازی را با یک روش جایگزین و بدون نیاز به تکرار (non-iterative) یعنی معادله نرمال بررسی می‌کنیم.\nبرای این کار معادله ما شبیه به معادله اصلی است، با این تفاوت که یک بخش جدید در داخل پرانتز اضافه می‌کنیم:\n$$ \\begin{align*}\u0026amp; \\theta = \\left( X^TX + \\lambda \\cdot L \\right)^{-1} X^Ty \\newline\u0026amp; \\text{where}\\ \\ L = \\begin{bmatrix} 0 \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\newline \u0026amp; 1 \u0026amp; \u0026amp; \u0026amp; \\newline \u0026amp; \u0026amp; 1 \u0026amp; \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \\ddots \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; 1 \\newline\\end{bmatrix}\\end{align*} $$\nL یک ماتریس است که به صورت مورب از قسمت بالا سمت چپ با $0$ شروع شده و تا انتهای بخش مورب $1$ است. و سایر خانه های ماتریس نیز مقدار $0$ دارند، که ابعاد آن (n+1)*(n+1) است.\nدر واقع یک ماتریس همانی (identity matrix) است، (اگر چه که شامل $x_0$ نمی‌شود) که در عدد حقیقی لامبدا ضرب شده است.\nبه خاطر بیاورید که:\n$$ \\text{if } m \u0026lt; n \\text{ then } X^TX $$ وارون ناپذیر (non-invertible) بود. اگر چه وقتی ما قسمت $\\lambda . L $ را اضافه می‌کنیم، سپس $ X^TX + \\lambda . L$ وارون پذیر می‌شود.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient2/",
	"title": "گرادیان کاهشی قسمت دوم",
	"tags": [],
	"description": "",
	"content": "در قسمت قبل گرادیان کاهشی را به این صورت معرفی کردیم، در این قسمت می‌خواهیم به توضیح آلفا و عبارت مشتق بپردازیم. اما برای برای درک بهتر می‌خواهیم با یک مثال ساده تر تابعی با یک پارامتر را مینیمم کنیم، یعنی فرض می‌کنیم تابع هزینه $J$ فقط یک پارامتر دارد.\nتصور کنید تابع $J$ زیر را با پارامتر تتا یک در این نقطه داریم، و از این نقطه کارمان را شروع می‌کنیم.\nکاری که عبارت مشتق می‌کند این است که تانژانت این نقطه را می‌گیرد، مثل این خط قرمز که با تابع مماس است. پس از این عبارت شیب خط را به دست می‌آوریم و می‌بینیم که در اینجا شیب خط قرمز ما مثبت است، پس متوجه شدیم که در این شکل حاصل مشتق مثبت است، همچنین نرخ یادگیری نیز همیشه عددی مثبت است.\nبنابراین تغییر $\\theta$ طبق فرمول به این صورت است: $$ \\theta_1 := \\theta_1 - \\alpha \\text{ } \\cdot \\text{ (positive number)} $$\nبنابراین داریم $\\theta$ منهای مقداری مثبت که این باعث می‌شود $\\theta$ ما کاهش یابد و به سمت چپ برود!\nهمان چیزی که می‌خواهیم، نزدیک شدن به مینیمم!\nو اگر طبق مثال قبل از این نقطه جدید شروع کنیم شیب خط ما منفی خواهد شد، یعنی مشتق منفی!\nبنابراین تغییر تتا طبق فرمول به این صورت است: $$ \\theta_1 := \\theta_1 - \\alpha \\text{ } \\cdot \\text{ (negative number)} $$\nمی‌بینیم که داریم تتا یک منهای مقداری منفی که این باعث می‌شود تتا ما افزایش یابد و به سمت راست برود!\nدر شکل سمت چپ مقدار آلفا بسیار کوچک است که باعث می‌شود گرادیان کاهشی خیلی کند تر به مینیمم برسد یعنی نیاز داریم قدم های بیشتری به پایین برداریم.\nاما در شکل راست آلفا بسیار بزرگ تر است که باعث شده گرادیان کاهشی هیچ وقت به مینیمم نرسد. یعنی گرادیان کاهشی ما همگرا نیست بلکه واگرا است!\nحالا شما جواب بدید!\nچه اتفاقی می‌افتد اگر در شکل زیر پارامتر $\\theta_1$ در نقطه مینیمم باشد؟!\n  برای دیدن پاسخ کلیک کن   اگر تصور کنیم که تتا در این مینیمم موضعی است، و ما می‌دانیم که عبارت مشتق ما در این حالت 0 است، و در واقع داریم:\n$$ \\theta_1 := \\theta_1 - \\alpha \\text{ } \\cdot 0$$\nو این به این معنی است که اگر در مینیمم موضعی باشیم، مقدار $\\theta_1$ بدون تغییر باقی می‌ماند!\n  گرادیان نزولی به مینیمم موضعی ختم می‌شود حتی زمانی که نرخ یادگیری یا همان آلفا ثابت باشد!\nزیرا در هر بار انجام الگوریتم شیب خط حاصل از عبارت مشتق ملایم تر از حالت دفعه قبلش است و همینطور که به مینیمم نزدیک تر می‌شویم، مشتق نیز به صفر میل می‌کند. بنابراین هر بار مشتق کوچک تر می‌شود و این باعث می‌شود قدم ها هر بار کوچک تر و کوچک تر شوند. به این خاطر نیازی نیست در طول زمان مقدار آلفا را کاهش دهیم!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/regularized-logistic-regression/",
	"title": "رگرسیون لجستیک منظم",
	"tags": [],
	"description": "",
	"content": "می‌توانیم Logistic Regression را به روشی مشابه رگرسیون خطی منظم سازی کنیم، که در نتیجه می‌توانیم از overfitting پرهیز کنیم.\nCost Function به یاد بیاورید که تابع هزینه ما برای رگرسیون لجستیک به این شکل بود:\n$$ J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^m [y^{(i)} log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\\theta(x^{(i)}) )]\n$$\nما می‌توانیم این معادله را با اضافه کردن یک قسمت به انتهای آن منظم کنیم:\n$$ J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^m [y^{(i)} log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\\theta(x^{(i)}) )] + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\theta_j ^ 2 $$\nسیگما دوم یعنی $\\sum_{j=1}^n \\theta_j ^ 2 $ به معنای حذف بایاس پارامتر $\\theta_0$ است، یعنی وکتور $\\theta$ که از 0 تا n ایندکس شده است(n+1 مقدار را از $\\theta_0$ تا $\\theta_n$ نگه می‌دارد) ، سیگما صراحتا $\\theta_0$ را با شروع از 1 تا n رد می‌کند.\nبنابراین، هنگام محاسبه معادله، باید دو معادله زیر را به طور مداوم به روز رسانی کنیم:\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient3/",
	"title": "گرادیان کاهشی قسمت سوم",
	"tags": [],
	"description": "",
	"content": "در این قسمت گرادیان کاهشی را با تابع هزینه ترکیب می‌کنیم و الگوریتم رگرسیون خطی را به دست می‌آوریم. تا اینجای کار به این ها رسیدیم:\nاینجا می‌خواهیم از گرادیان کاهشی برای مینیمم کردن تابع هزینه استفاده کنیم! ابتدا تابع $J$ را در الگوریتم گرادیان جاگذاری می‌کنیم و \u0026hellip;\nبا محاسبه عبارت مشتق جزئی در گرادیان کاهشی برای دو پارامتر $\\theta_0$ و $\\theta_1$ خواهیم داشت:\n$$ \\theta_0, j = 0: \\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) $$\n$$ \\theta_1, j = 1: \\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x^{(i)} $$\nبه الگوریتم گرادیان کاهشی بر‌ می‌گردیم و جایگذاری، و در واقع به الگوریتم رگرسیون خطی می‌رسیم!\nدر قسمت اول گرادیان کاهشی در مثال موتور سوار دیدیم که بسته به اینکه از کجا شروع کنیم ممکن است که به مینیمم موضعی برسیم! اما تابع هزینه برای رگرسیون خطی همیشه تابعی سهمی مانند مثل این است:\nاین تابع محدب مینیمم موضعی ندارد، و فقط یک مینیمم کلی دارد. یعنی گرادیان کاهشی برای این تابع هزینه همیشه به نقطه بهینه می‌رسد! و بنابراین گرادیان نزولی را در عمل برای داده خانه ها به به این صورت می‌بینیم، که نتیجه تناسب خوبی دارد:\nو حالا می‌توانید از آن استفاده کنید تا قیمت خانه ها را برای دوستانتان پیشبینی کنید!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]