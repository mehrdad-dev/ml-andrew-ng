[
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/",
	"title": "دوره یادگیری ماشین دانشگاه استنفورد به فارسی",
	"tags": [],
	"description": "Andrew Ng دوره ماشین لرنینگ پروفسور",
	"content": "دوره یادگیری ماشین دانشگاه استنفورد به فارسی در حال تکمیل است \u0026hellip;\n --  --           ℹ️ درباره دوره این دوره به طور رایگان توسط Andrew Ng استادیار دانشگاه استنفورد تهیه شده است، و ما اینجا به طور خلاصه و مفید این دوره ارزشمند را به فارسی روان قرار داده ایم.\nبرای مطالعه از قسمت منو هفته مورد نظر را انتخاب کنید 📚\nبرای دسترسی به محتوای اصلی دوره می‌توانید از روش های زیر اقدام کنید:\n  تماشای ویدئو ها از طریق یوتیوب\n  دسترسی به دوره از طریق کورسرا\n  برای مشاهده بهتر فرمول های ریاضی از کامپیوتر استفاده کنید! ممکن است با گوشی درست نمایش داده نشود.\n 👊 مشارکت اگر علاقه به مشارکت در این کار دارید از قبیل:\n کامل تر کردن محتوای مطالب بهتر کردن ترجمه مطالب کامل کردن بخش منابع مفید و غیره   گیت هاب وب سایت برای مشارکت    گیت هاب زیرنویس های این دوره به فارسی   -- و برای ارتباط بیشتر  ایمیل بزنید!  \nبا خبر شدن از تغییرات و مطالب جدید  اشتراک خبرنامه  \nبه پاس قدردانی از مشارکت شما برای تولید محتوای آزاد و کمک به جامعه فارسی زبان در صفحه درباره از شما تشکر خواهد شد ❤️\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/",
	"title": "   هفته اول ",
	"tags": [],
	"description": "",
	"content": "در این هفته به صورت کلی با مفهوم خود یادگیری ماشین و دو دسته اصلی از انواع مسائل آن آشنا می‌شویم. به سراغ رگرسیون خطی تک متغیره می‌رویم و با استفاده از تابع هزینه و گرادیان کاهشی سعی در بهتر کردن نتایج داریم.\n یادگیری ماشین چیست؟   یادگیری با نظارت چیست؟   یادگیری بدون نظارت چیست؟   رگرسیون خطی با یک متغیر   تابع هزینه قسمت اول   تابع هزینه قسمت دوم   تابع هزینه قسمت سوم   گرادیان کاهشی قسمت اول   گرادیان کاهشی قسمت دوم   گرادیان کاهشی قسمت سوم   فایل های هفته اول   "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week8/unsupervised-learning-introduction/",
	"title": "مقدمه یادگیری بدون نظارت",
	"tags": [],
	"description": "",
	"content": "یادگیری بدون نظارت در تضاد با یادگیری با نظارت است، زیرا از یک مجموعه آموزشی بدون لیبل استفاده می‌کند.\nبه عبارت دیگر، ما بردار $y$ را به عنوان نتایج مورد انتظار نداریم، فقط مجموعه داده ای از ویژگی ها داریم که می‌خواهیم ساختاری در آن ها پیدا کنیم.\nطبقه بندی برای موراد زیر خوب است:\n تقسیم بندی بازار تحلیل شبکه های اجتماعی سازماندهی خوشه های رایانه ای تجزیه و تحلیل داده های نجومی  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week7/optimization-objective/",
	"title": "بهینه سازی هدفمند",
	"tags": [],
	"description": "",
	"content": "ماشین بردار پشتیبان (SVM) یکی دیگر از الگوریتم های یادگیری ماشین با نظارت است که گاهی تمیزتر و قدرتمندتر عمل می کند. اگر به خاطر بیاورید، ما در رگریسیون لجستیک از ضوابط زیر استفاده می کردیم:\n$$ if\\hspace{0.3cm} y=1,\\hspace{0.2cm} then \\hspace{0.3cm} h_\\theta(x)\\approx 1 \\hspace{0.3cm} and \\hspace{0.3cm}\\theta\\ ^ T x \\gg 0 $$\n$$ if\\hspace{0.3cm} y=0,\\hspace{0.2cm} then \\hspace{0.3cm} h_\\theta(x)\\approx 0 \\hspace{0.3cm} and \\hspace{0.3cm}\\theta\\ ^ T x \\ll 0 $$\nتابع هزینه را برای رگریسیون لجستیک (نامنظم) به خاطر بیاورید:\n$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m -y^{(i)} \\hspace{0.1cm} log(h_\\theta(x^{(i)})) - (1 - y^{(i)}) \\hspace{0.1cm} log(1 - h_\\theta(x^{(i)}) ) $$\n$$ = \\frac{1}{m} \\sum_{i=1}^m -y^{(i)} \\hspace{0.1cm} log(\\frac{1}{1+e^ {-\\theta\\ ^ T x^{(i)} }}) - (1 - y^{(i)}) \\hspace{0.1cm} log(\\frac{1}{1+e^ {-\\theta\\ ^ T x^{(i)} }} ) $$\nبرای ساخت ماشین بردار پشتیبان، اولین عبارت تابع هزینه را تغییر می دهیم:\n$$ -log(h_\\theta(x))=-log(\\frac{1}{1+e^ {-\\theta\\ ^ T x}}) $$\nبنابراین هنگامی که $ \\theta^{T}x $ (که از این به بعد آن را z می نامیم) بزرگتر از 1 شود، خروجی 0 است. علاوه بر این، برای zهای کوچکتر از 1، به جای منحنی سیگموئید باید از یک خط راست نزولی استفاده کنیم.\n(در متون ادبی به آن تابع خطای Hinge می گویند https://en.wikipedia.org/wiki/Hinge_loss)\nبه طور مشابه، عبارت دوم تابع هزینه را تغییر می دهیم:\n$$ -log(1- h_\\theta(x))=-log(1- \\frac{1}{1+e^ {-\\theta\\ ^ T x }}) $$\nبنابراین وقتی که z کمتر از 1- است، خروجی 0 می شود. برای مقادیر بزرگتر از 1- هم آن را تغییر می دهیم و از خط راست صعودی به جای منحنی سیگموئید استفاده می کنیم.\nاین عبارات نشان دهنده $cost_1 z$ و $cost_0 z$ هستند (به ترتیب، $cost_1 z$ هزینه طبقه بندی برای زمانی که $y=1$ و $cost_0 z$ هزینه طبقه بندی برای $y=0$ است) و ما آن ها را به صورت زیر تعریف می کنیم (k یک ثابت دلخواه است که بزرگی شیب خط را نشان می دهد):\n$$ z = \\theta^{T} x $$ $$ cost_0(z) = max(0,k(1 + z)) $$ $$ cost_1(z) = max(0,k(1 - z)) $$\nعبارت کامل تابع هزینه را در رگریسیون لجستیک (منظم) به یاد بیاورید:\n$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m y^{(i)} (-log(h_\\theta(x^{(i)}))) + (1 - y^{(i)}) (-log(1 - h_\\theta(x^{(i)}) )) + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\theta_j ^ 2 $$\nتوجه داشته باشید که در معادله بالا علامت منفی در کل عبارت پخش شده است.\nما با جایگزین کردن $cost_0 z$ و $cost_1 z$ در معادله، آن را به تابع هزینه ماشین های بردار پشتیبان تبدیل می کنیم:\n$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m y^{(i)} cost_1(\\theta^Tx^{(i)}) + (1 - y^{(i)}) \\hspace{0.1cm} cost_0(\\theta^Tx^{(i)}) + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\theta_j ^ 2 $$\nمی توانیم با ضرب کردن m در معادله کمی آن را بهینه تر کنیم (بنابراین عامل m در مخرج حذف می شود). توجه داشته باشید که این کار تاثیری در بهینه سازی ما ندارد چون ما یک عدد ثابت مثبت را در معادله ضرب کردیم (برای مثال، مینیمم $(u - 5)^2 + 1$ ، 5 است. با ضرب کردن آن در 10 تبدیل به $10(u - 5)^2 + 10$ می شود که باز هم مینیمم آن 5 است).\n$$ J(\\theta) = \\sum_{i=1}^m y^{(i)} cost_1(\\theta^Tx^{(i)}) + (1 - y^{(i)}) \\hspace{0.1cm} cost_0(\\theta^Tx^{(i)}) + \\frac{\\lambda}{2} \\sum_{j=1}^n \\theta_j ^ 2 $$\nبه علاوه، طبق قرارداد، ما برای منظم سازی از C به جای $\\lambda$ استفاده می کنیم. مانند عبارت زیر:\n$$ J(\\theta) =C \\sum_{i=1}^m y^{(i)} cost_1(\\theta^Tx^{(i)}) + (1 - y^{(i)}) \\hspace{0.1cm} cost_0(\\theta^Tx^{(i)}) + \\frac{1}{2} \\sum_{j=1}^n \\theta_j ^ 2 $$\nاین کار مانند این است که معادله را در $C =\\frac{1}{\\lambda}$ ضرب کنیم بنابراین هنگام بهینه سازی نتیجه تغییر نمی کند. حالا، برای منظم سازی بیشتر (یعنی کاهش overfitting)، C را کاهش می دهیم و زمانی که بخواهیم کم تر منظم سازی کنیم (یعنی کاهش underfitting)، C را افزایش می دهیم.\nدر نهایت، توجه داشته باشید که معادله فرضی ماشین بردار پشتیبان احتمال 0 یا 1 بودن y را نشان نمی دهد (مانند چیزی که در معادله فرضی رگریسیون لجستیک داشتیم). در عوض، خروجی آن 0 یا 1 است. (اگر بخواهیم به طور تخصصی صحبت کنیم، این یک تابع تفکیکی است.)\n$$ h_\\theta(x)= \\begin{cases} 1 \u0026amp; if \\hspace{0.3cm} \\theta^T x\\ge 0\\newline 0 \u0026amp; otherwise \\end{cases} $$\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/evaluating-hypothesis/",
	"title": "ارزیابی فرضیه",
	"tags": [],
	"description": "",
	"content": "خطاهای موجود در پیش بینی هایتان را با استفاده از روش های زیر می‌توانید عیب یابی کنید:\n جمع آوری داده های آموزشی بیشتر استفاده از مجموعه های ویژگی کوچکتر امتحان کردن ویژگی های اضافی استفاده از ویژگی های چند جمله ای افزایش یا کاهش مقدار $\\lambda$  برای عیب یابی یکی از راه های ذکر شده در بالا را به صورت تصادفی انتخاب نکنید، در بخش های بعدی تکنیک هایی برای انتخاب یکی از راه حل ها را بررسی می‌کنیم.\n ارزیابی یک فرضیه یک فرضیه ممکن است برای یک نمونه آموزشی مقدار خطای کمی داشته باشد اما همچنان نادرست باشد (به دلیل overfitting).\nیک مجموعه داده از نمونه های آموزشی را می‌توانیم به دو مجموعه جدا تقسیم کنیم:\n۱. مجموعه آموزش\n۲. مجموعه تست\nروش جدید با استفاده از این دو مجموعه به صورت زیر خواهد بود:\n  یادگیری $\\Theta$ و کمینه کردن مقدار $J_{train}\\left ( \\Theta \\right )$ با استفاده از مجموعه آموزشی\n  محاسبه خطای مجموعه تست $J_{test}\\left ( \\Theta \\right )$\n  محاسبه خطای مجموعه تست   برای رگرسیون خطی: $$ J_{test\\left ( \\Theta \\right )} = \\frac{1}{2m_{test}}\\sum_{i=1}^{m_{test}}\\left ( h_{\\Theta }\\left ( x_{test}^{(i) } \\right ) - y_{test}^{(i)} \\right )^{2} $$\n  برای طبقه بندی - خطای طبقه بندی غلط: $$ err(h_\\Theta(x),y) = \\begin{matrix} 1 \u0026amp; \\mbox{if } h_\\Theta(x) \\geq 0.5\\ and\\ y = 0\\ or\\ h_\\Theta(x) \u0026lt; 0.5\\ and\\ y = 1\\newline 0 \u0026amp; \\mbox otherwise \\end{matrix} $$\n  این به ما یک نتیجه دودویی به صورت 0 یا 1 می‌دهد، که بر اساس طبقه بندی غلط است.\nمیانگین خطای آزمون، برای مجموعه داده آزمون به این صورت است: $$ Test Error = \\frac{1}{m_{test}}\\sum_{i=1}^{m_{test}}err(h_{\\Theta }(x_{test}^{(i)}), y_{test}^{(i)}) $$\nکه این به ما نسبت داده های آزمونی که در طبقه بندی غلط قرار دارند را می‌دهد.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week5/nn-cost-function/",
	"title": "تابع هزینه شبکه عصبی",
	"tags": [],
	"description": "",
	"content": "اجازه دهید برای شروع چند متغیر تعریف کنیم:\n   متغیر      $L$ تعداد کل لایه ها در شبکه عصبی   $s_l$ تعداد گره ها در لایه $l$ ام (بدون احتساب گره بایاس)   $K$ تعداد کلاس های خروجی    به یاد بیاورید که در شبکه های عصبی ممکن است تعداد گره های خروجی زیادی داشته باشیم. ما $h_\\Theta(x)_k$ را به عنوان یک فرضیه در نظر می‌گیریم، که منجر به خروجی $k^{th}$ می‌شود.\nتابع هزینه ما برای شبکه های عصبی تعمیم تابعی است، که برای رگرسیون لجستیک در هفته سوم استفاده می‌کردیم.\nبه عنوان یادآوری، تابع هزینه برای رگرسیون لجستیک منظم به این صورت بود:\n$$ J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^m [y^{(i)} log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\\theta(x^{(i)}) )] + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\theta_j ^ 2 $$\nکه برای شبکه های عصبی کمی پیچیده تر خواهد شد: $$ \\begin{gather*} J(\\Theta) = - \\frac{1}{m} \\sum_{i=1}^m \\sum_{k=1}^K \\left[y^{(i)}_k \\log ((h_\\Theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\\log (1 - (h_\\Theta(x^{(i)}))_k)\\right] + \\frac{\\lambda}{2m}\\sum_{l=1}^{L-1} \\sum_{i=1}^{s_l} \\sum_{j=1}^{s_{l+1}} ( \\Theta_{j,i}^{(l)})^2\\end{gather*} $$\nفقط یک ‌ذره 😂😂😅  ما برای چند گره خروجی خود، چند جمع تو در تو اضافه کرده ایم. در قسمت اول معادله قبل از براکت ها، ما یک جمع جدید برای تعداد گره های خروجی داریم: $ \\sum_{k=1}^K $\nدر قسمت منظم سازی بعد از براکت ها، باید چند ماتریس تتا را حساب کنیم.\nتعداد ستون ها در هر ماتریس تتای ما برابر است با تعداد گره های موجود در لایه ی آن (به همراه گره بایاس)، و تعداد ردیف های آن برابر است با تعداد گره های موجود در لایه بعدی اش (به استثنای گره بایاس).\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/non-linear-hypotheses/",
	"title": "فرضیه غیر خطی",
	"tags": [],
	"description": "",
	"content": "انجام رگرسیون لجستیک با مجموعه ای پیچیده از داده ها و ویژگی های زیاد، کار بسیار دشواری است. تصور کنید فرضیه ای با ۳ ویژگی دارید به همراه تمام جملات درجه ۲ آن:\n$$ g(\\theta_0 + \\theta_1 x_1^2 + \\theta_2 x_1 x_2 + \\theta_3 x_1 x_3 + \\theta_4 x_2 ^2 + \\theta_5 x_2 x_3 + \\theta_6 x_3 ^2 ) $$ می‌بینیم که ۶ ویژگی به ما می‌دهد.\nروشی دقیق برای محاسبه تعداد ویژگی ها: $ \\frac{(n + r - 1)!}{r!(n-1)!} $\nکه برای مثال بالا به این صورت خواهد بود: $ \\frac{(3 + 2 - 1)!}{2!(3-1)!} = \\frac{4!}{4} = 6 $\nبرای ۱۰۰ ویژگی اگر بخواهیم آن ها را درجه ۲ کنیم، خواهیم داشت: $ \\frac{(100 + 2 - 1)!}{2!(100-1)!} = 5050 $ ویژگی جدید.\nما می‌توانیم رشد تعداد ویژگی هایی را که با تمام جملات درجه ۲ به دست می‌آوریم را به صورت $ O(\\frac{n^2}{2}) $ تقریب کنیم. و اگر بخواهیم تمام جملات درجه ۳ را در فرضیه خود داشته باشیم، ویژگی ها به صورت مرتبه زمانی $ O(n^3) $ رشد می‌کنند.\nمی‌بینیم که با افزایش تعداد ویژگی های ما، تعداد ویژگی های درجه ۲ و یا درجه ۳ به سرعت افزایش می‌یابند\nمثال:\nتصور کنید که داده های شما مجموعه ای از عکس های $50 \\times 50$ پیکسل سیاه سفید هستند، و هدف شما طبقه بندی است برای اینکه متوجه بشویم کدام یک از آن ها ماشین است. تعداد ویژگی های ما اگر هر جفت پیکسل را با هم مقایسه کنیم برابر است با: $2500$ و اگر عکس های ما به جای سیاه سفید بودن RGB باشند تعداد ویژگی ها برابر خواهد بود با: $ 7500 $\nحالا تصور کنید که باید یک تابع فرضیه درجه ۲ بسازیم، که تعداد کد ویژگی های ما در حدود $ \\frac{2500^2}{2} = 3125000 $ خواهد بود!\nکه بسیار غیر عملی است.\nشبکه های عصبی راه دیگری را برای انجام مسائل یادگیری ماشین ارائه می‌دهد، زمانی که ما فرضیه ای پیچیده با تعداد زیادی ویژگی داریم!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/linear-regression-many-variable/",
	"title": "رگرسیون خطی چند متغیره",
	"tags": [],
	"description": "",
	"content": "توی این هفته قراره در مورد رگرسیون خطی با چندین متغیر صحبت کنیم!\nمثلا داده ای شبیه به این برای خانه ها را فرض کنید:\n   نماد      $m$ تعداد کل سطر های جدول داده ها   $n$ تعداد ویژگی ها یا همان متغیر ها   $x^{(i)}$ i امین ردیف از جدول شامل متغیر ها   $x_j^{(i)}$ مقدار موجود در ردیف i ام و ستون متغیر j    بنابراین برای تابع فرضه داریم: $h_\\theta = \\theta_0 + \\theta_1 + \\theta_2x + \u0026hellip; + \\theta_nx$\nبا مقدار پیشفرض برای $x_0$ که برابر با مقدار $1$ است.\nکه می‌توانیم برای محاسبه این مقدار از ضرب ترانهاده بردار مقادیر تتا و بردار x ها استفاده کنیم:\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/what-is-ml/",
	"title": "یادگیری ماشین چیست؟",
	"tags": [],
	"description": "",
	"content": "دو تعریف از یادگیری ماشین ارائه شده است:\nArthur Samuel: رشته مطالعاتی که به کامپیوتر ها این توانایی را می‌دهد که بدون برنامه نویسی صریح یاد بگیرند.\nتوجه: این یک تعریف قدیمی و غیر رسمی است!\n اما تعریفی مدرن تر \u0026hellip;\nTom Mitchell: به یک برنامه کامپیوتری گفته می‌شود که: برای یادگیری از تجربه E با توجه به برخی از وظایف به عنوان T و اندازه گیری عملکرد با P اگر عملکرد وظیفه T با استفاده از P اندازه گیری شود با استفاده از تجربه E بهبود یابد.\nمثلا بازی چکرز!    نماد      E تجربه بار ها بازی کردن   T انجام بازی چکرز   P احتمال اینکه برنامه در بازی بعد برنده شود    به طور کلی هر مسئله یادگیری ماشین را میتوان به دو دسته یادگیری با نظارت و یادگیری بدون نظارت تقسیم کرد.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/",
	"title": " هفته دوم",
	"tags": [],
	"description": "",
	"content": "در این هفته سراغ رگرسیون خطی چند متغیره می‌رویم و با فوت و فن هایی آشنا می‌شویم که برای بهتر کردن نتایج ما قابل استفاده است.\n رگرسیون خطی چند متغیره   گرادیان کاهشی چند متغیره   مقیاس بندی ویژگی   اشکال زدایی گرادیان   رگرسیون چند جمله ای   معادله نرمال   فایل های هفته دوم   "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/",
	"title": " هفته سوم",
	"tags": [],
	"description": "",
	"content": "این هفته با رگرسیون لجستیک آشنا می‌شویم که برای طبقه بندی از آن استفاده می‌کنیم.\nهم چنین با منظم سازی یا منظم سازی برای مدل مان آشنا می‌شویم، تا با استفاده از آن از مشکل overfit پرهیز کنیم.\n طبقه بندی   تابع هزینه   ساده شده تابع هزینه و گرادیان کاهشی   بهینه سازی پیشرفته   طبقه بندی چند کلاسه   مشکل Overfitting   تابع هزینه در Overfitting   رگرسیون خطی منظم   رگرسیون لجستیک منظم   فایل های هفته سوم   "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week7/large-margin-intuition/",
	"title": "درک حاشیه اطمینان زیاد",
	"tags": [],
	"description": "",
	"content": "یک راه مفید برای فکر کردن راجع به ماشین های بردار پشتیبان این است که آن ها را به عنوان طبقه بندی کننده هایی که حاشیه اطمینان زیادی دارند در نظر بگیرید.\n$$ if \\hspace{0.3cm} y=1,\\hspace{0.1cm} we\\hspace{0.2cm} want \\hspace{0.3cm} \\theta\\ ^ T x \\ge 1 \\hspace{0.3cm}(not\\hspace{0.1cm} just\\hspace{0.1cm} \\ge 0 ) $$\n$$ if \\hspace{0.3cm} y=0,\\hspace{0.1cm} we\\hspace{0.2cm} want \\hspace{0.3cm} \\theta\\ ^ T x \\le -1 \\hspace{0.3cm}(not\\hspace{0.1cm} just\\hspace{0.1cm} \u0026lt; 0 ) $$\nحالا زمانی که ثابت C را یک مقدار خیلی بزرگ در نظر بگیریم (برای مثال 100,000)، تابع بهینه سازی ما $\\theta$ را محدود می کند به طوری که معادله A (مجموع هزینه های هر نمونه) برابر 0 می شود. ما محدودیت زیر را برای $\\theta$ در نظر می گیریم:\n$$ \\theta\\ ^ T x \\ge 1 \\hspace{0.3cm} if \\hspace{0.3cm} y=1 \\hspace{0.3cm} and \\hspace{0.3cm} \\theta\\ ^ T x \\le -1 \\hspace{0.3cm} if \\hspace{0.3cm} y=0. $$\nاگر C خیلی بزرگ باشد، پارامترهای $\\theta$ را باید مطابق فرمول زیر انتخاب کنیم:\n$$ \\sum_{i=1}^m y^{(i)} \\hspace{0.1cm} cost_1(\\theta^T x)+(1- y^{(i)} ) \\hspace{0.1cm}cost_0(\\theta^T x)=0 $$\nکه تابع هزینه را به شکل زیر کاهش می دهد:\n$$ J(\\theta) = C.0+\\frac{1}{2} \\sum_{j=1}^n \\theta_j ^ 2 $$\n$$ =\\frac{1}{2} \\sum_{j=1}^n \\theta_j ^ 2 $$\nمرز تصمیم گیری را از رگریسیون لجستیک به یاد آوردید (خطی که نمونه های مثبت و منفی را از هم جدا می کرد). خصوصیت ویژه ای که مرز تصمیم گیری در ماشین های بردار پشتیبان دارد این است که تا جای ممکن، از نمونه های مثبت و منفی فاصله دارد.\nفاصله مرز تصمیم گیری تا نزدیک ترین نمونه، حاشیه اطمینان نامیده می شود. از آن جایی که ماشین های بردار پشتیبان این حاشیه را حداکثر می کنند، اغلب به آن ها طبقه بندی کننده با حاشیه اطمینان زیاد می گویند.\nماشین بردار پشتیبان نمونه های مثبت و منفی را با حاشیه اطمینان زیاد جدا می کند.\nاین حاشیه اطمینان زیاد تنها زمانی به دست میاید که C خیلی بزرگ باشد.\nداده ها زمانی به صورت خطی قابل جدا شدن هستند که یک خط راست بتواند نمونه های مثبت و منفی را از هم جدا کند.\nاگر ما داده های خارج از محدوده داریم که نمی خواهیم روی مرز تصمیم گیری ما اثر بگذارند، می توانیم C را کاهش دهیم.\nافزایش و کاهش C، به ترتیب مانند کاهش و افزایش $\\lambda$ است و می تواند مرز تصمیم گیری ما را ساده کند.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week8/k-means/",
	"title": "الگوریتم K-Means",
	"tags": [],
	"description": "",
	"content": "الگوریتم K-Means محبوب ترین و پرکاربردترین الگوریتم برای گروه بندی خودکار داده ها در زیر مجموعه های منسجم (اعضای آن به هم مربوط هستند) است.\n به طور تصادفی دو نقطه از مجموعه داده ها را به نام مرکز خوشه ای مقدار دهی می‌کنیم تخصیص خوشه: همه مثالها را به یکی از دو گروه تقسیم کنید بر اساس اینکه به کدام مرکز خوشه نزدیک است میانگین تمام نقاط داخل هر دو گروه مرکز خوشه ای را محاسبه کنید، سپس نقاط مرکز خوشه را به آن میانگین ها منتقل کنید مرحله ۲ و ۳ را دوباره اجرا کنید تا زمانی که خوشه های خود را پیدا کنید  متغیرهای اصلی ما عبارتند از:\n $K$ = تعداد خوشه ها مجموعه آموزشی = $x^{(1)}, x^{(2)}, \u0026hellip; , x^{(m)}$ به طوری که $x^{(i)} \\in \\mathbb{R} ^ n$  توجه داشته باشید که ما از عبارت $x ^ 0 = 1$ استفاده نخواهیم کرد.\nالگوریتم:\nRandomly initialize K cluster centroids mu(1), mu(2), ..., mu(K) Repeat: for i = 1 to m: c(i):= index (from 1 to K) of cluster centroid closest to x(i)‍ for k = 1 to K: mu(k):= average (mean) of points assigned to cluster k  حلقه for اول مرحله تخصیص خوشه یعنی مرحله ۲ است، یک بردار به اسم $c$ می‌سازیم که $c^{(i)}$ نمایانگر مرکزی است که به نمونه $x ^ {(i)}$ منتسب شده است.\nما می‌توانیم مرحله تخصیص خوشه را به ریاضی بنویسیم: $$ c^{(i)} = argmin _ k \\begin{Vmatrix} x^{(i)} - \\mu _ k \\end{Vmatrix} ^2 $$\nیعنی هر $c^{(i)}$ حاوی ایندکس مرکزی است که حداقل فاصله را تا $x^{(i)}$ دارد.\nطبق قرارداد، ما سمت راست معادله را به توان ۲ می‌رسانیم، که باعث می‌شود بار محاسباتی کاهش پیدا کند.\nبدون توان ۲: $$ \\begin{Vmatrix} x^{(i)} - \\mu _ k \\end{Vmatrix} = \\begin{Vmatrix} \\sqrt{ (x^{(i) _ 1 - \\mu _ {1 (k)}})^2 + (x^{(i) _ 2 - \\mu _ {2 (k)}})^2 + (x^{(i) _ 3 - \\mu _ {3 (k)}})^2 + \u0026hellip; } \\end{Vmatrix} $$\nبا توان ۲: $$ \\begin{Vmatrix} x^{(i)} - \\mu _ k \\end{Vmatrix} ^2 = \\begin{Vmatrix} (x^{(i) _ 1 - \\mu _ {1 (k)}})^2 + (x^{(i) _ 2 - \\mu _ {2 (k)}})^2 + (x^{(i) _ 3 - \\mu _ {3 (k)}})^2 + \u0026hellip; \\end{Vmatrix} $$\nبنابراین هدف از قرارداد توان ۲ محاسبه کمتر و دقیق تر است.\nحلقه for دوم همان مرحله ۳ است، جایی که هر مرکز را به میانگین گروه خود منتقل می‌کنیم.\nبه صورت رسمی تر ، معادله برای این حلقه به شرح زیر است:\n$$ \\mu _k = \\frac{1}{n} [ x^{(k _ 1)} + x^{(k _ 2)} + \u0026hellip; + x^{(k _ n)}] \\in \\mathbb{R} ^ n $$\nبه طوری که هر کدام از $x^{(k _ 1)} + x^{(k _ 2)} + \u0026hellip; + x^{(k _ n)}$ ها نمونه های آموزشی اختصاص داده شده به گروه $\\mu _k$ هستند.\nاگر یک مرکز خوشه ای دارید که 0 امتیاز به آن اختصاص داده شده است، می توانید آن مرکز را به طور تصادفی مجدداً در یک نقطه جدید تنظیم کنید. شما همچنین می توانید آن گروه خوشه را به سادگی از بین ببرید.\nبعد از تعدادی تکرار الگوریتم به همگرایی خواهید رسید، به طوری که تکرار های جدید تاثیری بر خوشه ها نمی‌گذارند!\nنکته ای در مورد خوشه های جدا نشده:\nبرخی از مجموعه های داده هیچ جدایی داخلی و ساختار طبیعی ندارند. K-mean هنوز هم می تواند داده های شما را به K زیر مجموعه تقسیم کند، بنابراین در این حالت نیز همچنان می‌تواند مفید باشد.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/model-selection/",
	"title": "انتخاب مدل",
	"tags": [],
	"description": "",
	"content": "فقط به این دلیل که یک الگوریتم یادگیری متناسب با مجموعه آموزشی ما است، به این معنی نیست که آن فرضیه خوبی است!\nمی‌تواند overfit شده باشد، که در نتیجه پیش بینی های شما برای مجموعه آزمون ضعیف خواهد بود.\nاگر خطای فرضیه خود را با داده هایی که با آن پارامتر ها را آموزش داده اید محاسبه کنید، کمتر از مجموعه داده های دیگر خواهد بود!\nبرای انتخاب مدل خود، می‌توانید هر درجه از چند جمله ای ها را آزمایش کرده و به نتیجه خطای آن توجه کنید.\nبدون مجموعه اعتبار سنجی:\n(توجه داشته باشید: این روش بدی است - از آن استفاده نکنید!)\n بهنیه سازی پارامتر های $\\Theta$، با استفاده از مجموعه آموزشی برای هر یک از درجات چند جمله ای. با استفاده از مجموعه آزمون، درجه چند جمله ای d را که کمترین خطا را دارد پیدا کنید. خطای تعمیم را با استفاده از مجموعه آزمون محاسبه کنید $J_{test}(\\Theta^{d})$  در این حالت ما متغیر d یا درجه چند جمله ای را با استفاده از مجموعه آزمون آموزش می‌دهیم.\nCV set:\nبرای انجام این کار می‌توانیم از مجموعه Cross Validation به عناون یک مجموعه میانی برای آموزش دادن d استفاده کنیم، و سپس مجموعه آزمون خطایی دقیق و غیر خوش بینانه به ما می‌دهد.\nیکی از روش های تجزیه مجموعه داده مان به سه مجموعه این است:\n مجموعه آموزشی: ۶۰ درصد مجموعه cross validation: درصد ۲۰ مجموعه آزمون: ۲۰ درصد  اکنون می توانیم سه مقدار خطای جداگانه را برای سه مجموعه مختلف محاسبه کنیم.\nبا مجموعه اعتبار سنجی:\nدر این روش فرض می‌کنیم که از مجموعه cross validation در منظم سازی استفاده نشده است.\n  برای هر درجه چندجمله ای با استفاده از مجموعه آموزشی، پارامترهای موجود در $\\Theta$ را بهینه سازی کنید. با استفاده از مجموعه cross validation درجه چند جمله ای d را که کمترین خطا را دارد پیدا کنید. با استفاده از مجموعه آزمون و $J_{test}(\\Theta ^{d})$ مقدار خطای تعمیم را تخمین بزنید.  از این روش، درجه چندجمله ای (d) با استفاده از مجموعه آزمون آموزش داده نخواهد شد.\nتوجه کنید که استفاده از مجموعه cross validation برای انتخاب مقدار d به این معناست که نمی‌توانیم از آن در روند منحنی اعتبار سنجی برای تعیین مقدار $\\lambda$ استفاده کنیم.\n "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week5/backpropagation-1/",
	"title": "پس انتشار قسمت اول",
	"tags": [],
	"description": "",
	"content": "پس انتشار در شبکه های عصبی، برای به حداقل رساندن تابع هزینه مثل کاری که با گرادیان کاهشی در رگرسیون لجستیک و خطی انجام می‌دادیم، استفاده می‌شود.\nهدف ما محاسبه این است:\n$$ min_\\Theta J(\\Theta) $$\nیعنی می‌خواهیم تابع هزیه $J$ را با استفاده از یک محموعه بهینه از پارامتر $\\Theta$ به حداقل برسانیم (یا به عبارتی دیگر مینیمم کنیم).\nدر این بخش به معادلاتی که برای محاسبه مشتق جزئی تابع $J(\\Theta)$ استفاده می‌کنیم، خواهیم پرداخت:\n$$ \\frac{\\partial}{\\partial \\Theta_ {i,j} ^{(l)}} J(\\Theta) $$\nدر پس انتشار ما برای هر گره محاسبه خواهیم کرد:\n$ = \\delta_j ^{(l)} $ خطا هر گره $j$ ام در لایه $l$\nبه خاطر آورید که $ \\delta_j ^{(l)} $ گره فعال ساز $j$ در لایه $l$ است.\n برای آخرین لایه یا همان لایه خروجی، می‌توانیم بردار مقادیر دلتا را به این صورت حساب کنیم: $$ \\delta ^{(L)} = a ^{(L)} - y $$\nبه طوری که $L$ تعداد کل لایه های ما است و $a ^{(L)}$ بردار خروجی گره های فعال ساز در آخرین لایه است. بنابراین مقادیر خطای ما برای آخرین لایه، تفاوت نتایج واقعی در لایه آخر و خروجی صحیح در $y$ است.\nبرای محاسبه مقادیر دلتای، لایه های قبل از لایه آخر می‌توانیم از معادله ای استفاده کنیم که ما را از سمت راست به چپ عقب می‌‌برد:\n$$ \\delta ^{(l)} = ( (\\Theta ^ {(l)}) ^ T \\delta ^ {(l+1)}) \\hspace{0.2cm} .* \\hspace{0.2cm} {g}\u0026rsquo; (z^{(l)}) $$\nمقادیر دلتای لایه $l$ با ضرب مقادیر دلتا در لایه بعدی با ماتریس تتا لایه $l$ محاسبه می‌شود، سپس به صورت عنصر به عنصر آن را در تابعی به اسم g-prime یا همان $g'$ ضرب می‌کنیم.\nکه $g'$ مشتق تابع فعال سازی $g$ است، و به عنوان ورودی $z^{(l)}$ را می‌گیرد.\nبخش $g'$ را به صورت زیر نیز می‌توان نوشت: $$ g\u0026rsquo;(u) = g(u) \\hspace{0.2cm} .* \\hspace{0.2cm} (1 - g(u)) $$\nو معادله کامل پس انتشار برای گره های داخلی را به این شکل می‌نویسیم: $$ \\delta ^{(l)} = ( (\\Theta ^ {(l)}) ^ T \\delta ^ {(l+1)}) \\hspace{0.2cm} .* \\hspace{0.2cm} a^{(l)} \\hspace{0.2cm} .* \\hspace{0.2cm} (1 - a^{(l)}) $$\nما می‌توانیم با ضرب مقادیر فعال ساز در مقادیر خطا برای هر نمونه آموزشی $t$، مشتق جزئی خود را محاسبه کنیم: $$ \\frac{\\partial}{\\partial \\Theta_ {i,j} ^{(l)}} J(\\Theta) = \\frac{1}{m} \\sum_{t=1} ^m a_j ^{(t) (l)} \\delta _ i ^{(t) (l+1)} $$\nنکته:\n$\\delta ^{(l+1)}$ و $a ^{(l+1)}$ بردار هایی با $s_ {l+1}$ عضو هستند و $a ^ {(l)}$ برداری با $s_l$ عضو است، که ضرب آن ها ماتریسی تولید می‌کند که $s_ {l+1}$ در $s_l$ است، که ابعاد آن شبیه به $\\Theta^{(l)}$ است.\nکه این فرایند برای هر عنصر موجود در $\\Theta^{(l)}$ گرادیان تولید می‌کند.\nالگوریتم پس انتشار تصور کنید چنین مجموعه آموزشی داریم: $ \\{ (x^{(1)}, y^{(1)}) \u0026hellip; (x^{(m)}, y^{(m)}) \\} $\n تنظیم $\\Delta _{i,j} ^{(l)} := 0 $ برای همه $(l,i,j)$ ها  برای نمونه آموزشی از $t=1$ تا $m$:\n  تنظیم $a ^{(1)} := x ^{(t)}$\n  برای انجام انتشار به جلو محاسبه $a ^{(1)}$ برای $l = 1,2,3, \u0026hellip; , L$ را انجام می‌دهیم\n  با استفاده از $y^{(t)}$ ، محاسبه $\\delta ^{(L)} = a ^{(L)} - y^{(t)}$ را انجام می‌دهیم\n  محاسبه $\\delta^{(L-1)},\\delta^{(L-2)}, \u0026hellip; , \\delta^{(2)} $ با استفاده از $\\delta ^{(l)} = ( (\\Theta ^ {(l)}) ^ T \\delta ^ {(l+1)}) \\hspace{0.2cm} .* \\hspace{0.2cm} a^{(l)} \\hspace{0.2cm} .* \\hspace{0.2cm} (1 - a^{(l)})$\n  محاسبه $\\Delta _{i,j} ^{(l)} := \\Delta _{i,j} ^{(l)} + a_j ^{(l)} \\delta _i ^{(l+1)} $ یا به صورت vectorization محاسبه $\\Delta ^{(l)} := \\Delta ^{(l)} + \\delta ^{(l+1)} (a^{(l)})^ T$\n  $D _{i,j} ^{(l)} := \\frac{1}{m} (\\Delta _{i,j} ^{(l)} + \\lambda \\Theta _{i,j} ^{(l)}) $ اگر $j \\neq 0$\n  $D _{i,j} ^{(l)} := \\frac{1}{m} \\Delta _{i,j} ^{(l)} $ اگر $j = 0$\n  ماتریس دلتا بزرگ یا همان $\\Delta$ به عنوان انباشتگر برای جمع آوری مقادیر ما در طول کار و محاسبه مشتق جزئی استفاده می‌شود.\nاثبات واقعی این الگوریتم کاملا پیچیده است، همانطور که Andew Ng می‌گوید که استنتاج و اثبات آن پیچیده است، اما ما می‌توانیم از معادلات برای انجام کارمان استفاده کنیم بدون دانستن جزئیات آن.\nو $D _{i,j} ^{(l)} $ جمله ای است که ما برای مشتقات جزئی و نتایج به دنبال آن هستیم:\n$$ D_ {i,j} ^{(l)} = \\frac{\\partial}{\\partial \\Theta_ {i,j} ^{(l)}} J(\\Theta) $$\nخلاصه که اینجوریه دیگه 😅  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/neurons-and-brain/",
	"title": "نورون ها و مغز",
	"tags": [],
	"description": "",
	"content": "مبدا و سرچشمه شبکه های عصبی ساخت الگوریتم هایی است که سعی کنند از مغز تقلید کنند. شبکه های عصبی در دهه ۸۰ و ۹۰ میلادی بسیار مورد استفاده قرار می‌گرفته اند، اما در اواخر دهه ۹۰ از محبوبیت آن ها کاسته شد، و اخیرا به دلیل پیشرفت در سخت افزار کامپیوتر ها دوباره احیا شده است.\nشواهدی وجود دارد که مغز تنها از یک الگوریتم یادگیری برای انجام تمام عملکرد های محتلف خود استفاده می‌کند.\nدانشمندان سعی کرده اند در مغز حیوانات اتصال بین گوش و قشر شنوایی آن در مغز را قطع کنند و به جای آن عصب بینایی را به قشر شنوایی متصل کنند و دریافت اند که قشر شنوایی دیدن را یاد می‌گیرد!\nبه طور مشابه برای قشر حس لامسه:\nبرای مثال های بیشتر اجرایی شده می‌توانیم به موارد زیر اشاره کنیم:\nپروژه Brainport با زبان خود ببینید! ویدئو مربوط به این پروژه را در Youtube ببینید (روی تصویر کلیک کنید!):\n\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/",
	"title": " هفته چهارم",
	"tags": [],
	"description": "",
	"content": "در این هفته، ما شبکه های عصبی را پوشش می‌دهیم. شبکه عصبی مدلی است که از نحوه کار مغز الهام گرفته شده است.\nامروزه به طور گسترده ای در بسیاری از برنامه ها مورد استفاده قرار می‌گیرد: هنگامی که تلفن شما دستورات صوتی شما را تفسیر و درک می‌کند، احتمالاً یک شبکه عصبی به درک گفتار شما کمک می‌کند. هنگامی که یک چک را نقد می‌کنید، ماشین هایی که به طور خودکار ارقام را می‌خوانند نیز از شبکه های عصبی استفاده می‌کنند.\n فرضیه غیر خطی   نورون ها و مغز   ارائه مدل قسمت اول   ارائه مدل قسمت دوم   مثال ها قسمت اول   مثال ها قسمت دوم   طبقه بندی چند کلاسه   فایل های هفته چهارم   "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/classification/",
	"title": "طبقه بندی",
	"tags": [],
	"description": "",
	"content": "رگرسیون لجستیک اینجا از مسائل رگرسیون به مسائل طبقه بندی می‌رویم، اما با اسم رگرسیون لجستیک گیج نشوید! این اسم به دلایل تاریخی نامگذاری شده که در واقع رویکردی برای حل مسائل طبقه بندی است نه رگرسیون!\nطبقه دودویی به جای اینکه خروجی یعنی $y$ مقداری پیوسته در یک محدوده باشد، فقط $0$ یا $1$ است، یعنی : $ y \\in \\text{{0,1}} $\nبه طوری که معمولا به $0$، negative class و به $1$ هم positive class می‌گوییم، اما شما آزاد هستید که هر اسم دلخواهی را برای نام‌گذاری آن ها انتخاب کنید!\nفعلا فقط دو تا کلاس داریم که به این نوع از مسئله طبقه بندی دودویی می‌گوییم.\nفرض کنید از رگرسیون خطی استفاده کنیم و نتیجه تمام پیش بینی های بیشتر از $0.5$ را به عنوان 1 در نظر بگیریم (نگاشت کنیم) ، و هم چنین تمام موارد کوچکتر از $0.5$ را $0$ در نظر بگیریم.\n  برای پاسخ کلیک کن   naghes\n  -- ارائه فرضیه تابع فرضیه ما باید به این شکل باشد:\n$$ h_\\theta(x) = g(\\theta^T x) \\hspace{2cm} 0 \\leqslant h_\\theta(x) \\leqslant 1 $$\n$$ g(z) = \\frac{1}{1 + e^{-z}} \\hspace{2cm} z = \\theta^Tx $$\nکه به این فرم جدید تابع سیگموئید یا تابع لجستیک می‌گوییم.\nکار با نمودار تعاملی تابع سیگموئید: http://desmos.com/calculator/bgontvxotm\n تابع $g(z)$ در اینجا اعداد حقیقی را به عددی بین $0$ و $1$ نگاشت می‌کند.\n$h_\\theta(x)$ به ما احتمال اینکه خروجی ما $1$ است را می‌دهد برای مثال $h_\\theta(x) = 0.7$ احتمال 70 درصدی را به ما می‌دهد که خروجی $1$ باشد.\nو احتمال اینکه پیش بینی ما در کلاس $0$ باشد متمم احتمال کلاس 0 است، که اینجا $\\text{30%} $ می‌شود.\n$$ h_\\theta(x) = P (y=1 | x;\\theta) = 1 - P (y = 0 | x;\\theta) $$ $$ P (y=0 | x;\\theta) + P (y=1 | x;\\theta) = 1 $$\nمرز تصمیم گیری برای مجزا کردن کلاس های $0$ و $1$ طبقه بندی باید خروجی تابع فرضیه را به این صورت تبدیل کنیم:\n$$ h_\\theta(x) \\geqslant 0.5 \\rightarrow y = 1 \\hspace{2cm} h_\\theta(x) \u0026lt; 0.5 \\rightarrow y = 0 $$\nنحوه عملکرد تابع لجستیکی $g$ ما به این صورت است که وقتی ورودی آن بزرگتر یا برابر 0 باشد، خروجی آن بزرگ تر یا مساوی $0.5$ می‌شود:\n$$ g(z) \\geqslant 0.5 $$ $$ \\text{ when } z \\geqslant 0 $$\nبه یاد داشته باشید که: $$z = 0, e^0 = 1 \\Rightarrow g(z) = \\frac{1}{2} $$ $$ z \\rightarrow \\infty, e^{-\\infty} \\rightarrow 0 \\Rightarrow g(z) = 1 $$ $$ z \\rightarrow -\\infty, e^{\\infty} \\rightarrow \\infty \\Rightarrow g(z) = 0 $$\nو اگر ورودی تابع g ،$ \\theta^T x $ باشد به این معنی است که:\n$$ h_\\theta(x) = g(\\theta^T x) \\geqslant 0.5 \\hspace{1.5cm} \\text{when } \\theta^T x \\geqslant 0 $$\nحالا می‌توانیم بگوییم که:\n$$ \\theta^T x \\geqslant 0 \\Rightarrow y = 1 \\hspace{1cm} \\theta^T x \u0026lt; 0 \\Rightarrow y = 0 $$\nمرز تصمیم گیری، خطی است که قسمتی که 1=y است را از قسمت های 0=y جدا می‌کند، که این خط توسط تابع فرضیه ساخته می‌شود.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/gradient-many-variable/",
	"title": "گرادیان کاهشی چند متغیره",
	"tags": [],
	"description": "",
	"content": "الگوریتم جدید ما برای گرادیان کاهشی با چندین متغیر به این صورت است:\nو قسمت $ \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)} $ همان مشتق جرئی $\\frac {\\partial} {\\partial\\theta_0} J(\\theta)$ است.\nبه طور مثال برای دو متغیره و یا بیشتر خواهیم داشت:\n$$ \\theta_0 := \\theta_0 - \\alpha \\frac{1}{m} \\sum ^ m _ {i=1} (h_\\theta(x^{(i)}) - y^{(i)}) x_0 ^{(i)} $$\n$$ \\theta_1 := \\theta_1 - \\alpha \\frac{1}{m} \\sum ^ m _ {i=1} (h_\\theta(x^{(i)}) - y^{(i)}) x_1 ^{(i)} $$\n$$ \\theta_2 := \\theta_2 - \\alpha \\frac{1}{m} \\sum ^ m _ {i=1} (h_\\theta(x^{(i)}) - y^{(i)}) x_2 ^{(i)} $$\n$$ \u0026hellip; $$\nیادآوری: مقدار $x_0$ برابر $1$ است.\n "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/supervised/",
	"title": "یادگیری با نظارت چیست؟",
	"tags": [],
	"description": "",
	"content": "تعریف یادگیری با نظارت در یادگیری با نظارت یک مجموعه داده داریم و از قبل می‌دانیم که خروجی صحیح باید چطور باشد، اصطلاحا داده ها برچسب خورده اند! با این ایده که به بین خروجی و ورودی رابطه وجود دارد.\nمسائل یادگیری با نظارت به دو دسته رگرسیون و طبقه بندی تقسیم می‌شوند.\nرگرسیون در این مسائل سعی می‌کنیم خروجی ای با مقدار پیوسته را پیش بینی کنیم.\nدر مسئله پیش بینی قیمت خانه می‌خواهیم با مجموعه داده ای از قیمت های واقعی خانه ها بر اساس اندازه، قیمت خانه ای جدیدی را پیش بینی کنیم.\nطبقه بندی در عوض اینجا سعی می‌کنیم خروجی ای با مقدار گسسته پیش بینی کنیم. مثلا در مسئله تشخیص وخیم بودن یا نبودن سرطان می‌خواهیم بر اساس دو ویژگی سن و سایز تومور نتیجه را در یکی از دو دسته وخیم یا غیر وخیم طبقه بندی کنیم.\nمثال های بیشتری که شما پاسخ دهید!  با توجه به عکسی که از یک شخص دریافت کردید تشخیص دهید که سنش چه قدر است. می‌خواهید حساب های مشتری هارا بررسی کنید و تصمیم بگیرید که هک شده است یا نه. شما انبار بزرگی از اقلام یکسان دارید و می‌ خواهید پیش بینی کنید که طی 3 ماه آینده چه تعداد از این اقلام به فروش می رسند.    برای پاسخ مثال ها کلیک کن    Regression Classification Regression    "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week5/",
	"title": " هفته پنجم",
	"tags": [],
	"description": "",
	"content": "در این هفته شما یاد خواهید گرفت که چگونه شبکه های عصبی را آموزش دهید. شبکه عصبی یکی از قدرتمندترین الگوریتم های یادگیری است (وقتی طبقه بندی خطی کار نمی‌کند ، این همان چیزی است که ما معمولاً به آن متوسل می‌شویم)\n تابع هزینه شبکه عصبی   پس انتشار قسمت اول   پس انتشار قسمت دوم   بازکردن پارامتر ها   بررسی گرادیان   مقدار دهی اولیه تصادفی   Putting It Together   نمونه ای از رانندگی خودکار   فایل های هفته پنجم   "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week7/mathematics-behind-large-margin-classification/",
	"title": "ریاضیات پشت طبقه بندی با حاشیه اطمینان زیاد (اختیاری)",
	"tags": [],
	"description": "",
	"content": "ضرب داخلی بردار\nفرض کنید دو بردار داریم ، $u$ و $v$:\n$$ u= \\begin{bmatrix} u_1 \\newline u_2 \\end{bmatrix} \\hspace{0.5cm} v= \\begin{bmatrix} v_1 \\newline v_2 \\end{bmatrix} $$\nطول بردار $v$ با $||v||$ نمایش داده می‌شود و خطی را روی نمودار توصیف می‌کند که از مبدا (0,0) شروع شده و تا $(v_1,v_2)$ ادامه دارد.\nطبق قضیه فیثاغورث، طول بردار $v$ را می‌توان با فرمول $\\sqrt{v_1^2+v_2^2}$ محاسبه کرد.\nتصویر بردار $v$ روی بردار $u$ با کشیدن یک زاویه قائم از $u$ به انتهای $v$ و ایجاد یک مثلث قائم الزاویه به دست می‌آید.\n p = طول تصویر $v$ روی بردار $u$ $u^Tv=p.||u||$  توجه داشته باشید که $u^Tv=||u||.||v||cos\\theta$ که $\\theta$ زاویه بین $u$ و $v$ است.همچنین، $p=||v||cos\\theta$. اگر p را جایگزین $||v||cos\\theta$ کنید، عبارت $u^Tv=p.||u||$ بدست می‌آید.\nبنابراین حاصل‌ضرب $u^Tv$ برابر است با طول تصویر، ضرب در طول بردار $u$.\nدر مثال ما، از آنجایی که $u$ و $v$ بردارهایی با طول برابر هستند، داریم $u^Tv=v^Tu$.\n$$ u^Tv=v^Tu=p.||u||=u_1v_1+u_2v_2 $$\nاگر زاویه بین خط های $u$ و $v$ بزرگتر از 90 درجه باشد، آن گاه p منفی خواهد بود.\n$$ \\underset{\\Theta}{min}\\frac{1}{2}\\sum_{j=1}^n\\theta_j^2 $$\n$$ =\\frac{1}{2}(\\theta_1^2+\\theta_2^2+\u0026hellip;+\\theta_n^2) $$\n$$ =\\frac{1}{2}(\\sqrt{\\theta_1^2+\\theta_2^2+\u0026hellip;+\\theta_n^2})^2 $$\n$$ =\\frac{1}{2}||\\theta||^2 $$\nمی‌توانیم همان قوانین را اینجا استفاده کنیم برای بازنویسی $\\theta^Tx^{(i)}$:\n$$ \\theta^Tx^{(i)}=p^{(i)}.||\\theta||=\\theta_1x_1^{(i)}+\\theta_2x_2^{(i)}+\u0026hellip;+\\theta_nx_n^{(i)} $$\nبنابراین حالا ما با قرار دادن $p^{(i)}.||\\theta||$ به جای $\\theta^Tx^{(i)}$، یک بهینه سازی هدفمند جدید داریم:\n$$ if \\hspace{0.3cm} y=1,\\hspace{0.1cm} we\\hspace{0.2cm} want \\hspace{0.3cm} p^{(i)}.||\\theta|| \\ge 1 $$\n$$ if \\hspace{0.3cm} y=0,\\hspace{0.1cm} we\\hspace{0.2cm} want \\hspace{0.3cm} p^{(i)}.||\\theta||\\le -1 $$\nدلیلی که این باعث یک حاشیه اطمینان زیاد می‌شود این است که: بردار متعلق به $\\theta$، عمود بر مرز تصمیم گیری است. برای این که بهینه سازی هدفمند ما (عبارت بالا) درست باشد احتیاج داریم که قدر مطلق تصویرهای ما $p^{(i)}$ تا جای ممکن بزرگ باشد.\nاگر $\\theta_0=0$، آن گاه همه مرزهای تصمیم گیری ما در (0,0) با هم تلاقی دارند، اگر $\\theta_0\\ne0$، ماشین بردار پشتیبان همچنان یک حاشیه اطمینان زیادی را برای مرز تصمیم گیری پیدا می‌کند.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week8/optimization-objective/",
	"title": "بهینه سازی هدفمند",
	"tags": [],
	"description": "",
	"content": "برخی از پارامتر هایی را که در الگوریتم خود استفاده کردیم به یاد بیاورید:\n $ = c ^ {(i)}$ ایندکس خوشه ای ${1,2,\u0026hellip;,k}$ که به نمونه $x^{(i)}$ منتسب شده است. $ = \\mu _k $ خوشه مرکزی k $(\\mu _k \\in \\mathbb{R} ^ n)$ $ = \\mu _ {c ^ {(i)}} $ مرکز خوشه ای که به نمونه $x^{(i)}$ منتسب شد است.  با استفاده از این متغیرها می‌توانیم تابع هزینه خود را تعریف کنیم:\n$$ J(c ^{(i)}, \u0026hellip;, c ^{(m)}, \\mu _1, \u0026hellip;, \\mu _k) = \\frac{1}{m} \\sum ^ m _ {i=1} || x ^{(i)} - \\mu _ {c^{(i)}} || ^2 $$\nهدف بهینه سازی ما این است که تمام پارامترهای خود را با استفاده از تابع هزینه بالا به حداقل برسانیم:\n$$ min _ {c,\\mu} J(c, \\mu) $$\nیعنی همه مقادیری که در مجموعه $c$ پیدا می‌کنیم، نمایانگر همه خوشه های ما است، و $\\mu$ نیز نمایانگر همه مرکز های ما است، که میانگین فاصله هر نمونه آموزشی تا مرکز خوشه مربوطه را به حداقل می‌رسانیم.\nتابع هزینه بالا اغلب distortion نمونه های آموزشی نامیده می‌شود.\nدر مرحله تخصیص خوشه (مرحله ۲ در قسمت قبل) هدف ما این است:\n$$ \\text{Minimize } J(\u0026hellip;) \\text{ with } c^{(1)},\u0026hellip;,c^{(m)} $$ (ثابت نگه داشتن $\\mu _ 1,\u0026hellip;,\\mu _ k $ ها)\nو در مرحله حرکت مرکز (مرحله ۳ در قسمت قبل) هدف ما این است:\n$$ \\text{Minimize } J(\u0026hellip;) \\text{ with } \\mu _ 1,\u0026hellip;,\\mu _ k $$\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/diagnosing-bias-variance/",
	"title": "تشخیص بایاس در مقابل واریانس",
	"tags": [],
	"description": "",
	"content": "در این بخش به بررسی رابطه بین درجه چند جمله ای (d) و underfit و یا overfit بودن فرضیه می‌پردازیم.\n در ابتدا لازم است که تشخیص دهیم، عاملی که باعث پیش بینی نادرست شده بایاس است یا واریانس؟ بایاس زیاد همان underfitting و واریانس زیاد همان overfitting است که باید یک میانگین مناسب بین این دو مقدار انتخاب شود.  مادامی که ما درجه چندجمله ای را افزایش می‌دهیم، خطای آموزش کاهش می‌یابد.\nخطای cross validation نیز با افزایش مقدار d تا یک نقطه مشخص، کاهش یافته و در ادامه با افزایش مقدار d، افزایش می‌یابد که این مسئله موجب به وجود آمدن یک منحنی محدب می شود. (منحنی سیز رنگ در شکل زیر)\nبایاس زیاد (underfitting): $J_{train}(\\Theta )$ و $J_{CV}(\\Theta )$ هردو مقادیر بزرگی خواهند بود. همچنین $J_{CV}(\\Theta ) \\approx J_{train}(\\Theta )$.\nواریانس زیاد(overfitting): $J_{train}(\\Theta )$ مقداری کوچک و $J_{CV}(\\Theta )$ مقداری بسیار بزرگ تر از $J_{train}(\\Theta )$ خواهد داشت که در تصویر زیر نمایش داده شده است:\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week5/backpropagation-2/",
	"title": "پس انتشار قسمت دوم",
	"tags": [],
	"description": "",
	"content": "به یاد بیاورید که تابع هزینه برای یک شبکه عصبی به این صورت بود:\n$$ \\begin{gather*}J(\\Theta) = - \\frac{1}{m} \\sum_{t=1}^m\\sum_{k=1}^K \\left[ y^{(t)}_k \\ \\log (h_\\Theta (x^{(t)}))_k + (1 - y^{(t)}_k)\\ \\log (1 - h_\\Theta(x^{(t)})_k)\\right] + \\frac{\\lambda}{2m}\\sum_{l=1}^{L-1} \\sum_{i=1}^{s_l} \\sum_{j=1}^{s_l+1} ( \\Theta_{j,i}^{(l)})^2\\end{gather*} $$\nاگر یک طبقه بندی ساده، و غیر چند کلاسه ($k=1$) را در نظر بگیریم و همچنین منظم سازی را هم نادیده بگیریم، تابع هزینه ما به این صورت محاسبه خواهد شد:\n$$ cost(t) = y^{(t)} \\log(h_\\Theta(x^{(t)})) + (1 - y^{(t)}) \\log(1 - h_\\Theta(x^{(t)})) $$\nواضح است که $\\delta^{(l)} _j$ به عنوان خطا برای $a^{(l)} _j$ است (گره $j$ ام در لایه $l$).\nبه طور رسمی تر، مقادیر دلتا در واقع مشتق تابع هزینه هستند: $$ \\delta^{(l)} _j = \\frac{\\delta}{\\delta z_j ^{(l)}} cost(t) $$\nبه یاد آورید که مشتق ما شیب یک خط مماس با تابع هزینه است، بنابراین هرچه شیب بیشتر باشد، بیشتر در اشتباه هستیم.\nبیایید شبکه عصبی زیر را در نظر بگیریم و ببینیم که چطور می‌شود برخی از $\\delta^{(l)} _j$ ها را محاسبه کرد:\nدر تصویر بالا برای محاسبه $\\delta^{(2)} _2$ (بالا سمت راست تصویر) وزن های $\\Theta ^ {(2)} _{12}$ و $\\Theta ^ {(2)} _{22}$ را با هم ضرب کرده ایم، و مقادیر $\\delta$ مربوطه نیز در سمت راست هر کدام از آن ها وجود دارد، که بنابراین خواهیم داشت: $$ \\delta^{(2)} _2 = \\Theta ^ {(2)} _{12} \\ast \\delta^{(3)} _1 + \\Theta ^ {(2)} _{22} \\ast \\delta^{(3)} _2 $$\nبرای محاسبه هر کدام از $\\delta ^ {(l)} _j$ های ممکن، می‌توانیم از سمت راست نمودار شروع کنیم، تصور می‌کنیم که جهت $\\Theta _ {ij}$ هایمان از سمت راست به چپ است، و برای محاسبه هر $\\delta ^ {(l)} _j$ فقط باید جمع همه وزن ها را در مقدار $\\delta$ ای که از آن جا آمده اید ضرب کنید.\nبه همین شکل یک مثال دیگر می‌تواند به این صورت باشد: $$ \\delta ^ {(3)} _2 = \\Theta ^ {(3)} _{12} \\ast \\delta^{(4)} _1 $$\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/",
	"title": " هفته ششم",
	"tags": [],
	"description": "",
	"content": "در هفته ۶ ام شمابهبود الگوریتم یادگیری خود به طور سیستماتیک را یاد خواهید گرفت. ما همچنین طراحی سیستم یادگیری ماشین را پوشش خواهیم داد. برای بهینه سازی الگوریتم یادگیری ماشین، ابتدا باید درک کنید که بزرگترین پیشرفت ها در کجا قابل انجام است.\n ارزیابی فرضیه   انتخاب مدل   تشخیص بایاس در مقابل واریانس   منظم سازی و بایاس/واریانس   منحنی های یادگیری   تصمیم گیری درباره اقدامات بعدی   اولویت بندی کارها   تحلیل خطا   معیار‌های خطا برای کلاس‌های نامتوازن   متوازن کردن Precision و Recall   داده برای یادگیری ماشین   فایل های هفته ششم   "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/model-representation-1/",
	"title": "ارائه مدل قسمت اول",
	"tags": [],
	"description": "",
	"content": "چگونه یک تابع فرضیه را با استفاده از شبکه های عصبی نشان خواهیم داد؟\nشبکه های عصبی به عنوان روشی برای شبیه سازی نورون ها یا شبکه ای از نورون های در مغز ساخته شده اند.\nیک نورون در مغز به این شکل است:\nکه به طور کلی از سه بخش قابل توجه زیر ساخته شده است:\n بدنه سلول بخش ورودی دنریت بخش خروجی اکسون  به طور ساده می‌توانیم بگوییم که:\nنورون ها اساسا واحد های محاسباتی هستند که از طریق رشته سیم های دنریت پالس های الکتریکی به اسم اسپایک را ورودی می‌گیرند، و آن ها را به خروجی یا همان اکسون هدایت می‌کنند. بنابراین متوجه می‌شویم که نورون ها توسط پالس های الکتریکی با هم ارتباط برقرار می‌کنند.\nدر شبکه های عصبی مصنوعی، نورون ها واحد هایی لجستیکی هستند:\nدر مدل ما دنریت ها شبیه به ویژگی ها ورودی $x_1 \u0026hellip; x_n$ هستند، و خروجی ما تابع فرضیه است.\nدر این مدل گره ورودی $x_0$ واحد بایاس یا نام دارد که همیشه برابر با مقدار ۱ است. در شبکه های عصبی ما از تابع لجستیکی که در طبقه بندی داشتیم استفاده می‌کنیم: $$ \\frac{1}{1+e^{- \\theta^T x}} $$ اگر چه که در شبکه های عصبی گاهی اوقات آن را تابع فعال سازی سیگموئید صدا می‌زنیم، بردار $\\theta$ نیز weights یا وزن های مدل نامیده می‌شوند.\nبه طور ساده می‌توانیم به این شکل نمایش دهیم:\nگره های ورودی یا لایه اول داخل لایه دوم می‌شوند، و خروجی هم تابع فرضیه است. لایه اول را لایه ورودی می‌نامیم، و لایه دوم را هم لایه خروجی می‌نامیم، که تابع فرضیه را به عنوان خروجی نتیجه می‌دهد.\nما می‌توانیم لایه های میانی از گره ها داشته باشیم که بین لایه ورودی و خروجی قرار می‌گیرند، که به آن ها لایه های پنهان می‌گوییم.\nما گره های لایه های میانی یا پنهان را به صورت $a_0 ^2 \u0026hellip; a_n ^2$ نام گذاری می‌کنیم، و به آن ها واحد های فعال سازی می‌گوییم.\n$$ \\begin{align*}\u0026amp; a_i^{(j)} = \\text{\u0026ldquo;activation\u0026rdquo; of unit $i$ in layer $j$} \\newline\u0026amp; \\Theta^{(j)} = \\text{matrix of weights controlling function mapping from layer $j$ to layer $j+1$}\\end{align*} $$\nبه طور مثال اگر فقط یک لایه پنهان داشته باشیم به این شکل می‌شود:\nمقدار هر گره فعال ساز به صورت زیر به دست می‌آید:\n$$ \\begin{align*} a_1^{(2)} = g(\\Theta_{10}^{(1)}x_0 + \\Theta_{11}^{(1)}x_1 + \\Theta_{12}^{(1)}x_2 + \\Theta_{13}^{(1)}x_3) \\newline a_2^{(2)} = g(\\Theta_{20}^{(1)}x_0 + \\Theta_{21}^{(1)}x_1 + \\Theta_{22}^{(1)}x_2 + \\Theta_{23}^{(1)}x_3) \\newline a_3^{(2)} = g(\\Theta_{30}^{(1)}x_0 + \\Theta_{31}^{(1)}x_1 + \\Theta_{32}^{(1)}x_2 + \\Theta_{33}^{(1)}x_3) \\newline h_\\Theta(x) = a_1^{(3)} = g(\\Theta_{10}^{(2)}a_0^{(2)} + \\Theta_{11}^{(2)}a_1^{(2)} + \\Theta_{12}^{(2)}a_2^{(2)} + \\Theta_{13}^{(2)}a_3^{(2)}) \\newline \\end{align*} $$\nاین به ما می‌گوید که گره های فعال ساز مان را با استفاده از یک ماتریس $3 \\times 4$ از پارامتر ها محاسبه می‌کنیم. به این ترتیب که ما هر ردیف (row) از پارامتر ها را به ورودی های خود اعمال می‌کنیم، تا مقدار یک گره فعال ساز را بدست آوریم.\nو خروجی فرضیه ما تابعی لجستیکی است که روی مجموع مقادیر گره های فعال ساز ما اعمال می‌شود، که در ماتریسی از پارامتر های دیگری ($\\Theta^{(2)}$) ضرب می‌شود.\nمحاسبه $a_1 ^{(2)}$ : محاسبه $a_2 ^{(2)}$ : محاسبه $a_3 ^{(2)}$ :\n[تصحیح: ردیف سوم از ماتریس $\\Theta^T X$ باید انتخاب شود] محاسبه $a_1 ^{(3)}$ یا همان $h_\\Theta(x)$: $\\Theta^{(2)}$ شامل وزن های گره های لایه دوم است.\n به طور کلی هر لابه ماتریس وزن خود را دارد که به شکل $ \\Theta^{(j)} $ نام گذاری می‌شود.\nابعاد این ماتریس های وزنی به شکل زیر محاسبه می‌شوند:\nاگر شبکه ما شامل $s_j$ واحد در هر لایه $j$ است، و $s_{j+1}$ واحد داخل لایه $j+1$ ام است، سپس ابعاد ماتریس $\\Theta^{(j)}$ برابر با $ s_{j+1} \\times (s_j + 1) $ خواهد بود.\n1+ آورده شده به خاطر گره بایاس است. گره بایاس در گره های خروجی شامل نمی‌شود، اما در گره های ورودی وجود دارد.\n مثال:\nاگر لایه اول ۲ گره ورودی، و لایه دوم ۴ گره فعال ساز داشته باشد، ابعاد $\\Theta^{(1)}$ به صورت $4 \\times 3$ خواهد بود، به طوری که:\n$$ s_j = 2, s_{j+1} = 4 $$\n$$ s_{j+1} \\times (s_j + 1) = 4 \\times 3 $$\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/cost-function/",
	"title": "تابع هزینه",
	"tags": [],
	"description": "",
	"content": "ما نمی‌توانیم از همان تابعی هزینه ای که برای رگرسیون خطی استفاده کردیم، برای تابع لجستیک نیز استفاده کنیم، زیرا خروجی تابع لجستیک موج گونه است و باعث ایجاد تعداد زیادی مینیمم محلی می‌شود. به عبارت دیگر یک تابع محدب نیست.\nتابع هزینه ما برای رگرسیون لجستیک به این صورت است:\n$$ J(\\theta) = \\frac{1}{m} \\sum_{i = 1}^m Cost(h_\\theta(x^{(i)}, y^{(i)})) $$\n$$ Cost(h_\\theta(x), y) = -log(h_\\theta(x)) \\hspace{1cm} if \\hspace{0.3cm} y = 1 $$\n$$ Cost(h_\\theta(x), y) = -log(1 - h_\\theta(x)) \\hspace{1cm} if \\hspace{0.3cm} y = 0 $$\nهرچه تابع فرضیه از $y$ دور تر باشد، خروجی تابع هزینه بزرگ تر است.\nو اگر تابع فرضیه برابر با $y$ باشد، هزینه ما $0$ است.\n$$ Cost(h_\\theta(x), y) = 0 \\hspace{0.3cm} if \\hspace{0.3cm} h_\\theta(x)) = y $$\n$$ Cost(h_\\theta(x), y) \\rightarrow \\infty \\hspace{0.5cm} if \\hspace{0.3cm} y = 0 \\hspace{0.3cm} and \\hspace{0.3cm} h_\\theta(x) \\rightarrow 1$$\n$$ Cost(h_\\theta(x), y) \\rightarrow \\infty \\hspace{0.5cm} if \\hspace{0.3cm} y = 1 \\hspace{0.3cm} and \\hspace{0.3cm} h_\\theta(x) \\rightarrow 0 $$\nاگر پاسخ صحیح ما $y = 0$ باشد، سپس تابع هزینه $0$ خواهد شد، اگر خروجی تابع فرضیه ما نیز $0$ شود.\nاگر فرضیه ما به $1$ میل کند، سپس تابع هزینه به بی نهایت میل می‌کند.\nاگر پاسخ صحیح ما $y = 1$ باشد، سپس تابع هزینه $0$ خواهد شد، اگر خروجی تابع فرضیه ما $1$ شود.\nاگر فرضیه ما به $0$ میل کند، سپس تابع هزینه به بی نهایت میل می‌کند.\nبه خاطر داشته باشید که نوشتن تابع هزینه به این روش که $J(\\theta)$ برای رگرسیون لجستیک محدب است.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/feature-scaling/",
	"title": "مقیاس بندی ویژگی",
	"tags": [],
	"description": "",
	"content": "در این قسمت و قسمت بعدی در مورد فوت و فن هایی برای اعمال الگوریتم گرادیـــان کـــاهشی صحبت می‌کنیم.\nاگر شما مسئله ای دارید که چندین ویژگی یا متغیر دارد و اگر مطمئن هستید که متغیر ها در مقیاس مشابه ای نسبت به هم هستند، در این حــالت گرادیــــان کـــاهشی با سرعت بیشتری به همگرایی می‌رسد.\nفرض کنید مسئله ما دو متغیر به صورت زیر دارد: $$ x_1 = \\text {size(0-2000 feet^2) }$$ $$ x_2 = \\text {number of bedrooms(1-5) }$$\nکه اگر بـخواهیم نــــمودار کــــانتور را رسم کـنیم به این شکل خواهد شد. شکلی بلند و بیضی مــانند که گرادیـــان کـــاهشی بـرای پیدا کردن مینیمم کلی در این تابع هزینه زمان زیادی را باید صرف کند!\nکه اینجا از تکنیک مقیاس بندی ویژگی استفاده می‌کنیم!\nبرای انجام این کار باید مقدار متغیر $x$ را بر تفـــاضـل کران بالا و پایین خودش تقسیم کنیم. که با این کار مقادیر متغیر ها عددی بین $0$ و $1 $ قرار می‌گــیرد، و شکل معقول تری خـــواهیم داشــت. مثلا در این مسئله داریم:\n$$ x_1 = \\frac {\\text {size(feet^2)} } {2000}$$ $$ x_2 = \\frac {\\text {number of bedrooms} } {(5-1)}$$\nهمچنین روش مشابه دیگری برای انجام این کار به اسم mean normalization داریم. که در صورت کسر، تفاضل مقدار متغیر با میانگین همه مقادیر متغیر $x$ را قرار می‌دهیم.\n$$ x_i := \\frac{x_i - \\mu_i} {s_i} $$\nهمچنین در مخرج کسر مـی‌توانیم از مــقدار انحراف معیار استفاده کنیم، که البته نتایج متفاوتی با هم دارند.\n "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/unsupervised/",
	"title": "یادگیری بدون نظارت چیست؟",
	"tags": [],
	"description": "",
	"content": "تعریف یادگیری بدون نظارت یادگیری بدون نظارت این امکان را به ما مـی‌دهد کــه بدون داشتن هیچ ایده ای نسبت به خروجی داده ها به حل مشکلات نزدیک شویم. در واقع در اینجا داده های ما هیچ برچسبی نـدارنـد و الگوریتم‌ها به حال خود رها می‌شوند تا سـاختـارهــای موجود در میان داده‌ها را کشف کنند. مسائل بدون نظارت ها به دو دسته خوشه بندی و غیر خوشه بندی تقسیم می‌شوند.\nخوشه بندی در این مسـائـــل سـعــی مـی‌کــنیم داده هایی با ویژگی های مشترک را به چـندین گــروه تقـسیم کــنیم، یعنی آن ها را به خوشه ها تخصیص بدهیم. فرض کنید مجموعه داده از 1000000 ژن مختلف دارید و می‌خواهید راهی پیدا کنید که به صورت خودکار آن ها را گروه بندی کند که به نوعی به هم شباهت دارند.\nمثال های بیشتر \u0026hellip;\n دسته بندی مشتری های فروشگاه اینترنتی تا بتوانیم مشتری های مشابه را در یک خوشه نگه داری کنیم. الگوریتم Cocktail Party به شما امکان می‌دهد کـــه در مــحیط بــی نظم سـاختـار پیدا کنید:  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week7/",
	"title": " هفته هفتم",
	"tags": [],
	"description": "",
	"content": "  بهینه سازی هدفمند   درک حاشیه اطمینان زیاد   ریاضیات پشت طبقه بندی با حاشیه اطمینان زیاد (اختیاری)   "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week8/random-initialization/",
	"title": "مقداردهی اولیه تصادفی",
	"tags": [],
	"description": "",
	"content": "یک روش پیشنهادی برای مقداردهی اولیه تصادفی برای مرکز های خوشه ای وجود دارد.\n  اگر داشته باشید $k \u0026lt; m$، یعنی اطمینان حاصل کنید که تعداد خوشه های شما از تعداد نمونه های آموزشی شما کمتر است.\n  به طور تصادفی نمونه های آموزشی $k$ را انتخاب کنید.(مطمعن شوید که نمونه ها منحصر به فرد باشند)\n  $\\mu_1, \u0026hellip;, \\mu _k$ ها را برابر با نمونه های $k$ قرار بدهید.\n  الگوریتم k-means می‌تواند در مینیمم محلی گیر کند، برای کاهش احتمال وقوع این اتفاق می‌توانید الگوریتم را در مقداردهی اولیه های تصادفی مختلف اجرا کنید.\nدر مواری که $k \u0026lt; 10$ است، به شدت توصیه می‌شود که یک حلقه از مقداردهی اولیه تصادفی اجرا کنید.\nfor i = 1 to 100: randomly initialize k-means run k-means to get 'c' and 'm' compute the cost function (distortion) J(c,m) pick the clustering that gave us the lowest cost "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week8/",
	"title": " هفته هشتم",
	"tags": [],
	"description": "",
	"content": "  مقدمه یادگیری بدون نظارت   الگوریتم K-Means   بهینه سازی هدفمند   مقداردهی اولیه تصادفی   انتخاب تعداد خوشه ها   کاهش ابعاد   تحلیل اجزای اصلی فرمول مسئله   تحلیل اجزای اصلی الگوریتم   "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/regularization-and-bias-variance/",
	"title": "منظم سازی و بایاس/واریانس",
	"tags": [],
	"description": "",
	"content": "در ادامه به جای بررسی d و تاثیر آن بر بایاس/واریانس، نگاهی به پارامتر مرتب سازی $\\lambda$ خواهیم داشت.\n $\\lambda$ بزرگ: بایاس زیاد (underfitting) $\\lambda$ متوسط: مقدار مناسب $\\lambda$ کوچک: واریانس زیاد (overfitting)  $\\lambda$ بزرگ به شدت در تمامی پارامترهای $\\theta$ ایجاد نقص می‌کند که این مسئله خط تابع حاصل شده را بسیار ساده کرده و موجب underfitting خواهد شد.\nرابطه $\\lambda$ با مجموعه آموزشی و مجموعه واریانس به صورت زیر است:\n$\\lambda$ کوچک: $J_{train}(\\Theta )$ کم و $J_{CV}(\\Theta )$ مقدار زیادی خواهد داشت (واریانس زیاد/overfitting).\n$\\lambda$ متوسط: مقدار $J_{train}(\\Theta )$ و $J_{CV}(\\Theta )$ تا حدودی کم خواهد بود و $J_{train}(\\Theta ) \\approx J_{CV}(\\Theta )$.\n$\\lambda$ بزرگ: هر دو مقدار $J_{train}(\\Theta )$ و $J_{CV}(\\Theta )$ زیاد خواهد بود (بایاس زیاد/underfitting).\nتصویر زیر رابطه بین $\\lambda$ و فرضیه را ترسیم می‌کند:\nبرای انتخاب مدل و مقدار $\\lambda$ در منظم سازی، نیاز داریم که:\n لیستی از مقادیر $\\lambda$ ایجاد کنید، برای مثال:  $$\\lambda \\in { 0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24 } $$\n مجموعه ای از مدل ها با درجه های متفاوت یا هر تفاوت دیگری بسازید.\n  بر روی مقادیر $\\lambda$ پیمایش کنید و برای هر $\\lambda$ تمامی مدل ها را تا یادگیری چند $\\Theta$ طی کنید.\n  خطای cross validation را با کمک $\\Theta$ آموخته شده، روی $J_{cv}\\left ( \\Theta \\right )$، و بدون منظم سازی یا $\\lambda = 0$ محاسبه کنید.\n  بهترین ترکیب که کمترین خطا را روی مجموعه cross validation تولید می‌کند انتخاب کنید.\n  با استفاده از بهترین ترکیب $\\Theta$ و $\\lambda$، این ترکیب را روی $J_{test}\\left ( \\Theta \\right )$ پیاده کرده تا اطمینان حاصل کنید از اینکه آیا مسئله به خوبی قابل تعمیم است یا خیر.\n  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week5/unrolling-parameters/",
	"title": "بازکردن پارامتر ها",
	"tags": [],
	"description": "",
	"content": "باز کردن پارامتر ها ما در شبکه های عصبی در حال کار با مجموعه ای از ماتریس ها هستیم: $$ \\begin{align*} \\Theta^{(1)}, \\Theta^{(2)}, \\Theta^{(3)}, \\dots \\newline D^{(1)}, D^{(2)}, D^{(3)}, \\dots \\end{align*} $$\nبرای استفاده از تابع بهینه سازی مثل ()fminunc، می‌خواهیم همه عضو ها را باز کنیم و داخل یک بردار طولانی قرار دهیم:\nthetaVector = [ Theta1(:); Theta2(:); Theta3(:); ] deltaVector = [ D1(:); D2(:); D3(:) ]  اگر ابعاد Theta1 $10 \\times 11$ و Theta2 $10 \\times 11$ و Theta3 $1 \\times 11$ باشند، سپس می‌توانیم ماتریس های اصلی مان را از نسخه های باز شده به این شکل برگردانیم:\nTheta1 = reshape(thetaVector(1:110),10,11) Theta2 = reshape(thetaVector(111:220),10,11) Theta3 = reshape(thetaVector(221:231),1,11)  به طور خلاصه:\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/model-representation-2/",
	"title": "ارائه مدل قسمت دوم",
	"tags": [],
	"description": "",
	"content": "در این قسمت چگونگی انجام محاسبات را به صورت بهینه تر از طریق پیاده سازی به روش برداری شده بررسی می‌کنیم. و می‌آموزیم که چرا شبکه های عصبی خوب هستند و چطور می‌توانیم از آن ها برای یادگیری چیز های پیچیده و غیر خطی استفاده کنیم.\nبرای یادآوری عبارات زیر مثالی های شبکه های عصبی بودند:\n$$ \\begin{align*} a_1^{(2)} = g(\\Theta_{10}^{(1)}x_0 + \\Theta_{11}^{(1)}x_1 + \\Theta_{12}^{(1)}x_2 + \\Theta_{13}^{(1)}x_3) \\newline a_2^{(2)} = g(\\Theta_{20}^{(1)}x_0 + \\Theta_{21}^{(1)}x_1 + \\Theta_{22}^{(1)}x_2 + \\Theta_{23}^{(1)}x_3) \\newline a_3^{(2)} = g(\\Theta_{30}^{(1)}x_0 + \\Theta_{31}^{(1)}x_1 + \\Theta_{32}^{(1)}x_2 + \\Theta_{33}^{(1)}x_3) \\newline h_\\Theta(x) = a_1^{(3)} = g(\\Theta_{10}^{(2)}a_0^{(2)} + \\Theta_{11}^{(2)}a_1^{(2)} + \\Theta_{12}^{(2)}a_2^{(2)} + \\Theta_{13}^{(2)}a_3^{(2)}) \\newline \\end{align*} $$\nما قصد داریم متغیر جدیدی را به صورت $z_k ^{(j)}$ معرفی کنیم، که تابع $g$ آن را به عنوان ورودی می‌گیرد.\nدر مثال قبلی اگر متغیر $z$ را جایگزین کنیم: $$ \\begin{align*}a_1^{(2)} = g(z_1^{(2)}) \\newline a_2^{(2)} = g(z_2^{(2)}) \\newline a_3^{(2)} = g(z_3^{(2)}) \\newline \\end{align*} $$\nبه عبارت دیگر، برای لایه $j=2$ و گره $k$ متغیر $z$ به این صورت خواهد بود: $$ z_k ^{(2)} = \\Theta_{k,0} ^{(1)}x_0 + \\Theta_{k,1} ^{(1)}x_1 + \u0026hellip; + \\Theta_{k,n} ^{(1)} x_n $$\nبه طور مثال: $$ z_1 ^{(2)} = \\Theta_{1,0} ^{(1)}x_0 + \\Theta_{1,1} ^{(1)}x_1 + \\Theta_{1,2} ^{(1)} x_2 + \\Theta_{1,3} ^{(1)}x_3 $$ $$ a_1 ^2 = g(z_1 ^{(2)} ) $$\nما می‌توانیم محاسبات شبکه عصبی را به صورت برداری شده درآوریم، برای نمایش $x$ و $z^j$ به صورت برداری می‌توانیم بنویسیم:\n$$ \\begin{align*}x = \\begin{bmatrix}x_0 \\newline x_1 \\newline\\cdots \\newline x_n\\end{bmatrix} \u0026amp; z^{(j)} = \\begin{bmatrix}z_1^{(j)} \\newline z_2^{(j)} \\newline\\cdots \\newline z_n^{(j)}\\end{bmatrix}\\end{align*} $$\nبا تنظیم $x = a^{(1)}$ می‌توانیم معادله را به صورت زیر بازنویسی کنیم: $$ z^{(j)} = \\Theta^{(j - 1)} a^{(j - 1)} $$\nما ماتریس $\\Theta^{(j - 1)}$ با ابعاد $ s_j \\times (n+1) $ ($s_j$ تعداد گره های فعال ساز ما است) را با بردار $a^{(j - 1)}$ با ارتفاع $n+1$ ضرب می‌کنیم، که به عنوان خروجی به ما بردار $z^{(j)}$ را با ارتفاغ $s_j$ می‌دهد.\nاکنون ما یک بردار از گره های فعال ساز مان از لایه j ام داریم: $$ a^{(j)} = g(z^{(j)}) $$\nهمانطور که می‌بینیم g، تابع سیگموئید را به صورت عنصر به عنصر به هر یک از اعضای بردار $z^{(j)}$ اعمال می‌کند.\nو سپس می‌توانیم واحد بایاس که برابر ۱ است را بعد از محاسبه $a^{(j)}$ اضافه کنیم. واحد بایاس همان $a_0 ^{(1)}$ است که برابر با ۱ می‌باشد.\nقبل از محاسبه فرضیه نهایی اجازه دهید یک بردار $z$ دیگر را هم محاسبه کنیم: $$ z^{(j+1)} = \\Theta^{(j)} a^{(j)} $$\nاین بردار را از طریق ضرب ماتریس تتا بعد از $\\Theta^{(j - 1)}$ با مقادیر تمام گره های فعال سازی که به دست آورده ایم، محاسبه می‌کنیم.\nآخرین ماتریس تتا یعنی $\\Theta^{(j)}$ فقط یک ردیف خواهد داشت که در یک ستون $a^{(j)}$ ضرب می‌شود، به طوری که نتیجه آن یک عدد است.\nسپس فرضیه نهایی خودمان را به این صورت نتیجه می‌گیریم:\n$$ h_\\theta(x) = a^{(j+1)} = g(z^{(j+1)}) $$\nتوجه داشته باشید که در این مرحله آخر، بین لایه $j$ و لایه $j+1$ دقیقا همان کاری انجام می‌هیم که در رگرسیون لجستیک انجام دادیم.\nافزودن تمام این لایه های میانی در شبکه های عصبی به ما این امکان را می دهد که با ظرافت بیشتری فرضیه های غیر خطی جالب و پیچیده تری تولید کنیم!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/simplified-cost-gradient/",
	"title": "ساده شده تابع هزینه و گرادیان کاهشی",
	"tags": [],
	"description": "",
	"content": "تابع هزینه ما می‌توانیم دو حالت شرطی تابع هزینه خودمان در قسمت قبلی را در یک حالت فشرده شده بنویسیم:\n$$ Cost(h_\\theta(x), y) = - y \\hspace{0.2cm} log(h_\\theta(x)) - (1 - y) log(1 - h_\\theta(x)) $$\nدر خاطر داشته باشید وقتی که $y$ برابر $1$ است، قسمت $(1 - y) log(1 - h_\\theta(x))$ برار $0$ خواهد شد.\nاگر $y$ برابر با $1$ باشد، سپس قسمت $- y \\hspace{0.2cm} log(h_\\theta(x))$ برابر $0$ خواهد شد و در نتیجه تاثیری ندارد.\nدر نهایت می‌توانیم کل تابه هزینه را به این صورت بنویسیم:\n$$ J(\\theta) = - \\frac{1}{m} \\sum_{i = 1}^m [y^{(i)} log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\\theta(x^{(i)})) ] $$\nو پیاده سازی برداری شده به این صورت خواهد بود:\n$$ \\begin{align*} \u0026amp; h = g(X\\theta)\\newline \u0026amp; J(\\theta) = \\frac{1}{m} \\cdot \\left(-y^{T}\\log(h)-(1-y)^{T}\\log(1-h)\\right) \\end{align*} $$\nگرادیان کاهشی به یاد داشته باشید که شکل کلی گرادیان کاهشی به این صورت است:\n$$ \\begin{align*}\u0026amp; Repeat \\lbrace \\newline \u0026amp; \\theta_j := \\theta_j - \\alpha \\dfrac{\\partial}{\\partial \\theta_j}J(\\theta) \\newline \u0026amp; \\rbrace\\end{align*} $$\nمی‌توانیم قسمت مشتق را با استفاده از حساب دیفرانسیل محاسبه کنیم:\n$$ \\begin{align*} \u0026amp; Repeat \\lbrace \\newline \u0026amp; \\theta_j := \\theta_j - \\frac{\\alpha}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} \\newline \u0026amp; \\rbrace \\end{align*} $$\nتوجه داشته باشید که این الگوریتم مشابه الگوریتمی است که ما در رگرسیون خطی استفاده کردیم، هنوز باید به صورت همزمان همه مقادیر $\\theta$ را به روز کنیم.\nو پیاده سازی برداری شده به این صورت خواهد بود:\n$$ \\theta := \\theta - \\frac{\\alpha}{m} X^T g((X \\theta) -\\vec{y} ) $$\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/debugging-gradient/",
	"title": "اشکال زدایی گرادیان",
	"tags": [],
	"description": "",
	"content": "در این قسمت در مورد تکنیک هایی برای اطمینان از درستی کار گرادیان کاهشی صحبت مـی‌کنیم. و در ادامه در مورد نحوه انتخاب مقدار پارامتر آلفا.\nهمانطور که می‌دانیم کار گرادیان کاهشی پیدا کردن مقدار تتا برای ما است تا تابع هزینه مینیمم شود. می‌خواهیم نمودار تابع $J$ بر حسب دفعات انــــجام گرادیان کاهشی را رسم کنیم و تا متوجه بشویم که گرادیان کاهشی عملکرد درستی دارد یا نه!\nبه این ترتیب نموداری به این شکل خواهیم داشت: می‌بینیم که احتملا گرادیان کاهشی درست کار مـی‌کند چون بعد از هر بار انجام مقدار $J$ کاهش می‌یابد!\nهمـچنین مـی‌توانیم از آزمون همگرایی خودکار استفاده کنیم، به این صورت که اگر $J$ بعد از هر تکرار کاهشی کمتر از $E= 10^{-3}$ داشته باشد، اعلام همگرایی می‌کنیم، که تعیین مقدار این آستانه سخت است!\nاگر چنین نموداری داشتیم یعنی گرادیان کـاهـشـی به درستی کار نمی‌کند:\nو معمولا به این معنی است که باید از مقدار آلفا کوچک تری استفاده کنیم.\nو در شکل زیر می‌بینیم که بزرگی بیش از حد آلفا باعث واگرایی شده است. که هیـچوقت به مینیمم نمی‌رسد!\nو گاهی اوقات نیز ممکن اسـت به شکل زیر باشد که باید مقدار آلفا را کاهش دهیم و اگر مقدار آلفا بیش از حد کوچک باشد، گرادیان کاهشی دیر تر به همگرایی می‌رسد.\nمتوجه می‌شویم که مقدار خوب برای آلفا مقداری است که در هر بار تکرار الگوریتم گرادیان کاهشی، تابع هزینه $J$ کاهش یابد.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/linear-regression-one-variable/",
	"title": "رگرسیون خطی با یک متغیر",
	"tags": [],
	"description": "",
	"content": "بررسی نماد ها و مفاهیم مثلا در داده ی خانه ها نماد ها به این صورت هستند:    نماد      $m$ تعداد کل ردیف های جدول داده آموزش   $x$ متغیر های ورودی   $y$ متغیر های خروجی یا هدف    برای آدرس دهی در جدول به این شکل عمل می‌کنیم:\n$$(x_i, y_i) \\Rightarrow x_1= 2104, y_1 = 460$$\nاینجا منظور از $i$ اندیس داده در جدول است.\n همانطور که می‌بینید هدف ما اینکه با دادن مجموعه آموزشی به الگوریتم، تابعی را به وجود بیاوریم که با گرفتن متغیر ورودی $x$ متغیر خروجی یعنی $y$ را پیش بینی کند! که به تابع $h$ ، فرضیه می‌گوییم.\nتابع $h$ را به این شکل نمایش می‌‌دهیم: $$ h_\\theta(x) = \\theta_0 + \\theta_1x $$\nکه این در واقع رگرسیون خطی تک متغیره است، $x$ همان تک متغیر مدل است، $ \\theta_0, \\theta_1 $ نیز پارامتر های مدل هستند.\nخط قرمز همان تابع $h$ است که برای پیش بینی قیمت خانه با متغیر $x$ به دست آمده\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week9/",
	"title": " هفته نهم",
	"tags": [],
	"description": "",
	"content": "  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week8/choosing-the-number-of-clusters/",
	"title": "انتخاب تعداد خوشه ها",
	"tags": [],
	"description": "",
	"content": "انتخاب $K$ می‌تواند کاملا خودسرانه و مبهم باشد.\nروش elbow: نمودار هزینه $J$ و تعداد خوشه های $K$ را رسم کنید، با افزایش تعداد خوشه ها مقدار تابع هزینه باید کاهش یابد، و سپس یکسان شود. $K$ را در نقطه ای انتخاب کنید که تابع هزینه در حال یکسان شدن است.\nبا افزایش $K$، $J$ همیشه کاهش می‌یابد. اما یک استثنا وجود دارد اگر k-means در مینیمم محلی گیر کند.\n بحث در مورد اشکالات K-Means http://stats.stackexchange.com/questions/133656/how-to-understand-the-drawbacks-of-k-means\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week10/",
	"title": " هفته دهم",
	"tags": [],
	"description": "",
	"content": "  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/learning-curves/",
	"title": "منحنی های یادگیری",
	"tags": [],
	"description": "",
	"content": "آموزش 3 نمونه به آسانی خطایی برابر با صفر خواهد داشت زیرا امکان پیدا کردن یک منحنی درجه دو که دقیقا با این سه نقطه برخورد کند همیشه وجود دارد!\n  هرچه مجموعه آموزشی بزرگتر می‌شود، خطای تابع درجه دو افزایش می‌یابد.\n  مقدار خطا پس از تعیین اندازه m یا مجموعه آموزشی، ثابت خواهد بود.\n  با بایاس زیاد مجموعه آموزشی کوچک: باعث می‌شود تا $J_{train}\\left ( \\Theta \\right )$ کم و $J_{cv}\\left ( \\Theta \\right )$ زیاد باشد.\nمجموعه آموزشی بزرگ: باعث می‌شود تا $J_{train}\\left ( \\Theta \\right )$ و $J_{CV}\\left ( \\Theta \\right )$ هر دو مقدار زیادی داشته باشند و $J_{train}\\left ( \\Theta \\right ) \\approx J_{CV}\\left ( \\Theta \\right )$\nاگر یک الگوریتم با مشکل بایاس زیاد مواجه باشد، اضافه کردن داده آموزشی (به تنهایی) موثر نخواهد بود.\nبرای مقدار واریانس زیاد، روابط زیر را به لحاظ اندازه مجموعه آموزشی داریم:\nبا واریانس زیاد مجموعه آموزشی کوچک: $J_{train}\\left ( \\Theta \\right )$ مقداری کم و $J_{CV}\\left ( \\Theta \\right )$ مقدار زیادی داشته باشد.\nمجموعه آموزشی بزرگ: $J_{train}\\left ( \\Theta \\right )$ متناسب با اندازه مجموعه آموزشی افزایش می‌یابد و $J_{CV}\\left ( \\Theta \\right )$ بدون ثابت شدن کاهش می یابد. همچنین $J_{train}\\left ( \\Theta \\right ) \u0026lt; J_{CV}\\left ( \\Theta \\right )$ خواهد بود و اختلاف قابل توجهی خواهند داشت.\nاگر یک الگوریتم با مشکل واریانس زیاد مواجه باشد، داده آموزشی بیشتر احتمالا موثر خواهد بود.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week5/gradient-checking/",
	"title": "بررسی گرادیان",
	"tags": [],
	"description": "",
	"content": "بررسی گرادیان به شما این اطمینان را می‌دهد که پس انتشار همانطور که در نظر گرفته شده کار می‌کند‌ (مطابق هدف کار می‌کند).\nما می‌توانیم مشتق تابع خود را به این صورت تقریب بزنیم: $$ \\frac{\\partial}{\\partial \\Theta} J(\\Theta) \\approx \\frac { J(\\Theta + \\epsilon) - J(\\Theta - \\epsilon) } {2 \\epsilon} $$\nبا چند ماتریس تتا، می‌توانیم مشتق را با توجه به $\\Theta _j$ تقریب بزنیم:\n$$ \\frac{\\partial}{\\partial \\Theta} J(\\Theta) \\approx \\frac{ J(\\Theta _1, \u0026hellip;, \\Theta _j + \\epsilon, \u0026hellip;, \\Theta _n) - J(\\Theta _1, \u0026hellip;, \\Theta _j - \\epsilon, \u0026hellip;, \\Theta _n)} {2 \\epsilon} $$\nمقدار کوچک ϵ (epsilon) مانند $\\epsilon = 10 ^ {-4}$ ، تضمین می‌کند که ریاضیات به درستی کار می‌کنند، اگر مقدار ϵ خیلی کوچک باشد امکان دارد که با مشکلات عددی مواجه شویم.\nاز این رو، ما فقط اپسیلون را به ماتریس $\\Theta _j$ اضافه یا کم می‌کنیم. در اکتاو می‌توانیم آن را به صورت زیر انجام دهیم:\n;epsilon = 1e-4 ,for i = 1:n ;thetaPlus = theta ;thetaPlus(i) += epsilon ;thetaMinus = theta ;thetaMinus(i) -= epsilon gradApprox(i) = (J(thetaPlus) - J(thetaMinus))/(2*epsilon) ;end  قبلا نحوه محاسبه deltaVector را مشاهده کردیم، و بعد از محاسبه بردار gradApprox در بالا می‌توانیم آن را چک کنیم $gradApprox \\approx deltaVector$ .\nزمانی که یک بار تأیید شد که الگوریتم پس انتشار شما درست کار می‌کند، دیگر نیازی به محاسبه مجدد gradApprox نیست، زیرا که قطعه کد محاسبه gradApprox می‌تواند بسیار کند باشد!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/examples-1/",
	"title": "مثال ها قسمت اول",
	"tags": [],
	"description": "",
	"content": "عملگر منطقی AND یک مثال ساده از کاربرد شبکه های عصبی پیش بینی نتیجه عملگر منطقی AND بین دو متغیر $x_1$ و $x_2$ است.\nمی‌دانیم که جدول درستی عملگر AND به این صورت است:\nشکل کلی توابع به صورت زیر است:\n$$ \\begin{align*}\\begin{bmatrix}x_0 \\newline x_1 \\newline x_2\\end{bmatrix} \\rightarrow\\begin{bmatrix}g(z^{(2)})\\end{bmatrix} \\rightarrow h_\\Theta(x)\\end{align*} $$\nبه خاطر داشته باشید که $x_0$ متغیر بایاس ما است، و همواره برابر با مقدار 1 است.\n و ماتریس وزن های خود را به این صورت تنظیم می‌کنیم:\n$$ \\Theta^{(1)} = [-30 \\hspace{0.5cm} 20 \\hspace{0.5cm} 20] $$\nاین کار باعث می‌شود که نتیجه تابع فرضیه ۱ شود، اگر هر دو متغیر $x_1$ و $x_2$ ۱ باشند.\nبه صورت خلاصه می‌توانیم این مثال را به شکل زیر شرح دهیم: عملگر منطقی OR عملگر OR شبیه به AND است، اما فقط نیاز داریم که وزن گره بایاس را به $-10$ تغییر دهیم:\nعملگر منطقی NAND عملگر منطقی NOT "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/advanced-optimization/",
	"title": "بهینه سازی پیشرفته",
	"tags": [],
	"description": "",
	"content": "Conjugate gradient, BFGS و L-BFGS راه های پیچیده تر و سریع تری برای بهینه سازی $\\theta$ به جای گرادیان کاهشی هستند.\nپیشنهاد می‌شود که این الگوریتم های پیچیده را خودتان ننویسید (مگر اینکه در محاسبات عددی متخصص باشید)، و به جای آن از کتابخانه ها استفاده کنید، زیرا قبلا آزمایش شده اند و بسیار بهینه شده اند.\nابتدا لازم است تابعی بسازیم که دو مقدار زیر را با ورودی مقدار $\\theta$ برگرداند:\n$$ \\begin{align*} \u0026amp; J(\\theta) \\newline \u0026amp; \\dfrac{\\partial}{\\partial \\theta_j}J(\\theta)\\end{align*} $$\nتابعی می‌نویسیم که هر دو این مقادیر را بر گرداند:\nfunction [jVal, gradient] = costFunction(theta) ;jVal = [...code to compute J(theta)...] ;gradient = [...code to compute derivative of J(theta)...] end  سپس می‌توانیم از الگوریتم بهینه سازی ()fminunc در اکتاو به همراه تابع ()optimset برای ساخت یک object شامل تنظیمات و گزینه هایی که می‌خواهیم به عنوان ورودی به تابع ()fminunc بدهیم.\n;options = optimset('GradObj', 'on', 'MaxIter', 100) ;initialTheta = zeros(2,1) ;[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options)  به عنوان ورودی به تابع ()fminunc:\nتابع هزینه، بردار مقادیر تتا، و options را که از قبل درست کرده ایم می‌دهیم.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/polynomial-regression/",
	"title": "رگرسیون چند جمله ای",
	"tags": [],
	"description": "",
	"content": "رگرسیون چند جمله ای تابع فرضیه $h$ می‌تواند خطی نباشد، اگر تناسب خوبی با داده های ما ندارد، می‌توانیم برای تغییر منحنی تابع از توابع چند جمله ای استفاده کنیم تا به تناسب بهتری برای داده ها برسیم.\nفرض کنید که تابع فرضیه ما $ h_\\theta(x) = \\theta_0 + \\theta_1 x_1$ باشد بنابراین می‌توانیم ویژگی جدیدی بر پایه ویژگی $x_1$ اضافه کنیم تا به تابعی درجه دو برسیم:\n$$ {\\color{Blue} h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2}$$\nیا به تابعی درجه سه: $$ {\\color{Green} h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2 + \\theta_3 x_1^3}$$\nبه طور مثال برای تابع درجه سه می‌نویسیم:\nهمچنین می‌توانیم از نمودار ریشه دوم استفاده کنیم:\n$$ h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 \\sqrt{x}$$\nتوجه کنید بعد از اینکه ویژگی های جدید خود را به این روش اضافه کردید، انجام مقیاس بندی ویژگی برای برای ویژگی ها یا همان متغیر ها خیلی مهم است!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost1/",
	"title": "تابع هزینه قسمت اول",
	"tags": [],
	"description": "",
	"content": "تابع هزینه با این تابع می‌توانیم بهترین خط مستقیم را برای داده هایمان به دست آوریم. با انتخاب های متفاوت برای پارامتر های $\\theta_1$ و $\\theta_0$ تابع های فرضیه متفاوتی به دست می‌آوریم: در رگرسیون خطی مجموعه آموزشی مثل این نمودار داریم و می‌خواهیم مقادیری برای $\\theta_0$ و $\\theta_1$ به دست آوریم به طوری که خط راستی که رسم می‌کنیم، بهترین تطابق را با داده هایمان داشته باشد.\nبنابراین مقادیر را باید طوری تعیین کنیم که خروجی تابع $h$ بر حسب $x$ تا جای ممکن به مقادیر واقعی $y$ در مجموعه داده آموزشی نزدیک باشد.\n$$ h_\\theta(x) = \\theta_0 + \\theta_1x $$ $$ J(\\theta_0,\\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y_i} - y_i)^2 = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x) - y_i)^2 $$\nبنابراین تابع هزینه $J$ را به این صورت تعریف می‌کنیم. که تابع خطای مجذور نیز نامیده می‌شود، و هدف آن مینیمم کردن $\\theta_0$ و $\\theta_1$ است. دلیل حضور $\\frac{1}{2m}$ نیز برای این است که فرمول ریاضی آسان تر شود، با قرار دادن 2 در کسر یعنی عبارت را نصف می‌کنیم چون می‌دانیم که مینیمم کردن نصف چیزی مثل مینیمم کردن همان چیز است!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week11/",
	"title": " هفته یازدهم",
	"tags": [],
	"description": "",
	"content": "  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week8/dimensionality-reduction/",
	"title": "کاهش ابعاد",
	"tags": [],
	"description": "",
	"content": "انگیزه ۱: فشرده سازی داده ها  اگر داده های زائد زیادی داشته باشیم ممکن است بخواهیم ابعاد ویژگی های خود را کاهش دهیم. برای انجام این کار، دو ویژگی بسیار مرتبط پیدا می‌کنیم، آنها را رسم می‌کنیم و یک خط جدید ایجاد می‌کنیم که به نظر می‌رسد هر دو ویژگی را به طور دقیق توصیف می‌کند. ما همه ویژگی های جدید را روی این خط واحد قرار می‌دهیم.  انجام کاهش ابعاد باعث کاهش کل داده هایی می‌شود که باید در حافظه کامپیوتر ذخیره کنیم و الگوریتم یادگیری ما را تسریع می‌کند.\nدر کاهش ابعاد ، ما در حال کاهش ویژگی های خود هستیم تا تعداد نمونه های خود. متغیر $m$ ما در همان اندازه قبلی خواهد ماند، $n$ یعنی تعداد ویژگی های هر نمونه از $x ^{(1)}$ تا $x ^ {(m)}$ کاهش خواهد یافت.\n انگیزه ۲: مصور سازی مصور سازی داده هایی که بیش از سه بعد هستند آسان نیست. ما می‌توانیم ابعاد داده های خود را به ۳ یا کمتر کاهش دهیم تا آنها را ترسیم کنیم.\nما نیاز داریم که ویژگی های جدید پیدا کنیم، $z_1, z_2$ (و شاید $z_3$)، که می‌توانند به طور موثر همه ویژگی های دیگر را خلاصه کنند.\nبه طور مثال: صدها ویژگی مرتبط با سیستم اقتصادی یک کشور ممکن است همه در یک ویژگی که شما آن را \u0026ldquo;فعالیت اقتصادی\u0026rdquo; می‌نامید، ترکیب شوند.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/deciding-what-to-do-next/",
	"title": "تصمیم گیری درباره اقدامات بعدی",
	"tags": [],
	"description": "",
	"content": "روند تصمیم‌گیری ما می‌تواند به به شرح زیر باشد:\n جمع‌آوری نمونه آموزشی بیشتر: اصلاح واریانس زیاد استفاده از مجموعه کوچکتری از ویژگی‌ها: اصلاح واریانس زیاد اضافه کردن ویژگی: اصلاح بایاس زیاد اضافه کردن ویژگی‌های چندجمله‌ای: اصلاح بایاس زیاد کاهش $\\lambda$: اصلاح بایاس زیاد افزایش $\\lambda$: اصلاح واریانس زیاد  تشخیص شبکه‌های عصبی   یک شبکه عصبی با تعداد پارامترهای کم مستعد underfitting خواهد بود. همچنین این شبکه عصبی از نظر محاسباتی ارزان است.\n  یک شبکه عصبی با تعداد بیشتری از پارامتر مستعد overfitting خواهد بود و از نظر محاسباتی گران است. در این شرایط می‌توانید از منظم‌سازی (افزایش $\\lambda$) برای اصلاح overfitting استفاده کنید.\n  استفاده از یک عدد لایه پنهان پیش‌ فرض مناسبی برای شروع است. با کمک مجموعه cross validation می‌توان شبکه عصبی را روی تعدادی از لایه‌های پنهان آموزش داد.\nانتخاب مدل انتخاب M به ترتیب چندجمله‌ای‌ها.\nچگونه می‌توانیم تعیین کنیم که کدام یک از پارامترهای $\\theta$ را در مدل قرار دهیم (معروف به \u0026ldquo;انتخاب مدل\u0026rdquo;)؟\nراه‌های گوناگونی برای حل این مسئله وجود دارد:\n جمع‌آوری داده بیشتر (که روش بسیار سختی است). انتخاب مدلی که بیشترین سازگاری را با داده دارد و باعث overfitting نخواهد شد (این روش هم بسیار مشکل است). کم کردن امکان overfitting از طریق منظم‌سازی.  بایاس: خطای تقریب (اختلاف مقدار مورد نظر و مقدار بهینه)\n بایاس زیاد = Underfitting (BU) $J_{train }\\left ( \\Theta \\right )$ و $J_{CV }\\left ( \\Theta \\right )$ مقادیر زیادی خواهند داشت و $J_{train }\\left ( \\Theta \\right ) \\approx J_{CV}\\left ( \\Theta \\right )$  واریانس: خطای تخمین به دلیل داده‌های محدود\n واریانس زیاد = Overfitting (VO) $J_{train }\\left ( \\Theta \\right )$ کم خواهد بود و $J_{CV }\\left ( \\Theta \\right ) \\gg J_{train}\\left ( \\Theta \\right )$  آگاهی برای متوازن کردن بایاس و واریانس\n مدل پیچیده $\\Leftarrow$ حساس به دیتا $\\Leftarrow$ تحت تاثیر تغییرات در X $\\Leftarrow$ واریانس زیاد، بایاس کم مدل ساده $\\Leftarrow$ پایدارتر $\\Leftarrow$ با تغییرات X چندان تغییر نمی‌کند $\\Leftarrow$ واریانس کم، بایاس زیاد  یکی از مهم‌ترین اهداف در یادگیری: پیدا کردن مدلی که در بایاس و واریانس توازن داشته باشد.\nتاثیرات منظم‌سازی:\n  مقادیر کوچک $\\lambda$ به مدل اجازه می‌دهند تا نسبت به اختلالاتی که به واریانس بزرگ منتهی می‌شوند، به خوبی وفق پیدا کنند $\\Leftarrow$ Overfitting.\n  مقادیر بزرگ $\\lambda$ پارامترهای وزن را که به بایاس بزرگ منتهی می‌شوند به صفر می‌رساند $\\Leftarrow$ Underfitting.\n  تاثیرات پیچیدگی مدل:\n  چندجمله‌ای‌های درجه پایین (پیچیدگی پایین مدل) بایاس زیاد و واریانس کم دارند. در این شرایط مدل همواره سازگاری کمی خواهد داشت.\n  چندجمله‌ای‌های درجه بالا (پیچیدگی بالای مدل) با داده آموزشی سازگاری بسیار خوب و با داده آزمون سازگاری بسیار کمی خواهد داشت. این مسئله باعث بایاس کم و واریانس بسیار زیاد روی داده آموزشی خواهد شد.\n  در واقعیت، ما می‌خواهیم مدل میانه‌ای را انتخاب کنیم که به خوبی اعتبارسنجی شود و همچنین به خوبی با داده سازگار باشد.\n  یک قانون معمول هنگام اجرای تشخیص:\n  نمونه‌های آموزشی بیشتر واریانس زیاد را اصلاح می‌کند اما تاثیری بر بایاس زیاد ندارد.\n  ویژگی‌های کمتر واریانس زیاد را اصلاح می‌کند اما تاثیری بر بایاس زیاد ندارد.\n  ویژگی‌های اضافه بایاس زیاد را اصلاح می‌کند اما بر واریانس زیاد تاثیری ندارد.\n  اضافه کردن چند‌جمله‌ای و ویژگی‌های متقابل بایاس زیاد را اصلاح می‌کند اما تاثیری بر واریانس زیاد ندارد.\n  هنگام استفاده از گرادیان کاهشی، کاهش $\\lambda$ می‌تواند بایاس زیاد را اصلاح کند و افزایش $\\lambda$ واریانس زیاد را اصلاح می‌کند. ($\\lambda$ پارامتر منظم‌سازی است.)\n  هنگام استفاده از شبکه‌های عصبی، شبکه‌های کوچک بیشتر در معرض Underfitting و شبکه‌های بزرگ بیشتر در معرض Overfitting هستند.\n  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week5/random-initialization/",
	"title": "مقدار دهی اولیه تصادفی",
	"tags": [],
	"description": "",
	"content": "مقدار دهی اولیه همه وزن های تتا (theta weights) به مقدار $0$ برای شبکه های عصبی کار ساز نیست!\nوقتی از پس انتشار استفاده می‌کنیم، همه گره ها به طور مکرر به یک مقدار مشابه به روز می‌شوند. اما در عوض می‌توانیم وزن های ماتریس $\\Theta$ خودمان را به روش زیر به صورت تصادفی مقدار دهی کنیم:\nاز این رو، ما هر $\\Theta _{ij} ^{(l)}$ را به صورت عددی تصادفی بین $[ - \\epsilon, \\epsilon]$ مقدار دهی می‌کنیم، و استفاده از فرمول بالا تضمین می‌کند که این حد مد نظر را به دست می‌آوریم، همین رویه برای همه $\\Theta$ ها انجام می‌شود.\nدر زیر قطعه کدی است که می‌توانید این موضوع را آزمایش کنید:\nIf the dimensions of Theta1 is 10x11, Theta2 is 10x11 and Theta3 is 1x11 ;Theta1 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON ;Theta2 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON ;Theta3 = rand(1,11) * (2 * INIT_EPSILON) - INIT_EPSILON  rand(x,y) تابعی در اوکتاو است که ماتریسی از اعداد حقیقی تصادفی بین 0 و 1 ایجاد می‌کند.\nاپسیلون استفاده شده در بالا ربطی به اپسیلون استفاده شده در قسمت بررسی گرادیان ندارد.\n "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/examples-2/",
	"title": "مثال ها قسمت دوم",
	"tags": [],
	"description": "",
	"content": "عملگر XNOR از قسمت قبل به خاطر داریم که ماتریس وزن $\\Theta^{(1)}$ برای عملگر های منطقی AND، OR و NOR به این صورت بود: $$ \\begin{align*}AND:\\newline\\Theta^{(1)} \u0026amp;=\\begin{bmatrix}-30 \u0026amp; 20 \u0026amp; 20\\end{bmatrix} \\newline NOR:\\newline\\Theta^{(1)} \u0026amp;= \\begin{bmatrix}10 \u0026amp; -20 \u0026amp; -20\\end{bmatrix} \\newline OR:\\newline\\Theta^{(1)} \u0026amp;= \\begin{bmatrix}-10 \u0026amp; 20 \u0026amp; 20\\end{bmatrix} \\newline\\end{align*} $$\nبا ترکیب آن ها می‌توانیم عملگر منطقی XNOR را به دست آوریم: $$ \\begin{align*}\\begin{bmatrix}x_0 \\newline x_1 \\newline x_2\\end{bmatrix} \\rightarrow\\begin{bmatrix}a_1^{(2)} \\newline a_2^{(2)} \\end{bmatrix} \\rightarrow\\begin{bmatrix}a^{(3)}\\end{bmatrix} \\rightarrow h_\\Theta(x)\\end{align*} $$\nبرای انتقال از لایه اول به لایه دوم می‌توانیم از ماتریس $\\Theta^{(1)}$ استفاده کنیم، که ترکیبی از مقادیر AND و NOR است:\n$$ \\Theta^{(1)} =\\begin{bmatrix}-30 \u0026amp; 20 \u0026amp; 20 \\newline 10 \u0026amp; -20 \u0026amp; -20 \\end{bmatrix} $$\nو برای انتقال از لایه دوم به لایه سوم از ماتریس $\\Theta^{(2)}$ استفاده می‌کنیم، که شامل مقادیر OR می‌باشد: $$ \\Theta^{(2)} =\\begin{bmatrix} -10 \u0026amp; -20 \u0026amp; -20 \\end{bmatrix} $$\nحالا مقادیر مربوط به گره های فعال ساز را می‌نویسیم: $$ \\begin{align*}\u0026amp; a^{(2)} = g(\\Theta^{(1)} \\cdot x) \\newline\u0026amp; a^{(3)} = g(\\Theta^{(2)} \\cdot a^{(2)}) \\newline\u0026amp; h_\\Theta(x) = a^{(3)}\\end{align*} $$\nو حالا عملگر XNOR را با استفاده از یک لایه پنهان با دو گره داریم!\nبه صورت خلاصه:\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/multiclass-classification/",
	"title": "طبقه بندی چند کلاسه",
	"tags": [],
	"description": "",
	"content": "هنگامی که در طبقه بندی، بیش از دو دسته داشته باشیم به جای $y = \\text{ {0,1} }$ تعاریف خود را به $ y = \\text { {0,1, \u0026hellip;, n} } $ گسترش می‌دهیم.\nاز آنجا که ما مسئله خودمان را به n+1 (n+1 به این خاطر که ایندکس از صفر شروع می‌شود) مسئله طبقه بندی باینری تقسیم می‌کنیم، در هر کدام از آن ها ما احتمال عضویت $y$ را در یکی از کلاس هایمان پیش بینی می‌کنیم:\n$$ \\begin{align*}\u0026amp; y \\in \\lbrace0, 1 \u0026hellip; n\\rbrace \\newline\u0026amp; h_\\theta^{(0)}(x) = P(y = 0 | x ; \\theta) \\newline\u0026amp; h_\\theta^{(1)}(x) = P(y = 1 | x ; \\theta) \\newline\u0026amp; \\cdots \\newline\u0026amp; h_\\theta^{(n)}(x) = P(y = n | x ; \\theta) \\newline\u0026amp; \\mathrm{prediction} = \\max_i( h_\\theta ^{(i)}(x) )\\newline\\end{align*} $$\nما در واقع یک کلاس را انتخاب می‌کنیم و سپس بقیه را به یک کلاس دوم واحد تبدیل می‌کنیم، این کار را به طور مکرر انجام می‌دهیم ، و binary logistic regression برای هر کدام از آن ها به کار می‌بریم، و سپس از تابع فرضیه ای برای پیش بینی استفاده می‌کنیم که بالاترین مقدار را برگرداننده باشد.\nتصویر زیر نحوه طبقه بندی 3 کلاس را نشان می‌دهد:\nبه طور خلاصه:\nبرای هر $class \\text{ } i$ تابع فرضیه logistic regression classifier را برای پیش‌بینی احتمال $y=i$ تشکیل بدهید.\nو برای یک ورودی جدید به اسم $x$ ، $i$ امین کلاسی که ماکسیمم است را انتخاب کنید:\n$$ \\max_i ( h_\\theta^{(i)} (x) ) $$\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/normal-equation/",
	"title": "معادله نرمال",
	"tags": [],
	"description": "",
	"content": "معادله نرمال الگوریتم گرادیان کاهشی روشی بود برای مینیمم کردن تابع $J$ ، اما روش دومی نیز وجود دارد که بدون داشتن حلقه تکرار این کار را انجام بدهد که معادله نرمال نام دارد.\nفرض کنید که تابع هزینه درجه دو ای مثل این داریم: $$ J(\\theta) = a\\theta^2 + b\\theta + c $$ $$ \\frac{\\partial} {\\partial x} J(\\theta) \\overset{\\underset{\\mathrm{set}}{}}{=} 0 $$\nکه برای مینیمم کردن این تابع درجه دو مشتق آن را می‌گیریم و برابر با 0 قرار می‌دهیم، که این به ما اجازه می‌دهد که مقدار $\\theta$ را برای مینیمم کردن تابع پیدا کنیم.\nاما مسئله ای که برای ما جالب است $\\theta$ یک عدد حقیقی نیست، بلکه یک بردار در ابعدا 1+n است:\nبرای محاسبه اینکه چطور تابع هزینه را مینیمم کنیم باید مشتق جزئی تابع $J$ را برای هر کدام از تتا ها بگیریم و برابر با 0 قرار دهیم، بعد از محاسبه همه معادله ها مقدار تتا ای که تابع $J$ مینیمم می‌شود را به دست می‌آوریم.\nاگر مجموعه آموزشی به این شکل داشته باشیم:\nمعادله نرمال ما برای محاسبه تتا به این صورت خواهد بود:\n$$ \\theta = (X^T X)^{-1} X^T y $$\nبا استفاده از معادله نرمال نیازی به مقیاس بندی ویژگی نداریم، و برای مقایسه گرادیان کاهشی و معادله نرمال:\n   گرادیان کاهشی معادله نرمال     به تنظیم پارامتر آلفا نیاز دارد به تنظیم پارامتر آلفا نیاز ندارد   به تکرار نیاز دارد به تکرار نیاز ندارد   مرتبه زمانی اش $O(kn)^3 $ است مرتبه زمانی اش $O(n)^3$ است   برای تعداد ویژگی های زیاد خوب کار می‌کند برای تعداد ویژگی های زیاد کند است    "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost2/",
	"title": "تابع هزینه قسمت دوم",
	"tags": [],
	"description": "",
	"content": "تا اینجا به طور خلاصه تمام چیزی که از تابع هزینه می‌دانیم در زیر آمده است:\nاما اجازه بدید برای ساده سازی تابع فرضیه را تنها با یک پارامتر به این شکل در نظر بگیریم: $ h_\\theta(x) = \\theta_1x $ و سه مقدار مختلف $0$، $5.0 $ و $1$ رو حساب کنیم \u0026hellip;\nمثلا برای مقدار تتا برابر با $1$ محاسبات زیر را خواهیم داشت:\n$$ {\\color{Red} J(\\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\theta_1x - y_i)^2 \\Rightarrow \\frac{1}{2m} (0^2 + 0^2 + 0^2) = 0 } $$ به همین صورت برای دو مقدار دیگر داریم:\n$$ {\\color{Blue} J(0.5) = \\frac{1}{2m} [ (0.5 - 1)^2 + (1-2)^2 + (1.5 -3)^2] \\Rightarrow 0.58 } $$ $$ {\\color{Green} J(0) = \\frac{1}{2m} ( 1^2 + 2^2 + 3^2 +) \\Rightarrow 2.3 }$$\nو اگر به همین ترتیب برای مقادیر دیگر رسم کنیم:\nمتوجه می‌شویم که به ازای هر مقدار تتا به یک تابع فرضیه متفاوت و یک مقدار متفاوت برای تابع $J$ می‌رسیم و همینطور که می‌بینیم در نقطه $1$ در مینیمم ترین حالت ممکن هستیم و این همان هدف ما است!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/dictionary/",
	"title": "لغت نامه دوره ",
	"tags": [],
	"description": "",
	"content": "فهرست تمام لغات تخصصی که در ترجمه دوره استفاده شده در این قسمت موجود است، لطفا اگر پیشنهاد بهتری برای هر کدام دارید مشارکت کنید.\nراهنما:\nکلماتی که در قسمت ترجمه none نوشته شده ترجمه آن ها هنوز معلوم نیست.\n   لغت  ترجمه      machine learning یادگیری ماشین   supervised learning یادگیری با نظارت   unsupervised learning یادگیری بدون نظارت   clustering خوشه بندی   non-clustering غیر خوشه بندی   linear-regression رگرسیون خطی   data داده   hypothesis فرضیه   cost function تابع هزینه   parameter پارامتر   squared error function تابع خطای مجذور   contour plot نمودار کانتور   gradient descent گرادیان کاهشی   convex محدب   vector بردار   partial derivative مشتق جزئی   feature scaling مقیاس بندی ویژگی   mean normalization none   automatic convergence test آزمون همگرایی خودکار   polynomial regression رگرسیون چند جمله ای   quadratic درجه دو   cubic درجه سه   square root ریشه دوم   normal equation معادله نرمال   logistic regression رگرسیون لجستیک   classification طبقه بندی   overfit none   regularization منظم سازی   binary classification طبقه دودویی   representation ارائه   sigmoid سیگموئید   decision boundary مرز تصمیم گیری   vectorized برداری شده   conjugate gradient گرادیان مزدوج   underfitting none   fit none   bias بایاس   variance واریانس   generalize تعمیم داده   model مدل   model selection انتخاب مدل   identity matrix ماتریس همانی   non-invertible وارون ناپذیر   neural network شبکه عصبی   model representation ارائه مدل   cell body بدنه سلول   dendrites دنریت   axon اکسون   spikes اسپایک   logistic unit واحد لجستیک   unit واحد   activation function تابع فعال سازی   activation units واحد های فعال سازی   input layer لایه ورودی   output layer لایه خروجی   hidden layers لایه پنهان   element-wise عنصر به عنصر   node گره   class کلاس   nested summation جمع تو در تو   backpropagation پس انتشار   accumulator انباشتگر   non-multiclass غیر چند کلاسه   unroll باز کردن   gradient checking بررسی گرادیان   epsilon اپسیلون   octave اوکتاو   forward propagation انتشار به جلو   training set مجموعه آموزش   test set مجموعه آزمون   misclassification طبقه بندی غلط   training example نمونه آموزشی   debugging gradient اشکال زدایی گرادیان   predictor پیش بینی کننده   validation set مجموعه اعتبار سنجی   learning rate نرخ یادگیری   local minimum مینیمم موضعی   approximation error خطای تقریب   estimation error خطای تخمین   market segmentation تقسیم بندی بازار   test data داده های آزمون   test error خطای آزمون   support vector machine ماشین بردار پشتیبان   label برچسب                            "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week8/pca-problem-formulation/",
	"title": "تحلیل اجزای اصلی فرمول مسئله",
	"tags": [],
	"description": "",
	"content": "محبوب ترین الگوریتم کاهش ابعاد، تحلیل اجزای اصلی یا PCA است.\nفرمول مسئله باتوجه به ۲ ویژگی $x_1$ و $x_2$ ،ما می‌خواهیم یک خط واحد پیدا کنیم که به طور موثر هر دو ویژگی را همزمان توصیف کند. سپس ویژگی های قدیمی خود را بر روی این خط جدید ترسیم می‌کنیم تا یک ویژگی واحد جدید بدست آوریم.\nهمین کار را می توان با سه ویژگی انجام داد.\nهدف PCA کاهش میانگین تمام فواصل هر ویژگی تا خط projection است. این خطای projection است.\nکاهش از ۲ بعدی به ۱ بعدی: جهتی را پیدا کنید (بردار $u^{(1)} \\in \\mathbb{R} ^ n $) که بتوان داده ها را بر روی آن نمایش داد، تا خطای projection به حداقل برسد.\nمورد کلی تر به شرح زیر است:\nکاهش از n بعدی به k بعدی: به تعداد k بردار پیدا کنید $u^{(1)}, u^{(2)}, \u0026hellip;, u^{(k)}$ که داده ها را بر روی آن ها نمایش دهید، تا خطای projection به حداقل برسد.\nاگر از ۳ بعدی به ۲ بعدی تبدیل می‌کنیم، داده ها را باید بر روی ۲ جهت نمایش دهیم، بنابراین $k=2$ خواهد بود.\nPCA رگرسیون خطی نیست   در رگرسیون خطی، ما خطای مجذور از هر نقطه به خط پیش بینی کننده را به حداقل می‌رسانیم. اینها فاصله های عمودی هستند.\n  در PCA، ما کمترین فاصله یا کوتاه ترین فاصله های قائم (ارتودنسی) را تا نقاط داده خود به حداقل می‌رسانیم.\n  به طور کلی در رگرسیون خطی، ما تمام نمونه های خود را در$x$ را گرفته و از پارامتر های موجود در$\\Theta$ برای پیش بینی $y$ استفاده می‌کنیم.\nدر PCA، ما در حال گرفتن تعدادی ویژگی هستیم $x_1, x_2, \u0026hellip;, x_n$، و نزدیک ترین مجموعه داده مشترک بین آن ها را پیدا می‌کنیم. ما سعی در پیش بینی هیچ نتیجه ای نداریم و هیچ وزن تتایی را روی ویژگی ها اعمال نمی‌کنیم.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/prioritizing-what-to-work-on/",
	"title": "اولویت بندی کارها",
	"tags": [],
	"description": "",
	"content": "راه‌های متفاوتی در برخورد با یک مسئله یادگیری ماشین وجود دارد:\n  جمع‌آوری داده‌های زیاد (برای مثال مسئله \u0026ldquo;کوزه عسل\u0026rdquo;. اما این روش در تمامی موارد پاسخگو نخواهد بود).\n  ایجاد ویژگی‌های پیچیده (برای مثال: استفاده از داده‌های سرتیتر ایمیل در ایمیل‌های spam).\n  توسعه الگوریتم‌هایی که ورودی‌ها را به گونه متفاوتی پردازش کنند (تشخیص غلط‌های املایی در spam).\n  اما انتخاب این که کدام یک از این گزینه‌ها مفید خواهد بود مشکل است.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week5/putting-it-together/",
	"title": "Putting It Together",
	"tags": [],
	"description": "",
	"content": "ابتدا معماری شبکه خود را انتخاب کنید!\nلایه های شبکه عصبی خود را انتخاب کنید، از جمله اینکه چند گره پنهان در هر لایه و در کل چند لایه می‌خواهد داشته باشید.\n تعداد گره های ورودی = ابعاد ویژگی های $x^{(i)}$ تعداد گره های خروجی = تعداد کلاس ها (طبقه بندی ها) تعداد گره های پنهان در هر لایه = معمولا هر چه بیشتر بهتر (افزایش تعداد گره های پنهان باید با هزینه محاسبه آن ها تعادل داشته باشد) پیش فرض ها: ۱ لایه پنهان، اگر بیش از ۱ لایه پنهان دارید پیشنهاد می‌شود که در هر لایه پنهان تعداد گره یکسانی داشته باشید.  آموزش یک شبکه عصبی  مقدار دهی اولیه تصادفی وزن ها برای پیاده سازی انتشار به جلو، محاسبه $h_\\Theta(x ^{(i)})$ برای هر $x ^{(i)}$ پیاده سازی تابع هزینه پیاده سازی پس انتشار برای محاسبه مشتقات جزئی استفاده از بررسی گرادیان برای اینکه مطمئن شویم پس انتشار کار می‌کند، و بعد از آن توقف بررسی گرادیان. استفاده از گرادیان کاهشی یا یک تابع توکار بهینه سازی برای به حداقل برساندن تابع هزینه با استفاده از وزن های داخل تتا  هنگام استفاده از انتشار به جلو و پس انتشار در هر نمونه آموزشی حلقه می‌زنیم:\n,for i = 1:m Perform forward propagation and backpropagation using example (x(i),y(i)) Get activations a(l) and delta terms d(l) for l = 2,...,L  تصویر زیر به ما شهودی از آنچه که در حین پیاده سازی شبکه عصبی اتفاق می‌افتد می‌دهد: در حالت ایده آل، می‌خواهیم: $$ h_\\Theta (x^{(i)}) \\approx y^{(i)} $$\nکه این یعنی تابع هزینه ما به حداقل می‌رسد، اما به خاطر داشته باشید که $J(\\Theta)$ محدب نیست، که بنابراین می‌توانیم به جای آن در مینیمم محلی قرار بگیریم.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/questions/",
	"title": "سوالات متداول افراد ",
	"tags": [],
	"description": "",
	"content": "لیستی از سوالات پرتکرار موجود که افراد مختلف می‌پرسند:\n Data Science:  مسیر پیشنهادی برای دیتاساینتیست شدن از صفر! آیا دیتاساینس شغل مناسبی برای من هست؟   Machine Learning:  منابع و ابزار یادگیری ماشین لرنینگ چیست؟    Data Science مسیر پیشنهادی برای دیتاساینتیست شدن از صفر!    View this post on Instagram         A post shared by Data science with sarvi! (@datascience_with_sarvi) on Jun 17, 2020 at 7:20am PDT\n  آیا دیتاساینس شغل مناسبی برای من هست؟    View this post on Instagram         A post shared by Data science with sarvi! (@datascience_with_sarvi) on Aug 1, 2020 at 10:56am PDT\n  Machine Learning منابع و ابزار یادگیری ماشین لرنینگ چیست؟    View this post on Instagram         A post shared by Kooshiar Azimian (@kooshiar) on Jun 21, 2020 at 11:42pm PDT\n  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/multiclass-classification/",
	"title": "طبقه بندی چند کلاسه",
	"tags": [],
	"description": "",
	"content": "برای طبقه بندی داده ها در چندین کلاس، نیاز داریم که تابع فرضیه ما برداری از مقادیر را برگرداند. مثلا اگر بخواهیم داده هایمان را در یکی از ۴ دسته طبقه بندی کنیم می‌توانیم برای دیدن نحوه انجام این طبقه بندی از مثال زیر استفاده می‌کنیم، این الگوریتم یک تصویر را به عنوان ورودی گرفته و بر اساس آن طبقه بندی را انجام می‌دهد، ۴ دسته ما عبارت اند از:\n pedestrian car motorcycle truck  می‌توانیم مجموعه کلاس های خود را به عنوان $y$ به صورت زیر تعریف کنیم:\n$$ y^{(i)} = \\begin{bmatrix}1 \\newline 0 \\newline 0 \\newline 0 \\end{bmatrix} , \\begin{bmatrix}0 \\newline 1 \\newline 0 \\newline 0 \\end{bmatrix} , \\begin{bmatrix}0 \\newline 0 \\newline 1 \\newline 0 \\end{bmatrix} , \\begin{bmatrix}0 \\newline 0 \\newline 0 \\newline 1 \\end{bmatrix} $$\nهر کدام از $y^{(i)}$ ها دسته متفاوتی را نشان می‌دهند، که مربوط به اتوموبیل، عابر پیاده، کامیون یا موتور سیکلت است. و لایه های میانی هر کدام اطلاعات جدیدی در اختیار ما قرار می‌دهند، که منجر به تابع فرضیه نهایی ما می‌شود.\n$$ \\begin{bmatrix}x_0 \\newline x_1 \\newline x_2 \\newline \u0026hellip;\\newline x_n \\end{bmatrix} \\rightarrow \\begin{bmatrix}a_0 ^ {(2)} \\newline a_1 ^ {(2)} \\newline a_2 ^ {(2)} \\newline \u0026hellip; \\end{bmatrix} \\rightarrow \\begin{bmatrix}a_0 ^ {(3)} \\newline a_1 ^ {(3)} \\newline a_2 ^ {(3)} \\newline \u0026hellip; \\end{bmatrix} \\rightarrow \u0026hellip; \\rightarrow \\begin{bmatrix}h_\\Theta (x)_1 \\newline h_\\Theta (x)_2 \\newline h_\\Theta (x)_3 \\newline h_\\Theta (x)_4 \\end{bmatrix} $$\nتابع فرضیه حاصل ما برای یک مجموعه ورودی ممکن است به این صورت شود: $$ h_\\Theta (x) = \\begin{bmatrix}0 \\newline 0 \\newline 1 \\newline 0 \\end{bmatrix} $$\nکه این نشان دهنده سومین کلاس ما یعنی موتور سیکلت است، یعنی همان $h_\\Theta (x)_3$.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/files/",
	"title": "فایل های هفته دوم",
	"tags": [],
	"description": "",
	"content": "اسلاید ها  Linear regression with multiple variables - pdf Octave tutorial - pdf  غلط نامه  Errata - pdf  تمرین برنامه نویسی  Programming Exercise 1: Linear Regression - pdf | problem  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/overfitting/",
	"title": "مشکل Overfitting",
	"tags": [],
	"description": "",
	"content": "تصور کنید مسئله پیش بینی $y$ را، به صورتی که $x \\in R$ است را داریم.\nسمت چپ ترین شکل زیر نتیجه fitting، $y = \\theta_0 + \\theta_1x$ را بر روی مجموعه داده نشان می‌دهد. می بینیم که داده ها واقعاً روی خط مستقیم قرار ندارند، بنابراین اصطلاحا خوب fit نشده است (تناسب خوبی با داده ها ندارد).\nدر عوض اگر ویژگی $x^2$ را اضافه کنیم، و $y = \\theta_0 + \\theta_1x+ \\theta_2 x^2$ را fit کنیم، سپس کمی بهتر با داده ها مطابقت پیدا می‌کنیم که در شکل وسطی می‌بینیم. به طور ساده لوحانه ممکن است به نظر برسد که هرچه تعداد ویژگی بیشتری اضافه کنیم بهتر است!\nبا این حال اضافه کردن ویژگی های بیش از حد نیز خطراتی دارد!\nسمت راست ترین شکل نتیجه چند جمله ای مرتبه ۵ $y = \\sum_{j = 0}^5 \\theta _j x^j$ است.\nما می‌بینیم که منحنی اعمال شده به خوبی از داده ها عبور می‌کند، اما انتظار نداریم که این پیش بینی کننده خوبی برای پیش بینی قیمت مسکن (y) در مناطق مختلف قابل سکونت (x) باشد.\nبدون اینکه به طور رسمی معنی این اصطلاحات را مشخص کنیم، می‌گوییم که:\nشکل سمت چپ نمونه ای از underfitting است. و شکل سمت راست نیز نمونه ای overfitting است.\nUnderfitting Underfitting بایاس زیاد زمانی رخ می‌دهد که شکل حاصل از تابع فرضیه ما (h) به طور ضعیفی با روند داده های ما در مجموعه داده (dataset) تطابق داشته باشد.\nاین وضعیت معمولا به دلیل بسیار ساده بودن تابع یا استفاده از ویژگی های کم رخ می‌دهد.\nOverfitting در طرف دیگر overfitting واریانس زیاد وضعیتی است که توسط یک تابع فرضیه ایجاد می‌شود که تناسب خوبی با داده های ما دارد، اما پیش بینی داده های جدید که تا کنون ندیده است را به خوبی انجام نمی‌دهد، اصطلاحا تعمیم داده شده یا عمومی نیست.\nاین وضعیت معمولا به دلیل پیچیده بودن تابع فرضیه ایجاد می‌شود که انحنا ها و زوایای غیر ضروری زیادی را ایجاد می‌کند که با داده های ما ارتباطی ندارند.\nدو گزینه برای حل مشکل overfitting وجود دارد:\n تعداد ویژگی ها را کاهش دهید   به طور دستی ویژگی هایی را برای نگهداری انتخاب کنید از یک الگوریتم انتخاب مدل استفاده کنید  منظم سازی    همه ویژگی ها را نگه دارید، اما اندازه پارامتر های $\\theta_j$ را کاهش دهید منظم سازی زمانی خوب عمل می‌کند که ویژگی های مفیدی داشته باشیم  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost3/",
	"title": "تابع هزینه قسمت سوم",
	"tags": [],
	"description": "",
	"content": "قسمت قبل دیدیم که با داشتن فقط یک پارامتر برای تابع فرضیه نمودار تابع هزینه یا همان $J$ به صورت سهمی بود. اگر دو پارامتر داشته باشیم باز هم به صورت سهمی است، اما سه بعدی و بسته به داده ما ممکن است به شکل زیر باشد:\nاما ما برای نمایش این تابع از شکل سه بعدی استفاده نمی‌کنیم‌، بلکه از نمودار های کانتور استفاده می‌کنیم!\nدر این نمودار ها هر یک از بیضی ها نشان دهنده مجموعه ای از نقاط است که مقادیر یکسانی در $J$ بر حسب $\\theta_0$ و $\\theta_1$ های مختلف دارند.\nمثالی از یک نمودار کانتور:\nمثلا نقطه قرمز روی نمودار کانتور سمت راست برابر است با: $ \\theta_1 = -0.15, \\theta_0 = 800 $\nاما همینطور که می‌بینیم خط حاصل از تابع فرضیه تناسب خوبی با داده های ما ندارد! به این خاطر که نقطه ما از مینیمم که کوچکترین بیضی است خیلی دور است!\nدر این نقطه جدید هم کاملا مینیمم نیست اما خیلی بهتر از قبلی است. باز هم خط حاصل از تابع فرضیه بر حسب مقادیر انتخابی برای دو پارامتر مسئله با داده های ما متناسب نیست \u0026hellip;\nدر واقع ما به الگوریتمی نیاز داریم که برای ما مقادیر $\\theta_0$ و $\\theta_1$ را در حالتی که تابع $J$ مینیمم است بیابد.\nکه پاسخ ما گرادیان کاهشی است !\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/useful-articles/",
	"title": "منابع مفید ",
	"tags": [],
	"description": "",
	"content": "این صفحه در حال ویرایش و کامل شدن است \u0026hellip;\nلیست منابع موجود:\n افراد تاثیر گذار کانال ها و صفحات اجتماعی:  تلگرام یوتیوب توییتر اینستاگرام   وب سایت ها و وبلاگ ها دیتاست کنفرانس دوره های مفید دیگر:  Deep Learning Data Science    افراد تاثیر گذار لیستی از صفحات اجتماعی افراد تاثیر گذار فارسی زبان در حوزه هوش مصنوعی و دیتاساینس به ترتیب الفبا:\n پوریا حداد سروناز چوبدار سعید چوپانی سید ناصر رضوی کوشیار عظیمیان شیدا وانوئی علیرضا اخوان پور علی صادقی عقیلی مریم رهبر عالم مهدی حبیب زاده  افراد تاثیر گذار انگلیسی زبان:\n Andrew Ng Yann LeCun Alfredo Canziani Ian Goodfellow  تلگرام  اطلاع رسانی از رویداد های حوزه هوش مصنوعی هوش مصنوعی و برنامه نویسی پایتون Recommender Systems آموزش هوش مصنوعی دستاوردهای یادگیری عمیق(InTec) Tensorflow(@CVision) School of AI NLP stuff Pythonic AI کتابخانه هوش مصنوعی arXiv  یوتیوب  Artificial Intelligence - All in One Machine Learning University Seyed Naser Razavi Alexander Amini TensorFlow  توییتر اینستاگرام وب سایت ها و وبلاگ ها  KDnuggets  دیتاست  Dataset Search Google Machine learning datasets UC Irvine Machine Learning Repository Academic Torrents Kaggle Dataset  کنفرانس  ACM Conference on Recommender Systems Signal Processing and Intelligent Systems AAAI Conference ICML Conference KDD Conference NIPS Conference SIGMOD Conference WSDM Conference CVPR Conference ICDE Conference  Deep Learning  دوره یادگیری عمیق با پایتورچ دانشگاه نیویورک توسط Yann LeCun و Alfredo Canziani (در حال ترجمه به فارسی)  Data Science "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week8/pca-algorithm/",
	"title": "تحلیل اجزای اصلی الگوریتم",
	"tags": [],
	"description": "",
	"content": "قبل از استفاده از PCA ، یک مرحله پیش پردازش داده وجود دارد که باید انجام دهیم:\nپیش پردازش داده   گرفتن مجموعه آموزشی: $x^{(1)}, x^{(2)}, \u0026hellip; , x^{(m)}$\n  پیش پردازش (feature scaling/mean normalization): $\\mu _j = \\frac{1}{m} \\sum _ {i=1} ^ m x ^ {(i)} _j $\n  جایگزین کردن هر $x ^ {(i)} _j $ با $x ^ {(i)} _j - \\mu _j$\n  اگر ویژگی های مختلف در مقیاس های متفاوت باشند (مثلا $= x_1$ اندازه خانه، $ = x_2$ تعداد اتاق خواب ها)، ویژگی ها را برای داشتن دامنه ای قابل مقایسه از مقادیر تغییر مقیاس دهید.\n  در بالا ، ابتدا میانگین هر ویژگی را از ویژگی اصلی کم می‌کنیم. سپس تمام ویژگی ها را مقیاس بندی می کنیم: $$ x ^ {(i)} _j = \\frac{x ^ {(i)} _j - \\mu _j}{s_j} $$\nمی‌توان به طور خاص کاهش از ۲ بعدی به ۱ بعدی داده را به این صورت تعریف کرد:\n$$ \\sum = \\frac{1}{m} \\sum _ {i=1} ^ m (x ^ {(i)}) (x ^ {(i)}) ^ T $$\nمقادیر z، همه اعداد حقیقی هستند و پیش بینی ویژگی های ما بر روی $u ^{(1)}$ هستند.\nبنابراین PCA دو وظیفه دارد: کشف کردن $u^{(1)}, u^{(2)}, \u0026hellip;, u^{(k)}$ ها، و پیدا کردن $z_1, z_2, \u0026hellip; , z_m$\nاثبات ریاضی برای روش زیر پیچیده و فراتر از محدوده این دوره است.\n1. محاسبه ماتریس کو واریانس $$ \\sum = \\frac{1}{m} \\sum _ {i=1} ^ m (x ^ {(i)}) (x ^ {(i)}) ^ T $$\nاین را می‌توان در اوکتاو به صورت زیر برداری کرد:\nSigma = (1/m) * X' * X  ما ماتریس کو واریانس را با یک سیگما بزرگ نشان می دهیم.\nتوجه داشته باشید که $x ^ {(i)}$ یک بردار $n \\times 1$ است، $(x ^ {(i)})^T$ یک بردار $1 \\times n$ است و X یک ماتریس $m \\times n$ است که نتیجه ضرب آن ها ماتریسی $n \\times n$ است، که ابعاد $\\sum$ است.\n2. محاسبه بردار های ویژه ماتریس کو واریانس $\\sum$\n[U,S,V] = svd(Sigma)  svd مخفف کلمه singular value decomposition است که یک تابع توکار در اوکتاو است.\nدر واقع آن چیزی که به عنوان خروجی از svd می‌خواهیم، $U$ یا ماتریس کو واریانس سیگما است:\n$$ U \\in \\mathbb{R} ^{n \\times n} $$\n$$ U = u ^ {(1)}, \u0026hellip;, u ^ {(n)} $$\n3. k ستون اول ماتریس U را گرفته و z را محاسبه کنید\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/error-analysis/",
	"title": "تحلیل خطا",
	"tags": [],
	"description": "",
	"content": "رویکرد پیشنهادی برای حل کردن یک مسئله یادگیری ماشین به شرح زیر است:\n  با یک الگوریتم ساده شروع کنید، سریعا آن را پیاده کرده و تست کنید.\n  منحنی یادگیری را رسم کنید تا متوجه شوید که آیا داده بیشتر، ویژگی‌های بیشتر و \u0026hellip; مفید خواهند بود یا خیر.\n  تحلیل خطا: به صورت دستی خطای موجود در نمونه‌های مجموعه cross validation را بررسی کرده و سعی کنید روند الگوریتم را تشخیص دهید.\n  این نکته حائز اهمیت است که نتیجه خطا را به صورت مقدار واحد و عددی بدست آورید. در غیر این صورت ارزیابی کارایی الگوریتم دشوار خواهد بود.\nممکن است قبل ازاینکه ورودی‌های شما قابل استفاده باشند، نیاز به پردازش داشته باشند. برای مثال، اگر ورودی شما مجموعه‌ای از کلمات باشد، ممکن است بخواهید با حالت‌های مختلف همان کلمه (fail, failing, failed) مانند یک کلمه رفتار کنید. پس برای تشخیص آن‌ها به عنوان یک کلمه واحد باید از نرم‌افزار ریشه‌یاب استفاده کنید.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week5/autonomous-driving/",
	"title": "نمونه ای از رانندگی خودکار",
	"tags": [],
	"description": "",
	"content": "پروژه ALVINN ماشین خودران در سال ۱۹۸۹ ALVINN: Autonomous Land Vehicle In a Neural Network\nبرای مشاهده ویدئو این پروژه در YouTube بر روی تصویر زیر کلیک کنید:\n\nتوییت ای جالب در توییتر در این مورد (نیاز به vpn):\nGPU? Gez, ALVINN ran on 100 MFLOP CPU, ~10x slower than iWatch; Refrigerator-size \u0026amp; needed 5000 watt generator. @olivercameron pic.twitter.com/QdGpZUzGCs\n\u0026mdash; Dean Pomerleau (@deanpomerleau) November 24, 2016  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week4/files/",
	"title": "فایل های هفته چهارم",
	"tags": [],
	"description": "",
	"content": "اسلاید ها  Neural Networks: Representation - pdf  غلط نامه  Errata - pdf  تمرین برنامه نویسی  Programming Exercise 3: Multi-class Classification and Neural Networks - pdf | problem  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/cost-function-overfitting/",
	"title": " تابع هزینه در Overfitting",
	"tags": [],
	"description": "",
	"content": "اگر تابع فرضیه ما مشکل overfitting دارد، ما می‌توانیم وزن بعضی از بخش های تابع فرضیه را با افزایش هزینه آن ها کاهش دهیم:\nتصور کنید که تابع زیر را درجه دو تر کنیم: $$ \\theta_0 + \\theta_1x + \\theta_2 x^2 + \\theta_3 x^3 +\\theta_4 x^4 $$\nما می‌خواهیم تاثیر $\\theta_3 x^3$ و $\\theta_4 x^4$ را از بین ببریم ، بدون اینکه از شر این ویژگی ها خلاص شویم یا فرم تابع فرضیه خود را تغییر دهیم، ما می‌توانیم تابع هزینه خود را اصلاح کنیم:\n$$ min_\\theta \\frac{1}{2m} \\sum_{i = 1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 + 1000 \\cdot \\theta_3 ^2 + 1000 \\cdot \\theta_4 ^ 2 $$\nما اینجا در انتها دو بخش اضافه کرده ایم تا هزینه $\\theta_3$ و $\\theta_4$ را افزایش دهیم. حالا برای اینکه تابع هزینه به صفر نزدیک شود، ما باید مقادیر $\\theta_3$ و $\\theta_4$ را به صفر نزدیک کنیم.\nاین کار به خوبی مقادیر $\\theta_3 x^3$ و $\\theta_4 x^4$ را در تابع هزینه ما کاهش می‌هد.\nدر نتیجه می‌بینیم که فرضیه جدید (که توسط منحنی صورتی نشان داده شده است) مانند یک تابع درجه دوم به نظر می‌رسد، و به خاطر اصلاحات در $\\theta_3 x^3$ و $\\theta_4 x^4$ با داده ها تناسب بهتری دارد.\nو برای جمع بندی می‌توانیم بنویسیم: $$ min_\\theta \\frac{1}{2m} \\sum_{i = 1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j = 1}^n \\theta_j ^ 2 $$\nلامبدا ($\\lambda$) پارامتر منظم سازی (regularization parameter) است، تعیین می‌کند که هزینه پارامتر های تتا ما چه قدر باید زیاد شود.\nبا استفاده از تابع هزینه بالا ما می‌توانیم خروجی تابع فرضیه خود را صافکاری کنیم تا وضعیت overfitting را کاهش دهیم.\nاگر پارامتر لامبدا بسیار بزرگ انتخاب شود، ممکن است تابع ما را بیش از حد صافکاری کند و باعث underfitting شود!\n  برای پاسخ کلیک کن   باید پر بشه\n  -- "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/sponsorship/",
	"title": "حمایت",
	"tags": [],
	"description": "",
	"content": "بهترین حمایت ممکن معرفی وب سایت به دوستان علاقه‌مند‌تان است!\nپس بهتره پیشاپیش از حمایتتون تشکر کنیم 🥰✨\nو اما \u0026hellip; اگر مایل هستید که کمک بیشتری کنید، از دکمه زیر می‌تونید به مقدار دلخواه کمک مالی کنید 🙂💸\nحمایت ❤️  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient1/",
	"title": "گرادیان کاهشی قسمت اول",
	"tags": [],
	"description": "",
	"content": "گرادیان کاهشی گرادیان کاهشی را برای مینیمم کردن تابع هزینه $J$ استفاده می‌کنیم. اما این الگوریتم تنها فقط در رگرسیون خطی کاربرد ندارد، بلکه در سایر قسمت های حوزه یادگیری ماشین نیز استفاده می‌شود.\nمراحل کار به این شکل است:\nبا حدس های اولیه برای دو پارامتر $\\theta_0$ و $\\theta_1$ شروع می‌کنیم، مثلا مقدار هر دو را در ابتدا $0$ تعیین می‌کنیم.\nو سپس مقادیر $\\theta_0$ و $\\theta_1$ را به صورت جزئی تغییر می‌دهیم تا تابع $J$ کاهش یابد، تا زمانی که به مینیمم کلی یا محلی برسیم.\nبرای درک بهتر فرض کنید موتور سواری هستید بر روی سطح شکل زیر و می‌خواهید به پایین ترین نقطه این سطح برسید!\nکه بسته به مقادیر پارامتر ها سفر خود را از یک نقطه بر روی این سطح شروع می‌کنید.\nشما در همه جهات می‌چرخید و اطرافتان را نگاه می‌کنید و سپس سعی می‌کنید مقدار کمی به پایین در یک جهت بروید و در سریع ترین زمان به پایین برسید. بنابراین به کدام جهت باید بروید ؟!\nاگر از بالاترین نقطه شکل زیر حرکت کنید به این نقطه نهایی در کف سطح می‌رسید.\nاما اگر نقطه شروع را کمی از سمت راست شروع کرده بودید مسیرتان به این شکل می‌شد.\nکه این ویژگی گرادیان کاهشی است!\nو اما این تعریف ریاضی الگوریتم گرادیان کاهشی است:\nقرار است به صورت مکرر این کار را ادامه بدهیم تا به نقطه مینیمم برسیم!، اما اجازه دهید با مثال موتور قضیه را باز کنیم!\nاینجا $\\alpha$ / آلفا یا همان نرخ یادگیری شبیه به گاز موتور ما است که تعیین می‌کند میزان بزرگی حرکت ما به پایین چه قدر باشد.\nعبارت مشتق $\\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) $ نیز برای ما شبیه به فرمان موتور است که تعیین کننده جهت حرکت خواهد بود.\nاما نکته ی دیگری نیز در گرادیان کاهشی وجود دارد تغییر مقدار $\\theta_0$ و $\\theta_1$ در هر بار در فرمول باید به صورت پیوسته انجام بشود!، یعنی ابتدا مقادیر حساب شود و سپس به مقادیر بعد از انجام محاسبه تغییر کند:\nاما به نظر شما کدام درست است ؟!\n  برای پاسخ کلیک کن   جواب درست شکل سمت چپ است، زیرا دو پارامتر هم زمان و پشت سر هم مقادیرشان تغییر می‌کند، درحالی که در شکل سمت راست ابتدا $\\theta_0$ تغییر می‌کند و بعد از آن در مرحله بعد برای محاسبه $\\theta_1$ از مقدار جدید و تغییر داده شده $\\theta_0$ استفاده می‌شود.\n  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/about/",
	"title": "درباره ",
	"tags": [],
	"description": "",
	"content": "مشارکت کنندگان  /* mobile */ @media (max-width: 767px) { .avatarcont { border-radius: 50%; box-shadow: 0px 5px 10px 0px rgba(30, 30, 30, 0.3); margin-top: -20px; display: block; margin: 0 auto; max-width: 100px; } .pcont { margin-top: -30px; text-align: center; font-size:13px; font-weight:bold; } } /* desktop */ @media only screen and (min-width: 992px) { .avatarcont { border-radius: 50%; box-shadow: 0px 5px 10px 0px rgba(30, 30, 30, 0.3); margin-top: -20px; display: block; margin: 0 auto; max-width: 120px; } .pcont { margin-top: -30px; text-align: center; font-size:15px; font-weight:bold; } }  --  mehrdad mohammadian\n  nargesrzn  fariba javadpour\n  -- منابع استفاده شده "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/error-metrics-for-skewed-classes/",
	"title": "معیار‌های خطا برای کلاس‌های نامتوازن",
	"tags": [],
	"description": "",
	"content": "گاهی اوقات دشوار است که بگوییم کاهش خطاها باعث بهبود الگوریتم می‌شوند.\n برای مثال: در پیش‌ بینی تشخیص سرطان که 0.5% از نمونه‌ها سرطان دارند، متوجه می‌شویم که الگوریتم یادگیری 1% خطا دارد.  هرچند اگر به سادگی هریک از نمونه‌ها را با عنوان 0 طبقه‌بندی می‌کردیم، خطا به 0.5% کاهش پیدا میکرد، با این وجود که ما الگوریتم را بهبود نداده بودیم.\nاین مسئله در کلاس‌های نامتوازن رخ می‌دهد، هنگامی که کلاس در کل مجموعه داده بسیار نادر است.\nبه بیان دیگر، هنگامی که نمونه‌های یک کلاس تعداد خیلی بیشتری از یک کلاس دیگر داشته باشد.\nمی‌توان از Precision/Recall استفاده کرد.\n پیش ‌بینی شده: 1، حقیقی: 1 $\\Leftarrow$ True positive پیش ‌بینی شده: 0، حقیقی: 0 $\\Leftarrow$ True negative پیش ‌بینی شده: 0، حقیقی: 1 $\\Leftarrow$ False negative پیش ‌بینی شده: 1، حقیقی: 0 $\\Leftarrow$ False positive  Precision: از تمام بیمارانی که پیش بینی برای آنها y=1 بوده است، چه بخشی از آن‌ها واقعا مبتلا به سرطان هستند؟\n$$\\frac{\\text{True Positives}}{\\text{Total number of predicted positives}} = \\frac{\\text{True Positives}}{\\text{True Positives + False positives}}$$\nRecall: از تمام بیمارانی که واقعا به سرطان مبتلا هستند، سرطان چه بخشی از آن‌ها توسط ما به درستی تشخیص داده شده است؟\n$$\\frac{\\text{True Positives}}{\\text{Total number of actual positives}} = \\frac{\\text{True Positives}}{\\text{True Positives + False negatives}}$$\nاین دو معیار دید بهتری نسبت به این که عملکرد طبقه‌بندی ما چگونه است می‌دهند. ما می‌خواهیم هر دو مقدار Precision و Recall زیاد باشند.\nدر مثال ابتدای بخش، اگر تمام بیماران را به عنوان 0 طبقه‌بندی کنیم، مقدار recall با $\\frac{0}{0 + f}$ برابر خواهد بود، پس با وجود داشتن درصد خطای پایین‌تر recall بدتری خواهد بود.\n$$Accuracy = \\frac{\\text{true positive + true negative}}{\\text{total population}}$$\nاگر یک الگوریتم مانند یکی از مثال‌ها فقط موارد منفی را پیش‌ بینی کند، مقدار precision تعریف نشده و تقسیم بر صفر غیر ممکن است. F1 نیز تعریف نشده خواهد بود.\n "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week5/files/",
	"title": "فایل های هفته پنجم",
	"tags": [],
	"description": "",
	"content": "اسلاید ها  Neural Networks: Learning - pdf  غلط نامه  Errata - pdf  تمرین برنامه نویسی  Programming Exercise 4: Neural Networks Learning - pdf | problem  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/regularized-linear-regression/",
	"title": "رگرسیون خطی منظم",
	"tags": [],
	"description": "",
	"content": "ما می‌توانیم منظم سازی را هم برای رگرسیون خطی و هم برای رگرسیون لجستیک استفاده کنیم. که اینجا ابتدا رگرسیون خطی را بررسی می‌کنیم.\nگرادیان کاهشی گرادیان کاهشی را اصلاح می‌کنیم تا $\\theta_0$ را از بقیه پارامتر ها جدا کنیم، زیرا نمی‌خواهیم تاثیر $\\theta_0$ را کاهش دهیم و از بین ببریم:\n$$ \\begin{align*} \u0026amp; \\text{Repeat}\\ \\lbrace \\newline \u0026amp; \\ \\ \\ \\ \\theta_0 := \\theta_0 - \\alpha\\ \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \\newline \u0026amp; \\ \\ \\ \\ \\theta_j := \\theta_j - \\alpha\\ \\left[ \\left( \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\right) + \\frac{\\lambda}{m}\\theta_j \\right] \u0026amp;\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ j \\in \\lbrace 1,2\u0026hellip;n\\rbrace\\newline \u0026amp; \\rbrace \\end{align*} $$\nقسمت $\\frac{\\lambda}{m}\\theta_j$ منظم سازی ما را انجام می‌دهد. و با یک مقدار دستکاری می‌توانیم $\\theta_j$ را به این صورت نشان دهیم:\n$$ \\theta_j := \\theta_j(1 - \\alpha \\frac{\\lambda}{m} ) - \\alpha \\frac{1}{m} \\sum_{i = 1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j ^ {(i)} $$\nقسمت اول معدله یعنی $1 - \\alpha \\frac{\\lambda}{m}$ همیشه کم از $1$ خواهد بود، و به طور چشمی می‌بینیم که مقدار $\\theta_j$ را در هر بروزرسانی کمتر می‌کند.\nتوجه داشته باشید که قسمت دوم دقیقا مثل قبل است.\nمعادله نرمال حالا منظم سازی را با یک روش جایگزین و بدون نیاز به تکرار (non-iterative) یعنی معادله نرمال بررسی می‌کنیم.\nبرای این کار معادله ما شبیه به معادله اصلی است، با این تفاوت که یک بخش جدید در داخل پرانتز اضافه می‌کنیم:\n$$ \\begin{align*}\u0026amp; \\theta = \\left( X^TX + \\lambda \\cdot L \\right)^{-1} X^Ty \\newline\u0026amp; \\text{where}\\ \\ L = \\begin{bmatrix} 0 \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\newline \u0026amp; 1 \u0026amp; \u0026amp; \u0026amp; \\newline \u0026amp; \u0026amp; 1 \u0026amp; \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \\ddots \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; 1 \\newline\\end{bmatrix}\\end{align*} $$\nL یک ماتریس است که به صورت مورب از قسمت بالا سمت چپ با $0$ شروع شده و تا انتهای بخش مورب $1$ است. و سایر خانه های ماتریس نیز مقدار $0$ دارند، که ابعاد آن $(n+1) \\times (n+1)$ است.\nدر واقع یک ماتریس همانی است، (اگر چه که شامل $x_0$ نمی‌شود) که در عدد حقیقی لامبدا ضرب شده است.\nبه خاطر بیاورید که:\n$$ \\text{if } m \u0026lt; n \\text{ then } X^TX $$ وارون ناپذیر بود. اگر چه وقتی ما قسمت $\\lambda . L $ را اضافه می‌کنیم، سپس $ X^TX + \\lambda . L$ وارون پذیر می‌شود.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient2/",
	"title": "گرادیان کاهشی قسمت دوم",
	"tags": [],
	"description": "",
	"content": "در قسمت قبل گرادیان کاهشی را به این صورت معرفی کردیم، در این قسمت می‌خواهیم به توضیح آلفا و عبارت مشتق بپردازیم. اما برای برای درک بهتر می‌خواهیم با یک مثال ساده تر تابعی با یک پارامتر را مینیمم کنیم، یعنی فرض می‌کنیم تابع هزینه $J$ فقط یک پارامتر دارد.\nتصور کنید تابع $J$ زیر را با پارامتر $\\theta_1$ در این نقطه داریم، و از این نقطه کارمان را شروع می‌کنیم.\nکاری که عبارت مشتق می‌کند این است که تانژانت این نقطه را می‌گیرد، مثل این خط قرمز که با تابع مماس است. پس از این عبارت شیب خط را به دست می‌آوریم و می‌بینیم که در اینجا شیب خط قرمز ما مثبت است، پس متوجه شدیم که در این شکل حاصل مشتق مثبت است، همچنین نرخ یادگیری نیز همیشه عددی مثبت است.\nبنابراین تغییر $\\theta$ طبق فرمول به این صورت است: $$ \\theta_1 := \\theta_1 - \\alpha \\text{ } \\cdot \\text{ (positive number)} $$\nبنابراین داریم $\\theta$ منهای مقداری مثبت که این باعث می‌شود $\\theta$ ما کاهش یابد و به سمت چپ برود!\nهمان چیزی که می‌خواهیم، نزدیک شدن به مینیمم!\nو اگر طبق مثال قبل از این نقطه جدید شروع کنیم شیب خط ما منفی خواهد شد، یعنی مشتق منفی!\nبنابراین تغییر تتا طبق فرمول به این صورت است: $$ \\theta_1 := \\theta_1 - \\alpha \\text{ } \\cdot \\text{ (negative number)} $$\nمی‌بینیم که داریم $\\theta_1$ منهای مقداری منفی که این باعث می‌شود تتا ما افزایش یابد و به سمت راست برود!\nدر شکل سمت چپ مقدار آلفا بسیار کوچک است که باعث می‌شود گرادیان کاهشی خیلی کند تر به مینیمم برسد یعنی نیاز داریم قدم های بیشتری به پایین برداریم.\nاما در شکل راست آلفا بسیار بزرگ تر است که باعث شده گرادیان کاهشی هیچ وقت به مینیمم نرسد. یعنی گرادیان کاهشی ما همگرا نیست بلکه واگرا است!\nحالا شما جواب بدید!\nچه اتفاقی می‌افتد اگر در شکل زیر پارامتر $\\theta_1$ در نقطه مینیمم باشد؟!\n  برای دیدن پاسخ کلیک کن   اگر تصور کنیم که تتا در این مینیمم محلی است، و ما می‌دانیم که عبارت مشتق ما در این حالت 0 است، و در واقع داریم:\n$$ \\theta_1 := \\theta_1 - \\alpha \\text{ } \\cdot 0$$\nو این به این معنی است که اگر در مینیمم محلی باشیم، مقدار $\\theta_1$ بدون تغییر باقی می‌ماند!\n  گرادیان نزولی به مینیمم محلی ختم می‌شود حتی زمانی که نرخ یادگیری یا همان آلفا ثابت باشد!\nزیرا در هر بار انجام الگوریتم شیب خط حاصل از عبارت مشتق ملایم تر از حالت دفعه قبلش است و همینطور که به مینیمم نزدیک تر می‌شویم، مشتق نیز به صفر میل می‌کند. بنابراین هر بار مشتق کوچک تر می‌شود و این باعث می‌شود قدم ها هر بار کوچک تر و کوچک تر شوند. به این خاطر نیازی نیست در طول زمان مقدار آلفا را کاهش دهیم!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/trading-off-precision-and-recall/",
	"title": "متوازن کردن Precision  و Recall",
	"tags": [],
	"description": "",
	"content": "ممکن است ما نیاز به یک پیش بینی مطمئن از دو کلاس به وسیله رگرسیون لجستیک داشته باشیم. یک راه این است که آستانه را افزایش دهیم:\n پیش بینی 1 اگر: $h_{\\theta }\\left ( x \\right ) \\geq 0.7$ پیش بینی 0 اگر: $h_{\\theta }\\left ( x \\right ) \u0026lt; 0.7$  بدین ترتیب تنها درصورتی که بیمار 70% شانس بیماری داشته باشد، سرطان را پیش بینی می‌کنیم.\nاکنون ما precision زیادتر و recall کمتر خواهیم داشت(با توجه به تعاریف در بخش قبل).\nدر یک مثال متفاوت، میتوان آستانه را کمتر کرد:\n پیش بینی 1 اگر: $h_{\\theta }\\left ( x \\right ) \\geq 0.3$ پیش بینی 0 اگر: $h_{\\theta }\\left ( x \\right ) \u0026lt; 0.3$  که با این روش، پیش بینی مطمئن‌تری خواهیم داشت. که منجر به recall زیادتر و precision کمتر خواهد شد.\nهرچه آستانه زیادتر باشد، precision زیادتر و recall کمتر خواهد بود.\nهرچه آستانه کمتر باشد، recall زیادتر و precision کمتر خواهد بود.\nبرای تبدیل این دو استاندارد به یک عدد واحد می‌توانیم از مقدار F استفاده کنیم.\nیک راه استفاده از میانگین است: $\\frac{P + R }{2}$\nاما این راه حل مناسبی نیست. اگر تمامی مقادیر y را با 0 پیش بینی کنیم(y = 0) با وجود recall = 0، میانگین بالا خواهد رفت.\nاگر تمامی نمونه‌ها را با y=1 پیش بینی کنیم، recall بسیار بالا با وجود precision = 0، میانگین را بالا خواهد برد.\nراه حل بهتر محاسبه F Score خواهد بود(یا F1 Score):\n$$ F Score = 2\\frac{PR}{P + R} $$\nبرای زیاد بودن مقدار F، هردو مقدار precision و recall باید زیاد باشند.\nما می‌خواهیم Precision و Recall را روی مجموعه Cross validaion آموزش دهیم تا مجموعه آزمون دچار بایاس نشود.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/regularized-logistic-regression/",
	"title": "رگرسیون لجستیک منظم",
	"tags": [],
	"description": "",
	"content": "می‌توانیم رگرسیون لجستیک را به روشی مشابه رگرسیون خطی منظم سازی کنیم، که در نتیجه می‌توانیم از overfitting پرهیز کنیم.\nتابع هزینه به یاد بیاورید که تابع هزینه ما برای رگرسیون لجستیک به این شکل بود:\n$$ J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^m [y^{(i)} log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\\theta(x^{(i)}) )]\n$$\nما می‌توانیم این معادله را با اضافه کردن یک قسمت به انتهای آن منظم کنیم:\n$$ J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^m [y^{(i)} log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\\theta(x^{(i)}) )] + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\theta_j ^ 2 $$\nسیگما دوم یعنی $\\sum_{j=1}^n \\theta_j ^ 2 $ به معنای حذف بایاس پارامتر $\\theta_0$ است، یعنی بردار $\\theta$ که از 0 تا n ایندکس شده است(n+1 مقدار را از $\\theta_0$ تا $\\theta_n$ نگه می‌دارد) ، سیگما صراحتا $\\theta_0$ را با شروع از 1 تا n رد می‌کند.\nبنابراین، هنگام محاسبه معادله، باید دو معادله زیر را به طور مداوم به روز رسانی کنیم:\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient3/",
	"title": "گرادیان کاهشی قسمت سوم",
	"tags": [],
	"description": "",
	"content": "در این قسمت گرادیان کاهشی را با تابع هزینه ترکیب می‌کنیم و الگوریتم رگرسیون خطی را به دست می‌آوریم. تا اینجای کار به این ها رسیدیم:\nاینجا می‌خواهیم از گرادیان کاهشی برای مینیمم کردن تابع هزینه استفاده کنیم! ابتدا تابع $J$ را در الگوریتم گرادیان جاگذاری می‌کنیم و \u0026hellip;\nبا محاسبه عبارت مشتق جزئی در گرادیان کاهشی برای دو پارامتر $\\theta_0$ و $\\theta_1$ خواهیم داشت:\n$$ \\theta_0, j = 0: \\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) $$\n$$ \\theta_1, j = 1: \\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x^{(i)} $$\nبه الگوریتم گرادیان کاهشی بر‌ می‌گردیم و جایگذاری، و در واقع به الگوریتم رگرسیون خطی می‌رسیم!\nدر قسمت اول گرادیان کاهشی در مثال موتور سوار دیدیم که بسته به اینکه از کجا شروع کنیم ممکن است که به مینیمم محلی برسیم! اما تابع هزینه برای رگرسیون خطی همیشه تابعی سهمی مانند مثل این است:\nاین تابع محدب مینیمم محلی ندارد، و فقط یک مینیمم کلی دارد. یعنی گرادیان کاهشی برای این تابع هزینه همیشه به نقطه بهینه می‌رسد! و بنابراین گرادیان نزولی را در عمل برای داده خانه ها به به این صورت می‌بینیم، که نتیجه تناسب خوبی دارد:\nو حالا می‌توانید از آن استفاده کنید تا قیمت خانه ها را برای دوستانتان پیش‌بینی کنید!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/data-for-machine-learning/",
	"title": "داده برای یادگیری ماشین",
	"tags": [],
	"description": "",
	"content": "چه مقدار داده را باید آموزش دهیم؟ در موارد مشخص، یک الگوریتم کم کیفیت با داده بیشتر، میتواند عملکرد بهتری نسبت به یک الگوریتم با کیفیت و داده کمتر داشته باشد.\nما باید ویژگی‌هایی را انتخاب کنیم تا اطلاعات کافی داشته باشیم. یک آزمون مفید به این صورت است که: با توجه به ورودی x، آیا یک متخصص انسانی می‌تواند با اطمینان y را پیش بینی کند؟\nمنطق داده‌های بزرگ: اگر یک الگوریتم با بایاس کم داشته باشیم (ویژگی‌های زیاد یا واحدهای پنهان یک تابع بسیار پیچیده می‌سازد)، پس هرچه مجموعه آموزشی بزرگتر باشد، overfitting کمتری خواهیم داشت (و الگوریتم روی مجموعه آزمون دقیق‌تر خواهد بود).\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/files/",
	"title": "فایل های هفته سوم",
	"tags": [],
	"description": "",
	"content": "اسلاید ها  Logistic regression - pdf Regularization - pdf  غلط نامه  Errata - pdf  تمرین برنامه نویسی  Programming Exercise 2: Logistic Regression - pdf | problem  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/files/",
	"title": "فایل های هفته اول",
	"tags": [],
	"description": "",
	"content": "اسلاید ها  Welcome - pdf Linear regression with one variable - pdf Linear Algebra review (Optional) - pdf  غلط نامه  Errata - pdf  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week6/files/",
	"title": "فایل های هفته ششم",
	"tags": [],
	"description": "",
	"content": "اسلاید ها  Advice for applying machine learning - pdf Machine learning system design - pdf  غلط نامه  Errata - pdf  تمرین برنامه نویسی  Programming Exercise 5: Regularized Linear Regression and Bias v.s. Variance - pdf | problem  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]