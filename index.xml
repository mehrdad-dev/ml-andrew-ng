<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>دوره یادگیری ماشین دانشگاه استنفورد به فارسی on Machine Learning Andrew Ng</title>
    <link>https://mehrdad-dev.github.io/ml-andrew-ng/</link>
    <description>Recent content in دوره یادگیری ماشین دانشگاه استنفورد به فارسی on Machine Learning Andrew Ng</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 05 Sep 2020 18:40:41 +0430</lastBuildDate>
    
	<atom:link href="https://mehrdad-dev.github.io/ml-andrew-ng/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>مقدمه یادگیری بدون نظارت</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week8/unsupervised-learning-introduction/</link>
      <pubDate>Mon, 19 Oct 2020 12:22:06 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week8/unsupervised-learning-introduction/</guid>
      <description>یادگیری بدون نظارت در تضاد با یادگیری با نظارت است، زیرا از یک مجموعه آموزشی بدون لیبل استفاده می‌کند.
به عبارت دیگر، ما بردار $y$ را به عنوان نتایج مورد انتظار نداریم، فقط مجموعه داده ای از ویژگی ها داریم که می‌خواهیم ساختاری در آن ها پیدا کنیم.
طبقه بندی برای موراد زیر خوب است:
 تقسیم بندی بازار تحلیل شبکه های اجتماعی سازماندهی خوشه های رایانه ای تجزیه و تحلیل داده های نجومی  </description>
    </item>
    
    <item>
      <title>بهینه سازی هدفمند</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week7/optimization-objective/</link>
      <pubDate>Mon, 12 Oct 2020 14:37:24 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week7/optimization-objective/</guid>
      <description>ماشین بردار پشتیبان (SVM) یکی دیگر از الگوریتم های یادگیری ماشین با نظارت است که گاهی تمیزتر و قدرتمندتر عمل می کند. اگر به خاطر بیاورید، ما در رگریسیون لجستیک از ضوابط زیر استفاده می کردیم:
$$ if\hspace{0.3cm} y=1,\hspace{0.2cm} then \hspace{0.3cm} h_\theta(x)\approx 1 \hspace{0.3cm} and \hspace{0.3cm}\theta\ ^ T x \gg 0 $$
$$ if\hspace{0.3cm} y=0,\hspace{0.2cm} then \hspace{0.3cm} h_\theta(x)\approx 0 \hspace{0.3cm} and \hspace{0.3cm}\theta\ ^ T x \ll 0 $$
تابع هزینه را برای رگریسیون لجستیک (نامنظم) به خاطر بیاورید:</description>
    </item>
    
    <item>
      <title>ارزیابی فرضیه</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/evaluating-hypothesis/</link>
      <pubDate>Sun, 04 Oct 2020 13:22:30 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/evaluating-hypothesis/</guid>
      <description>خطاهای موجود در پیش بینی هایتان را با استفاده از روش های زیر می‌توانید عیب یابی کنید:
 جمع آوری داده های آموزشی بیشتر استفاده از مجموعه های ویژگی کوچکتر امتحان کردن ویژگی های اضافی استفاده از ویژگی های چند جمله ای افزایش یا کاهش مقدار $\lambda$  برای عیب یابی یکی از راه های ذکر شده در بالا را به صورت تصادفی انتخاب نکنید، در بخش های بعدی تکنیک هایی برای انتخاب یکی از راه حل ها را بررسی می‌کنیم.</description>
    </item>
    
    <item>
      <title>تابع هزینه شبکه عصبی</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week5/nn-cost-function/</link>
      <pubDate>Wed, 30 Sep 2020 17:52:45 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week5/nn-cost-function/</guid>
      <description>اجازه دهید برای شروع چند متغیر تعریف کنیم:
   متغیر      $L$ تعداد کل لایه ها در شبکه عصبی   $s_l$ تعداد گره ها در لایه $l$ ام (بدون احتساب گره بایاس)   $K$ تعداد کلاس های خروجی    به یاد بیاورید که در شبکه های عصبی ممکن است تعداد گره های خروجی زیادی داشته باشیم. ما $h_\Theta(x)_k$ را به عنوان یک فرضیه در نظر می‌گیریم، که منجر به خروجی $k^{th}$ می‌شود.</description>
    </item>
    
    <item>
      <title>فرضیه غیر خطی</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week4/non-linear-hypotheses/</link>
      <pubDate>Tue, 15 Sep 2020 13:37:07 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week4/non-linear-hypotheses/</guid>
      <description>انجام رگرسیون لجستیک با مجموعه ای پیچیده از داده ها و ویژگی های زیاد، کار بسیار دشواری است. تصور کنید فرضیه ای با ۳ ویژگی دارید به همراه تمام جملات درجه ۲ آن:
$$ g(\theta_0 + \theta_1 x_1^2 + \theta_2 x_1 x_2 + \theta_3 x_1 x_3 + \theta_4 x_2 ^2 + \theta_5 x_2 x_3 + \theta_6 x_3 ^2 ) $$ می‌بینیم که ۶ ویژگی به ما می‌دهد.
روشی دقیق برای محاسبه تعداد ویژگی ها: $ \frac{(n + r - 1)!</description>
    </item>
    
    <item>
      <title>رگرسیون خطی چند متغیره</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week2/linear-regression-many-variable/</link>
      <pubDate>Wed, 09 Sep 2020 21:11:53 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week2/linear-regression-many-variable/</guid>
      <description>توی این هفته قراره در مورد رگرسیون خطی با چندین متغیر صحبت کنیم!
مثلا داده ای شبیه به این برای خانه ها را فرض کنید:
   نماد      $m$ تعداد کل سطر های جدول داده ها   $n$ تعداد ویژگی ها یا همان متغیر ها   $x^{(i)}$ i امین ردیف از جدول شامل متغیر ها   $x_j^{(i)}$ مقدار موجود در ردیف i ام و ستون متغیر j    بنابراین برای تابع فرضه داریم: $h_\theta = \theta_0 + \theta_1 + \theta_2x + &amp;hellip; + \theta_nx$</description>
    </item>
    
    <item>
      <title>یادگیری ماشین چیست؟</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week1/what-is-ml/</link>
      <pubDate>Sat, 05 Sep 2020 18:40:41 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week1/what-is-ml/</guid>
      <description>دو تعریف از یادگیری ماشین ارائه شده است:
 Arthur Samuel: رشته مطالعاتی که به کامپیوتر ها این توانایی را می‌دهد که بدون برنامه نویسی صریح یاد بگیرند.
 توجه: این یک تعریف قدیمی و غیر رسمی است!
 اما تعریفی مدرن تر &amp;hellip;
 Tom Mitchell: به یک برنامه کامپیوتری گفته می‌شود که: برای یادگیری از تجربه E با توجه به برخی از وظایف به عنوان T و اندازه گیری عملکرد با P اگر عملکرد وظیفه T با استفاده از P اندازه گیری شود با استفاده از تجربه E بهبود یابد.</description>
    </item>
    
    <item>
      <title>الگوریتم K-Means</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week8/k-means/</link>
      <pubDate>Mon, 19 Oct 2020 12:43:35 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week8/k-means/</guid>
      <description>الگوریتم K-Means محبوب ترین و پرکاربردترین الگوریتم برای گروه بندی خودکار داده ها در زیر مجموعه های منسجم (اعضای آن به هم مربوط هستند) است.
 به طور تصادفی دو نقطه از مجموعه داده ها را به نام مرکز خوشه ای مقدار دهی می‌کنیم تخصیص خوشه: همه مثالها را به یکی از دو گروه تقسیم کنید بر اساس اینکه به کدام مرکز خوشه نزدیک است میانگین تمام نقاط داخل هر دو گروه مرکز خوشه ای را محاسبه کنید، سپس نقاط مرکز خوشه را به آن میانگین ها منتقل کنید مرحله ۲ و ۳ را دوباره اجرا کنید تا زمانی که خوشه های خود را پیدا کنید  متغیرهای اصلی ما عبارتند از:</description>
    </item>
    
    <item>
      <title>انتخاب مدل</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/model-selection/</link>
      <pubDate>Thu, 15 Oct 2020 17:25:10 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/model-selection/</guid>
      <description>فقط به این دلیل که یک الگوریتم یادگیری متناسب با مجموعه آموزشی ما است، به این معنی نیست که آن فرضیه خوبی است!
می‌تواند overfit شده باشد، که در نتیجه پیش بینی های شما برای مجموعه آزمون ضعیف خواهد بود.
اگر خطای فرضیه خود را با داده هایی که با آن پارامتر ها را آموزش داده اید محاسبه کنید، کمتر از مجموعه داده های دیگر خواهد بود!
برای انتخاب مدل خود، می‌توانید هر درجه از چند جمله ای ها را آزمایش کرده و به نتیجه خطای آن توجه کنید.</description>
    </item>
    
    <item>
      <title>پس انتشار قسمت اول</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week5/backpropagation-1/</link>
      <pubDate>Thu, 01 Oct 2020 12:30:31 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week5/backpropagation-1/</guid>
      <description>پس انتشار در شبکه های عصبی، برای به حداقل رساندن تابع هزینه مثل کاری که با گرادیان کاهشی در رگرسیون لجستیک و خطی انجام می‌دادیم، استفاده می‌شود.
هدف ما محاسبه این است:
$$ min_\Theta J(\Theta) $$
یعنی می‌خواهیم تابع هزیه $J$ را با استفاده از یک محموعه بهینه از پارامتر $\Theta$ به حداقل برسانیم (یا به عبارتی دیگر مینیمم کنیم).
در این بخش به معادلاتی که برای محاسبه مشتق جزئی تابع $J(\Theta)$ استفاده می‌کنیم، خواهیم پرداخت:</description>
    </item>
    
    <item>
      <title>نورون ها و مغز</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week4/neurons-and-brain/</link>
      <pubDate>Tue, 15 Sep 2020 19:18:30 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week4/neurons-and-brain/</guid>
      <description>مبدا و سرچشمه شبکه های عصبی ساخت الگوریتم هایی است که سعی کنند از مغز تقلید کنند. شبکه های عصبی در دهه ۸۰ و ۹۰ میلادی بسیار مورد استفاده قرار می‌گرفته اند، اما در اواخر دهه ۹۰ از محبوبیت آن ها کاسته شد، و اخیرا به دلیل پشرفت در سخت افزار کامپیوتر ها دوباره احیا شده است.
شواهدی وجود دارد که مغز تنها از یک الگوریتم یادگیری برای انجام تمام عملکرد های محتلف خود استفاده می‌کند.</description>
    </item>
    
    <item>
      <title>طبقه بندی</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week3/classification/</link>
      <pubDate>Thu, 10 Sep 2020 12:51:11 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week3/classification/</guid>
      <description>رگرسیون لجستیک اینجا از مسائل رگرسیون به مسائل طبقه بندی می‌رویم، اما با اسم رگرسیون لجستیک گیج نشوید! این اسم به دلایل تاریخی نامگذاری شده که در واقع رویکردی برای حل مسائل طبقه بندی است نه رگرسیون!
طبقه بندی دودویی به جای اینکه خروجی یعنی $y$ مقداری پیوسته در یک محدوده باشد، فقط $0$ یا $1$ است، یعنی : $ y \in \text{{0,1}} $
به طوری که معمولا به $0$، negative class و به $1$ هم positive class می‌گوییم، اما شما آزاد هستید که هر اسم دلخواهی را برای نام‌گذاری آن ها انتخاب کنید!</description>
    </item>
    
    <item>
      <title>گرادیان کاهشی چند متغیره</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week2/gradient-many-variable/</link>
      <pubDate>Wed, 09 Sep 2020 21:27:26 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week2/gradient-many-variable/</guid>
      <description>الگوریتم جدید ما برای گرادیان کاهشی با چندین متغیر به این صورت است:
و قسمت $ \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)} $ همان مشتق جرئی $\frac {\partial} {\partial\theta_0} J(\theta)$ است.
به طور مثال برای دو متغیره و یا بیشتر خواهیم داشت:
یادآوری: مقدار $x_0$ برابر $1$ است.
 </description>
    </item>
    
    <item>
      <title>یادگیری با نظارت چیست؟</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week1/supervised/</link>
      <pubDate>Sun, 06 Sep 2020 12:54:05 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week1/supervised/</guid>
      <description>تعریف یادگیری با نظارت در یـادگـیری با نظارت یک مجموعه داده داریم و از قبل می‌دانیم که خروجی صحیح باید چطور باشد، اصطلاحا داده های لیبل خورده اند! با این ایده که به بین خروجی و ورودی رابطه وجود دارد.
مسائل یادگیری با نظارت به دو دسته رگرسیون و طبقه بندی تقسیم می‌شوند.
رگرسیون | Regression در این مسائل سعی می‌کنیم خروجی ای با مقدار پیوسته را پیش بینی کنیم.</description>
    </item>
    
    <item>
      <title>بهینه سازی هدفمند</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week8/optimization-objective/</link>
      <pubDate>Thu, 22 Oct 2020 17:08:35 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week8/optimization-objective/</guid>
      <description>برخی از پارامتر هایی را که در الگوریتم خود استفاده کردیم به یاد بیاورید:
 $ = c ^ {(i)}$ ایندکس خوشه ای ${1,2,&amp;hellip;,k}$ که به نمونه $x^{(i)}$ منتسب شده است. $ = \mu _k $ خوشه مرکزی k $(\mu _k \in \mathbb{R} ^ n)$ $ = \mu _ {c ^ {(i)}} $ مرکز خوشه ای که به نمونه $x^{(i)}$ منتسب شد است.  </description>
    </item>
    
    <item>
      <title>تشخیص بایاس در مقابل واریانس</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/diagnosing-bias-variance/</link>
      <pubDate>Fri, 16 Oct 2020 19:43:49 +0000</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/diagnosing-bias-variance/</guid>
      <description>در این بخش به بررسی رابطه بین درجه چند جمله ای (d) و underfit و یا overfit بودن فرضیه می‌پردازیم.
 در ابتدا لازم است که تشخیص دهیم، عاملی که باعث پیش بینی نادرست شده بایاس است یا واریانس؟ بایاس زیاد همان underfitting و واریانس زیاد همان overfitting است که باید یک میانگین مناسب بین این دو مقدار انتخاب شود.  مادامی که ما درجه چندجمله ای را افزایش می‌دهیم، خطای آموزش کاهش می‌یابد.</description>
    </item>
    
    <item>
      <title>پس انتشار قسمت دوم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week5/backpropagation-2/</link>
      <pubDate>Thu, 08 Oct 2020 12:25:51 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week5/backpropagation-2/</guid>
      <description>به یاد بیاورید که تابع هزینه برای یک شبکه عصبی به این صورت بود:
$$ \begin{gather*}J(\Theta) = - \frac{1}{m} \sum_{t=1}^m\sum_{k=1}^K \left[ y^{(t)}_k \ \log (h_\Theta (x^{(t)}))_k + (1 - y^{(t)}_k)\ \log (1 - h_\Theta(x^{(t)})_k)\right] + \frac{\lambda}{2m}\sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_l+1} ( \Theta_{j,i}^{(l)})^2\end{gather*} $$
اگر یک طبقه بندی ساده، و غیر چند کلاسه ($k=1$) را در نظر بگیریم و همچنین منظم سازی را هم نادیده بگیریم، تابع هزینه ما به این صورت محاسبه خواهد شد:</description>
    </item>
    
    <item>
      <title>ارائه مدل قسمت اول</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week4/model-representation-1/</link>
      <pubDate>Thu, 17 Sep 2020 11:13:34 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week4/model-representation-1/</guid>
      <description>چگونه یک تابع فرضیه را با استفاده از شبکه های عصبی نشان خواهیم داد؟
شبکه های عصبی به عنوان روشی برای شبیه سازی نورون ها یا شبکه ای از نورون های در مغز ساخته شده اند.
یک نورون در مغز به این شکل است:
که به طور کلی از سه بخش قابل توجه زیر ساخته شده است:
 بدنه سلول بخش ورودی دنریت بخش خروجی اکسون  به طور ساده می‌توانیم بگوییم که:</description>
    </item>
    
    <item>
      <title>تابع هزینه</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week3/cost-function/</link>
      <pubDate>Fri, 11 Sep 2020 11:12:45 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week3/cost-function/</guid>
      <description>ما نمی‌توانیم از همان تابعی هزینه ای که برای رگرسیون خطی استفاده کردیم، برای تابع لجستیک نیز استفاده کنیم، زیرا خروجی تابع لجستیک موج گونه است و باعث ایجاد تعداد زیادی مینیمم محلی می‌شود. به عبارت دیگر یک تابع محدب (convex) نیست.
تابع هزینه ما برای Logistic Regression به این صورت است:
$$ J(\theta) = \frac{1}{m} \sum_{i = 1}^m Cost(h_\theta(x^{(i)}, y^{(i)})) $$
$$ Cost(h_\theta(x), y) = -log(h_\theta(x)) \hspace{1cm} if \hspace{0.3cm} y = 1 $$</description>
    </item>
    
    <item>
      <title>Feature Scaling</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week2/feature-scaling/</link>
      <pubDate>Wed, 09 Sep 2020 21:48:49 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week2/feature-scaling/</guid>
      <description>در این قسمت و قسمت بعدی در مورد فوت و فن هایی برای اعمال الگوریتم گرادیـــان کـــاهشی صحبت می‌کنیم.
اگر شما مسئله ای دارید که چندین ویژگی یا متغیر دارد و اگر مطمئن هستید که متغیر ها در مقیاس مشابه ای نسبت به هم هستند، در این حــالت گرادیــــان کـــاهشی با سرعت بیشتری به همگرایی می‌رسد.
فرض کنید مسئله ما دو متغیر به صورت زیر دارد: $$ x_1 = \text {size(0-2000 feet^2) }$$ $$ x_2 = \text {number of bedrooms(1-5) }$$</description>
    </item>
    
    <item>
      <title>یادگیری بدون نظارت چیست؟</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week1/unsupervised/</link>
      <pubDate>Sun, 06 Sep 2020 12:56:04 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week1/unsupervised/</guid>
      <description>تعریف یادگیری بدون نظارت یادگیری بدون نظارت این امکان را به ما مـی‌دهد کــه بدون داشتن هیچ ایده ای نسبت به خروجی داده ها به حل مشکلات نزدیک شویم. در واقع در اینجا داده های ما هیچ برچسبی نـدارنـد و الگوریتم‌ها به حال خود رها می‌شوند تا سـاختـارهــای موجود در میان داده‌ها را کشف کنند. مسائل بدون نظارت ها به دو دسته خوشه بندی و غیر خوشه بندی تقسیم می‌شوند.</description>
    </item>
    
    <item>
      <title>منظم سازی و بایاس/واریانس</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/regularization-and-bias-variance/</link>
      <pubDate>Fri, 16 Oct 2020 19:43:49 +0000</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/regularization-and-bias-variance/</guid>
      <description>در ادامه به جای بررسی d و تاثیر آن بر بایاس/واریانس، نگاهی به پارامتر مرتب سازی $\lambda$ خواهیم داشت.
 $\lambda$ بزرگ: بایاس زیاد (underfitting) $\lambda$ متوسط: مقدار مناسب $\lambda$ کوچک: واریانس زیاد (overfitting)  $\lambda$ بزرگ به شدت در تمامی پارامترهای $\theta$ ایجاد نقص می‌کند که این مسئله خط تابع حاصل شده را بسیار ساده کرده و موجب underfitting خواهد شد.
رابطه $\lambda$ با مجموعه آموزشی و مجموعه واریانس به صورت زیر است:</description>
    </item>
    
    <item>
      <title>بازکردن پارامتر ها</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week5/unrolling-parameters/</link>
      <pubDate>Sat, 10 Oct 2020 13:31:21 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week5/unrolling-parameters/</guid>
      <description>ما در شبکه های عصبی در حال کار با مجموعه ای از ماتریس ها هستیم: $$ \begin{align*} \Theta^{(1)}, \Theta^{(2)}, \Theta^{(3)}, \dots \newline D^{(1)}, D^{(2)}, D^{(3)}, \dots \end{align*} $$
برای استفاده از تابع بهینه سازی مثل ()fminunc، می‌خواهیم همه عضو ها را باز کنیم و داخل یک بردار طولانی قرار دهیم:
thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ] deltaVector = [ D1(:); D2(:); D3(:) ]  اگر ابعاد Theta1 $10 \times 11$ و Theta2 $10 \times 11$ و Theta3 $1 \times 11$ باشند، سپس می‌توانیم ماتریس های اصلی مان را از نسخه های باز شده به این شکل برگردانیم:</description>
    </item>
    
    <item>
      <title>ارائه مدل قسمت دوم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week4/model-representation-2/</link>
      <pubDate>Sun, 20 Sep 2020 15:54:56 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week4/model-representation-2/</guid>
      <description>در این قسمت چگونگی انجام محاسبات را به صورت بهینه تر از طریق پیاده سازی به روش برداری شده بررسی می‌کنیم. و می‌آموزیم که چرا شبکه های عصبی خوب هستند و چطور می‌توانیم از آن ها برای یادگیری چیز های پیچیده و غیر خطی استفاده کنیم.
برای یادآوری عبارات زیر مثالی های شبکه های عصبی بودند:
$$ \begin{align*} a_1^{(2)} = g(\Theta_{10}^{(1)}x_0 + \Theta_{11}^{(1)}x_1 + \Theta_{12}^{(1)}x_2 + \Theta_{13}^{(1)}x_3) \newline a_2^{(2)} = g(\Theta_{20}^{(1)}x_0 + \Theta_{21}^{(1)}x_1 + \Theta_{22}^{(1)}x_2 + \Theta_{23}^{(1)}x_3) \newline a_3^{(2)} = g(\Theta_{30}^{(1)}x_0 + \Theta_{31}^{(1)}x_1 + \Theta_{32}^{(1)}x_2 + \Theta_{33}^{(1)}x_3) \newline h_\Theta(x) = a_1^{(3)} = g(\Theta_{10}^{(2)}a_0^{(2)} + \Theta_{11}^{(2)}a_1^{(2)} + \Theta_{12}^{(2)}a_2^{(2)} + \Theta_{13}^{(2)}a_3^{(2)}) \newline \end{align*} $$</description>
    </item>
    
    <item>
      <title>ساده شده تابع هزینه و گرادیان کاهشی</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week3/simplified-cost-gradient/</link>
      <pubDate>Fri, 11 Sep 2020 12:53:43 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week3/simplified-cost-gradient/</guid>
      <description>Cost Function ما می‌توانیم دو حالت شرطی تابع هزینه خودمان در قسمت قبلی را در یک حالت فشرده شده بنویسیم:
$$ Cost(h_\theta(x), y) = - y \hspace{0.2cm} log(h_\theta(x)) - (1 - y) log(1 - h_\theta(x)) $$
در خاطر داشته باشید وقتی که $y$ برابر $1$ است، قسمت $(1 - y) log(1 - h_\theta(x))$ برار $0$ خواهد شد.
اگر $y$ برابر با $1$ باشد، سپس قسمت $- y \hspace{0.2cm} log(h_\theta(x))$ برابر $0$ خواهد شد و در نتیجه تاثیری ندارد.</description>
    </item>
    
    <item>
      <title>اشکال زدایی گرادیان</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week2/debugging-gradient/</link>
      <pubDate>Wed, 09 Sep 2020 22:03:11 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week2/debugging-gradient/</guid>
      <description>در این قسمت در مورد تکنیک هایی برای اطمینان از درستی کار گرادیان کاهشی صحبت مـی‌کنیم. و در ادامه در مورد نحوه انتخاب مقدار پارامتر آلفا.
همانطور که می‌دانیم کار گرادیان کاهشی پیدا کردن مقدار تتا برای ما است تا تابع هزینه مینیمم شود. می‌خواهیم نمودار تابع $J$ بر حسب دفعات انــــجام گرادیان کاهشی را رسم کنیم و تا متوجه بشویم که گرادیان کاهشی عملکرد درستی دارد یا نه!
به این ترتیب نموداری به این شکل خواهیم داشت: می‌بینیم که احتملا گرادیان کاهشی درست کار مـی‌کند چون بعد از هر بار انجام مقدار $J$ کاهش می‌یابد!</description>
    </item>
    
    <item>
      <title>رگرسیون خطی با یک متغیر</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week1/linear-regression-one-variable/</link>
      <pubDate>Sun, 06 Sep 2020 13:26:16 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week1/linear-regression-one-variable/</guid>
      <description>بررسی نماد ها و مفاهیم مثلا در داده ی خانه ها نماد ها به این صورت هستند:    نماد      $m$ تعداد کل ردیف های جدول داده آموزش   $x$ متغیر های ورودی   $y$ متغیر های خروجی یا هدف    برای آدرس دهی در جدول به این شکل عمل می‌کنیم:
$$(x_i, y_i) \Rightarrow x_1= 2104, y_1 = 460$$
اینجا منظور از $i$ اندیس داده در جدول است.</description>
    </item>
    
    <item>
      <title>منحنی های یادگیری</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/learning-curves/</link>
      <pubDate>Fri, 16 Oct 2020 19:43:49 +0000</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/learning-curves/</guid>
      <description>آموزش 3 نمونه به آسانی خطایی برابر با صفر خواهد داشت زیرا امکان پیدا کردن یک منحنی درجه دو که دقیقا با این سه نقطه برخورد کند همیشه وجود دارد!
  هرچه مجموعه آموزشی بزرگتر می‌شود، خطای تابع درجه دو افزایش می‌یابد.
  مقدار خطا پس از تعیین اندازه m یا مجموعه آموزشی، ثابت خواهد بود.
  با بایاس زیاد مجموعه آموزشی کوچک: باعث می‌شود تا $J_{train}\left ( \Theta \right )$ کم و $J_{cv}\left ( \Theta \right )$ زیاد باشد.</description>
    </item>
    
    <item>
      <title>بررسی گرادیان</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week5/gradient-checking/</link>
      <pubDate>Sun, 11 Oct 2020 16:33:27 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week5/gradient-checking/</guid>
      <description>بررسی گرادیان به شما این اطمینان را می‌دهد که پس انتشار همانطور که در نظر گرفته شده کار می‌کند‌ (مطابق هدف کار می‌کند).
ما می‌توانیم مشتق تابع خود را به این صورت تقریب بزنیم: $$ \frac{\partial}{\partial \Theta} J(\Theta) \approx \frac { J(\Theta + \epsilon) - J(\Theta - \epsilon) } {2 \epsilon} $$
با چند ماتریس تتا، می‌توانیم مشتق را با توجه به $\Theta _j$ تقریب بزنیم:
$$ \frac{\partial}{\partial \Theta} J(\Theta) \approx \frac{ J(\Theta _1, &amp;hellip;, \Theta _j + \epsilon, &amp;hellip;, \Theta _n) - J(\Theta _1, &amp;hellip;, \Theta _j - \epsilon, &amp;hellip;, \Theta _n)} {2 \epsilon} $$</description>
    </item>
    
    <item>
      <title>مثال ها قسمت اول</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week4/examples-1/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week4/examples-1/</guid>
      <description>عملگر منطقی AND یک مثال ساده از کاربرد شبکه های عصبی پیش بینی نتیجه عملگر منطقی AND بین دو متغیر $x_1$ و $x_2$ است.
می‌دانیم که جدول درستی عملگر AND به این صورت است:
شکل کلی توابع به صورت زیر است:
$$ \begin{align*}\begin{bmatrix}x_0 \newline x_1 \newline x_2\end{bmatrix} \rightarrow\begin{bmatrix}g(z^{(2)})\end{bmatrix} \rightarrow h_\Theta(x)\end{align*} $$
به خاطر داشته باشید که $x_0$ متغیر بایاس ما است، و همواره برابر با مقدار 1 است.
 و ماتریس وزن های خود را به این صورت تنظیم می‌کنیم:</description>
    </item>
    
    <item>
      <title>بهینه سازی پیشرفته</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week3/advanced-optimization/</link>
      <pubDate>Fri, 11 Sep 2020 13:28:40 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week3/advanced-optimization/</guid>
      <description>Conjugate gradient, BFGS و L-BFGS راه های پیچیده تر و سریع تری برای بهینه سازی $\theta$ به جای Gradient descent هستند.
پیشنهاد می‌شود که این الگوریتم های پیچیده را خودتان ننویسید (مگر اینکه در محاسبات عددی متخصص باشید)، و به جای آن از کتابخانه ها استفاده کنید، زیرا قبلا آزمایش شده اند و بسیار بهینه شده اند.
ابتدا لازم است تابعی بسازیم که دو مقدار زیر را با ورودی مقدار $\theta$ برگرداند:</description>
    </item>
    
    <item>
      <title>رگرسیون چند جمله ای</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week2/polynomial-regression/</link>
      <pubDate>Wed, 09 Sep 2020 22:12:45 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week2/polynomial-regression/</guid>
      <description>Polynomial Regression | رگرسیون چند جمله ای تابع فرضیه $h$ می‌تواند خطی نباشد، اگر تناسب خوبی با داده های ما ندارد، می‌توانیم برای تغییر منحنی تابع از توابع چند جمله ای استفاده کنیم تا به تناسب بهتری برای داده ها برسیم.
فرض کنید که تابع فرضیه ما $ h_\theta(x) = \theta_0 + \theta_1 x_1$ باشد بنابراین می‌توانیم ویژگی جدیدی بر پایه ویژگی $x_1$ اضافه کنیم تا به تابعی quadratic یا درجه دو برسیم:</description>
    </item>
    
    <item>
      <title>تابع هزینه قسمت اول</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost1/</link>
      <pubDate>Sun, 06 Sep 2020 14:08:57 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost1/</guid>
      <description>تابع هزینه | Cost Function با این تابع می‌توانیم بهترین خط مستقیم را برای داده هایمان به دست آوریم. با انتخاب های متفاوت برای پارامتر های $\theta_1$ و $\theta_0$ تابع های فرضیه متفاوتی به دست می‌آوریم: در رگرسیون خطی مجموعه آموزشی مثل این نمودار داریم و می‌خواهیم مقادیری برای $\theta_0$ و $\theta_1$ به دست آوریم به طوری که خط راستی که رسم می‌کنیم، بهترین تطابق را با داده هایمان داشته باشد.</description>
    </item>
    
    <item>
      <title>تصمیم گیری درباره اقدامات بعدی</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/deciding-what-to-do-next/</link>
      <pubDate>Sat, 17 Oct 2020 20:45:00 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/deciding-what-to-do-next/</guid>
      <description>روند تصمیم‌گیری ما می‌تواند به به شرح زیر باشد:
 جمع‌آوری نمونه آموزشی بیشتر: اصلاح واریانس زیاد استفاده از مجموعه کوچکتری از ویژگی‌ها: اصلاح واریانس زیاد اضافه کردن ویژگی: اصلاح بایاس زیاد اضافه کردن ویژگی‌های چندجمله‌ای: اصلاح بایاس زیاد کاهش $\lambda$: اصلاح بایاس زیاد افزایش $\lambda$: اصلاح واریانس زیاد  تشخیص شبکه‌های عصبی   یک شبکه عصبی با تعداد پارامترهای کم مستعد underfitting خواهد بود. همچنین این شبکه عصبی از نظر محاسباتی ارزان است.</description>
    </item>
    
    <item>
      <title>مقدار دهی اولیه تصادفی</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week5/random-initialization/</link>
      <pubDate>Sun, 11 Oct 2020 17:13:59 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week5/random-initialization/</guid>
      <description>مقدار دهی اولیه همه وزن های تتا (theta weights) به مقدار $0$ برای شبکه های عصبی کار ساز نیست!
وقتی از پس انتشار استفاده می‌کنیم، همه گره ها به طور مکرر به یک مقدار مشابه به روز می‌شوند. اما در عوض می‌توانیم وزن های ماتریس $\Theta$ خودمان را به روش زیر به صورت تصادفی مقدار دهی کنیم:
از این رو، ما هر $\Theta _{ij} ^{(l)}$ را به صورت عددی تصادفی بین $[ - \epsilon, \epsilon]$ مقدار دهی می‌کنیم، و استفاده از فرمول بالا تضمین می‌کند که این حد مد نظر را به دست می‌آوریم، همین رویه برای همه $\Theta$ ها انجام می‌شود.</description>
    </item>
    
    <item>
      <title>مثال ها قسمت دوم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week4/examples-2/</link>
      <pubDate>Wed, 30 Sep 2020 12:06:57 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week4/examples-2/</guid>
      <description>عملگر XNOR از قسمت قبل به خاطر داریم که ماتریس وزن $\Theta^{(1)}$ برای عملگر های منطقی AND، OR و NOR به این صورت بود: $$ \begin{align*}AND:\newline\Theta^{(1)} &amp;amp;=\begin{bmatrix}-30 &amp;amp; 20 &amp;amp; 20\end{bmatrix} \newline NOR:\newline\Theta^{(1)} &amp;amp;= \begin{bmatrix}10 &amp;amp; -20 &amp;amp; -20\end{bmatrix} \newline OR:\newline\Theta^{(1)} &amp;amp;= \begin{bmatrix}-10 &amp;amp; 20 &amp;amp; 20\end{bmatrix} \newline\end{align*} $$
با ترکیب آن ها می‌توانیم عملگر منطقی XNOR را به دست آوریم: $$ \begin{align*}\begin{bmatrix}x_0 \newline x_1 \newline x_2\end{bmatrix} \rightarrow\begin{bmatrix}a_1^{(2)} \newline a_2^{(2)} \end{bmatrix} \rightarrow\begin{bmatrix}a^{(3)}\end{bmatrix} \rightarrow h_\Theta(x)\end{align*} $$</description>
    </item>
    
    <item>
      <title>طبقه بندی چند کلاسه</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week3/multiclass-classification/</link>
      <pubDate>Sat, 12 Sep 2020 10:56:25 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week3/multiclass-classification/</guid>
      <description>هنگامی که در classifiction، بیش از دو دسته داشته باشیم به جای $y = \text{ {0,1} }$ تعاریف خود را به $ y = \text { {0,1, &amp;hellip;, n} } $ گسترش می‌دهیم.
از آنجا که ما مسئله خودمان را به n+1 (n+1 به این خاطر که ایندکس از صفر شروع می‌شود) مسئله طبقه بندی باینری تقسیم می‌کنیم، در هر کدام از آن ها ما احتمال عضویت $y$ را در یکی از کلاس هایمان پیش بینی می‌کنیم:</description>
    </item>
    
    <item>
      <title>معادله نرمال</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week2/normal-equation/</link>
      <pubDate>Thu, 10 Sep 2020 11:44:59 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week2/normal-equation/</guid>
      <description>Normal Equation | معادله نرمال الگوریتم گرادیان کاهشی روشی بود برای مینیمم کردن تابع $J$ ، اما روش دومی نیز وجود دارد که بدون داشتن حلقه تکرار این کار را انجام بدهد که معادله نرمال نام دارد.
فرض کنید که تابع هزینه درجه دو ای مثل این داریم: $$ J(\theta) = a\theta^2 + b\theta + c $$ $$ \frac{\partial} {\partial x} J(\theta) \overset{\underset{\mathrm{set}}{}}{=} 0 $$
که برای مینیمم کردن این تابع درجه دو مشتق آن را می‌گیریم و برابر با صفر قرار می‌دهیم، که این به ما اجازه می‌دهد که مقدار $\theta$ را برای مینیمم کردن تابع پیدا کنیم.</description>
    </item>
    
    <item>
      <title>تابع هزینه قسمت دوم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost2/</link>
      <pubDate>Sun, 06 Sep 2020 14:26:42 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost2/</guid>
      <description>تا اینجا به طور خلاصه تمام چیزی که از تابع هزینه می‌دانیم در زیر آمده است:
اما اجازه بدید برای ساده سازی تابع فرضیه را تنها با یک پارامتر به این شکل در نظر بگیریم: $ h_\theta(x) = \theta_1x $ و سه مقدار مختلف $0$، $5.0 $ و $1$ رو حساب کنیم &amp;hellip;
مثلا برای مقدار تتا برابر با $1$ محاسبات زیر را خواهیم داشت:
$$ {\color{Red} J(\theta_1) = \frac{1}{2m} \sum_{i=1}^{m} (\theta_1x - y_i)^2 \Rightarrow \frac{1}{2m} (0^2 + 0^2 + 0^2) = 0 } $$ به همین صورت برای دو مقدار دیگر داریم:</description>
    </item>
    
    <item>
      <title>Putting It Together</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week5/putting-it-together/</link>
      <pubDate>Sun, 11 Oct 2020 19:45:27 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week5/putting-it-together/</guid>
      <description>ابتدا معماری شبکه خود را انتخاب کنید!
لایه های شبکه عصبی خود را انتخاب کنید، از جمله اینکه چند گره پنهان در هر لایه و در کل چند لایه می‌خواهد داشته باشید.
 تعداد گره های ورودی = ابعاد ویژگی های $x^{(i)}$ تعداد گره های خروجی = تعداد کلاس ها (طبقه بندی ها) تعداد گره های پنهان در هر لایه = معمولا هر چه بیشتر بهتر (افزایش تعداد گره های پنهان باید با هزینه محاسبه آن ها تعادل داشته باشد) پیشفرض ها: ۱ لایه پنهان، اگر بیش از ۱ لایه پنهان دارید پیشنهاد می‌شود که در هر لایه پنهان تعداد گره یکسانی داشته باشید.</description>
    </item>
    
    <item>
      <title>طبقه بندی چند کلاسه</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week4/multiclass-classification/</link>
      <pubDate>Wed, 30 Sep 2020 16:39:28 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week4/multiclass-classification/</guid>
      <description>برای طبقه بندی داده ها در چندین کلاس، نیاز داریم که تابع فرضیه ما برداری از مقادیر را برگرداند. مثلا اگر بخواهیم داده هایمان را در یکی از ۴ دسته طبقه بندی کنیم می‌توانیم برای دیدن نحوه انجام این طبقه بندی از مثال زیر استفاده می‌کنیم، این الگوریتم یک تصویر را به عنوان ورودی گرفته و بر اساس آن طبقه بندی را انجام می‌دهد، ۴ دسته ما عبارت اند از:</description>
    </item>
    
    <item>
      <title>فایل های هفته دوم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week2/files/</link>
      <pubDate>Wed, 30 Sep 2020 12:56:30 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week2/files/</guid>
      <description>اسلاید ها  Linear regression with multiple variables - pdf Octave tutorial - pdf  غلط نامه  Errata - pdf  تمرین برنامه نویسی  Programming Exercise 1: Linear Regression - pdf | problem  </description>
    </item>
    
    <item>
      <title>مشکل Overfitting</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week3/overfitting/</link>
      <pubDate>Sun, 13 Sep 2020 10:33:52 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week3/overfitting/</guid>
      <description>تصور کنید مسئله پیش بینی $y$ را، به صورتی که $x \in R$ است را داریم.
سمت چپ ترین شکل زیر نتیجه fitting، $y = \theta_0 + \theta_1x$ را بر روی مجموعه داده نشان می‌دهد. می بینیم که داده ها واقعاً روی خط مستقیم قرار ندارند، بنابراین اصطلاحا خوب fit نشده است (تناسب خوبی با داده ها ندارد).
در عوض اگر ویژگی $x^2$ را اضافه کنیم، و $y = \theta_0 + \theta_1x+ \theta_2 x^2$ را fit کنیم، سپس کمی بهتر با داده ها مطابقت پیدا می‌کنیم که در شکل وسطی می‌بینیم.</description>
    </item>
    
    <item>
      <title>تابع هزینه قسمت سوم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost3/</link>
      <pubDate>Sun, 06 Sep 2020 16:31:03 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost3/</guid>
      <description>قسمت قبل دیدیم که با داشتن فقط یک پارامتر برای تابع فرضیه، نمودار تابع هزینه یا همان $J$ به صورت سهمی بود. اگر دو پارامتر داشته باشیم باز هم به صورت سهمی است، اما سه بعدی و بسته به داده ما ممکن است به شکل زیر باشد:
اما ما برای نمایش این تابع از شکل سه بعدی استفاده نمی‌کنیم‌، بلکه از نمودار های کانتور استفاده می‌کنیم!
در این نمودار ها هر یک از بیضی ها نشان دهنده مجموعه ای از نقاط است که مقادیر یکسانی در $J$ بر حسب $\theta_0$ و $\theta_1$ های مختلف دارند.</description>
    </item>
    
    <item>
      <title>نمونه ای از رانندگی خودکار</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week5/autonomous-driving/</link>
      <pubDate>Mon, 12 Oct 2020 13:09:44 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week5/autonomous-driving/</guid>
      <description>پروژه ALVINN ماشین خودران در سال ۱۹۸۹ ALVINN: Autonomous Land Vehicle In a Neural Network
برای مشاهده ویدئو این پروژه در YouTube بر روی تصویر زیر کلیک کنید:

توییت ای جالب در توییتر در این مورد (نیاز به vpn):
GPU? Gez, ALVINN ran on 100 MFLOP CPU, ~10x slower than iWatch; Refrigerator-size &amp;amp; needed 5000 watt generator. @olivercameron pic.twitter.com/QdGpZUzGCs
&amp;mdash; Dean Pomerleau (@deanpomerleau) November 24, 2016  </description>
    </item>
    
    <item>
      <title>فایل های هفته چهارم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week4/files/</link>
      <pubDate>Wed, 30 Sep 2020 13:04:55 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week4/files/</guid>
      <description>اسلاید ها  Neural Networks: Representation - pdf  غلط نامه  Errata - pdf  تمرین برنامه نویسی  Programming Exercise 3: Multi-class Classification and Neural Networks - pdf | problem  </description>
    </item>
    
    <item>
      <title> تابع هزینه در Overfitting</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week3/cost-function-overfitting/</link>
      <pubDate>Sun, 13 Sep 2020 12:19:33 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week3/cost-function-overfitting/</guid>
      <description>اگر تابع فرضیه ما مشکل overfitting دارد، ما می‌توانیم وزن بعضی از بخش های تابع فرضیه را با افزایش هزینه آن ها کاهش دهیم:
تصور کنید که تابع زیر را درجه دو تر کنیم: $$ \theta_0 + \theta_1x + \theta_2 x^2 + \theta_3 x^3 +\theta_4 x^4 $$
ما می‌خواهیم تاثیر $\theta_3 x^3$ و $\theta_4 x^4$ را از بین ببریم ، بدون اینکه از شر این ویژگی ها خلاص شویم یا فرم تابع فرضیه خود را تغییر دهیم، ما می‌توانیم تابع هزینه خود را اصلاح کنیم:</description>
    </item>
    
    <item>
      <title>گرادیان کاهشی قسمت اول</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient1/</link>
      <pubDate>Wed, 09 Sep 2020 16:31:43 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient1/</guid>
      <description>گرادیان کاهشی | Gradient Descent گرادیان کاهشی را برای مینیمم کردن تابع هزینه $J$ استفاده می‌کنیم. اما این الگوریتم تنها فقط در رگرسیون خطی کاربرد ندارد، بلکه در سایر قسمت های حوزه یادگیری ماشین نیز استفاده می‌شود.
مراحل کار به این شکل است:
با حدس های اولیه برای دو پارامتر $\theta_0$ و $\theta_1$ شروع می‌کنیم، مثلا مقدار هر دو را در ابتدا $0$ تعیین می‌کنیم.
و سپس مقادیر $\theta_0$ و $\theta_1$ را به صورت جزئی تغییر می‌دهیم تا تابع $J$ کاهش یابد، تا زمانی که به مینیمم کلی یا محلی برسیم.</description>
    </item>
    
    <item>
      <title>فایل های هفته پنجم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week5/files/</link>
      <pubDate>Mon, 12 Oct 2020 13:33:56 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week5/files/</guid>
      <description>اسلاید ها  Neural Networks: Learning - pdf  غلط نامه  Errata - pdf  تمرین برنامه نویسی  Programming Exercise 4: Neural Networks Learning - pdf | problem  </description>
    </item>
    
    <item>
      <title>رگرسیون خطی منظم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week3/regularized-linear-regression/</link>
      <pubDate>Sun, 13 Sep 2020 12:59:40 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week3/regularized-linear-regression/</guid>
      <description>ما می‌توانیم منظم سازی را هم برای رگرسیون خطی و هم برای رگرسیون لجستیک استفاده کنیم. که اینجا ابتدا رگرسیون خطی را بررسی می‌کنیم.
Gradient Descent گرادیان کاهشی را اصلاح می‌کنیم تا $\theta_0$ را از بقیه پارامتر ها جدا کنیم، زیرا نمی‌خواهیم تاثیر $\theta_0$ را کاهش دهیم و از بین ببریم:
$$ \begin{align*} &amp;amp; \text{Repeat}\ \lbrace \newline &amp;amp; \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline &amp;amp; \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &amp;amp;\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2&amp;hellip;n\rbrace\newline &amp;amp; \rbrace \end{align*} $$</description>
    </item>
    
    <item>
      <title>گرادیان کاهشی قسمت دوم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient2/</link>
      <pubDate>Wed, 09 Sep 2020 16:31:43 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient2/</guid>
      <description>در قسمت قبل گرادیان کاهشی را به این صورت معرفی کردیم، در این قسمت می‌خواهیم به توضیح آلفا و عبارت مشتق بپردازیم. اما برای برای درک بهتر می‌خواهیم با یک مثال ساده تر تابعی با یک پارامتر را مینیمم کنیم، یعنی فرض می‌کنیم تابع هزینه $J$ فقط یک پارامتر دارد.
تصور کنید تابع $J$ زیر را با پارامتر $\theta_1$ در این نقطه داریم، و از این نقطه کارمان را شروع می‌کنیم.</description>
    </item>
    
    <item>
      <title>رگرسیون لجستیک منظم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week3/regularized-logistic-regression/</link>
      <pubDate>Tue, 15 Sep 2020 12:48:24 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week3/regularized-logistic-regression/</guid>
      <description>می‌توانیم Logistic Regression را به روشی مشابه رگرسیون خطی منظم سازی کنیم، که در نتیجه می‌توانیم از overfitting پرهیز کنیم.
Cost Function به یاد بیاورید که تابع هزینه ما برای رگرسیون لجستیک به این شکل بود:
$$ J(\theta) = - \frac{1}{m} \sum_{i=1}^m [y^{(i)} log(h_\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\theta(x^{(i)}) )]
$$
ما می‌توانیم این معادله را با اضافه کردن یک قسمت به انتهای آن منظم کنیم:
$$ J(\theta) = - \frac{1}{m} \sum_{i=1}^m [y^{(i)} log(h_\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\theta(x^{(i)}) )] + \frac{\lambda}{2m} \sum_{j=1}^n \theta_j ^ 2 $$</description>
    </item>
    
    <item>
      <title>گرادیان کاهشی قسمت سوم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient3/</link>
      <pubDate>Wed, 09 Sep 2020 17:40:28 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient3/</guid>
      <description>در این قسمت گرادیان کاهشی را با تابع هزینه ترکیب می‌کنیم و الگوریتم رگرسیون خطی را به دست می‌آوریم. تا اینجای کار به این ها رسیدیم:
اینجا می‌خواهیم از گرادیان کاهشی برای مینیمم کردن تابع هزینه استفاده کنیم! ابتدا تابع $J$ را در الگوریتم گرادیان جاگذاری می‌کنیم و &amp;hellip;
با محاسبه عبارت مشتق جزئی در گرادیان کاهشی برای دو پارامتر $\theta_0$ و $\theta_1$ خواهیم داشت:
$$ \theta_0, j = 0: \frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1) = \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) $$</description>
    </item>
    
    <item>
      <title>فایل های هفته سوم</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week3/files/</link>
      <pubDate>Wed, 30 Sep 2020 13:04:49 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week3/files/</guid>
      <description>اسلاید ها  Logistic regression - pdf Regularization - pdf  غلط نامه  Errata - pdf  تمرین برنامه نویسی  Programming Exercise 2: Logistic Regression - pdf | problem  </description>
    </item>
    
    <item>
      <title>فایل های هفته اول</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week1/files/</link>
      <pubDate>Wed, 30 Sep 2020 12:46:19 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week1/files/</guid>
      <description>اسلاید ها  Welcome - pdf Linear regression with one variable - pdf Linear Algebra review (Optional) - pdf  غلط نامه  Errata - pdf  </description>
    </item>
    
  </channel>
</rss>