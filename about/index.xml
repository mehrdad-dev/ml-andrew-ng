<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>درباره  on Machine Learning Andrew Ng</title>
    <link>https://mehrdad-dev.github.io/ml-andrew-ng/about/</link>
    <description>Recent content in درباره  on Machine Learning Andrew Ng</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Sep 2020 17:16:09 +0430</lastBuildDate>
    
	<atom:link href="https://mehrdad-dev.github.io/ml-andrew-ng/about/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>فهرست مطالب</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/about/table-of-contents/</link>
      <pubDate>Sat, 05 Sep 2020 18:40:41 +0430</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/about/table-of-contents/</guid>
      <description>هفته اول     یادگیری ماشین چیست؟     یادگیری با نظارت چیست؟     یادگیری بدون نظارت چیست؟     رگرسیون خطی با یک متغیر     تابع هزینه قسمت اول     تابع هزینه قسمت دوم     تابع هزینه قسمت سوم     گرادیان کاهشی قسمت اول     گرادیان کاهشی قسمت دوم     گرادیان کاهشی قسمت سوم     فایل های هفته اول      هفته دوم    رگرسیون خطی چند متغیره     گرادیان کاهشی چند متغیره     مقیاس بندی ویژگی     اشکال زدایی گرادیان     رگرسیون چند جمله ای     معادله نرمال     فایل های هفته دوم      هفته سوم    طبقه بندی     تابع هزینه     ساده شده تابع هزینه و گرادیان کاهشی     بهینه سازی پیشرفته     طبقه بندی چند کلاسه     مشکل Overfitting     تابع هزینه در Overfitting     رگرسیون خطی منظم     رگرسیون لجستیک منظم     فایل های هفته سوم      هفته چهارم    فرضیه غیر خطی     نورون ها و مغز     ارائه مدل قسمت اول     ارائه مدل قسمت دوم     مثال ها قسمت اول     مثال ها قسمت دوم     طبقه بندی چند کلاسه     فایل های هفته چهارم      هفته پنجم    تابع هزینه شبکه عصبی     پس انتشار قسمت اول     پس انتشار قسمت دوم     بازکردن پارامتر ها     بررسی گرادیان     مقدار دهی اولیه تصادفی     Putting It Together     نمونه ای از رانندگی خودکار     فایل های هفته پنجم      هفته ششم    ارزیابی فرضیه     انتخاب مدل     تشخیص بایاس در مقابل واریانس     منظم سازی و بایاس/واریانس     منحنی های یادگیری     تصمیم گیری درباره اقدامات بعدی     اولویت بندی کارها     تحلیل خطا     معیار‌های خطا برای کلاس‌های نامتوازن     متوازن کردن Precision و Recall     داده برای یادگیری ماشین     فایل های هفته ششم      هفته هفتم    بهینه سازی هدفمند     درک حاشیه اطمینان زیاد     ریاضیات پشت طبقه بندی با حاشیه اطمینان زیاد (اختیاری)     کرنل ها قسمت اول     کرنل ها قسمت دوم     فایل های هفته هفتم     منابع بیشتر      هفته هشتم    مقدمه یادگیری بدون نظارت     الگوریتم K-Means     بهینه سازی هدفمند     مقداردهی اولیه تصادفی     انتخاب تعداد خوشه ها     کاهش ابعاد     تحلیل اجزای اصلی فرمول مسئله     تحلیل اجزای اصلی الگوریتم     بازسازی از حالت فشرده     انتخاب تعداد اجزای اصلی     توصیه هایی برای اعمال PCA     فایل های هفته هشتم      هفته نهم    انگیزه مسئله     توزیع گاوسی     الگوریتم     توسعه و ارزیابی سیستم تشخیص ناهنجاری     تشخیص ناهنجاری در مقابل یادگیری با نظارت      انتخاب ویژگی‌ها     توزیع گاوسی چند متغیره(اختیاری)     تشخیص ناهنجاری با استفاده از توزیع گاوسی چند متغیره (اختیاری)     فرمول مسئله     پیشنهادهای مبتنی بر محتوا     فیلترینگ مشارکتی     الگوریتم فیلترینگ مشارکتی     بردارسازی: فاکتورگیری ماتریس با درجه پایین     جزئیات پیاده‌سازی: نرمال‌سازی میانگین     فایل های هفته نهم      هفته دهم    یادگیری با مجموعه داده های بزرگ     گرادیان کاهشی تصادفی     همگرایی گرادیان کاهشی تصادفی     یادگیری آنلاین     کاهش نگاشت و موازی سازی داده     فایل های هفته دهم      هفته یازدهم    تبریک!</description>
    </item>
    
  </channel>
</rss>